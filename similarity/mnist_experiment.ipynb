{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "datasets.MNIST('../data', train=True, download=True,\n",
    "               transform=transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "               ])),\n",
    "    batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc_fn(features, classes):\n",
    "    inner_products = features.mm(features.t())\n",
    "    predictions = torch.sign(inner_products)\n",
    "    class_sims = 2 * classes.mm(classes.t()) - 1\n",
    "    num_incorrect = torch.sum(torch.abs(predictions - class_sims))/2\n",
    "    num_correct = torch.sum(torch.abs(predictions + class_sims))/2\n",
    "    return num_correct.double()\n",
    "\n",
    "def hinge_loss_fn(features, classes, gamma=1.0):    \n",
    "    inner_products = features.mm(features.t())\n",
    "    same_class = 2 * classes.mm(classes.t()) - 1\n",
    "    scores = torch.clamp(gamma - torch.mul(same_class, inner_products), min=0)\n",
    "    output = torch.sum(scores)\n",
    "    return output\n",
    "\n",
    "def logistic_loss_fn(features, classes):\n",
    "    inner_products = features.mm(features.t())\n",
    "    same_class = 2 * classes.mm(classes.t()) - 1\n",
    "    scores = torch.log1p(torch.exp(-same_class * inner_products))\n",
    "    output = torch.sum(scores)\n",
    "    return output\n",
    "\n",
    "def reg_fn(x, alpha = 1):\n",
    "    return alpha * torch.sum(x **2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    classes = Variable(torch.DoubleTensor(128, 10))\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if (data.shape[0] != 128):\n",
    "            classes = Variable(torch.DoubleTensor(data.shape[0], 10))\n",
    "            data = Variable(data).view(data.shape[0], 784)\n",
    "            target = Variable(target).view(data.shape[0], 1)\n",
    "        else:\n",
    "            data = Variable(data).view(128, 784)\n",
    "            target = Variable(target).view(128, 1)\n",
    "        classes.zero_()\n",
    "        classes.scatter_(1, target, 1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output.double(), classes.double()) + reg_fn(output.double())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = acc_fn(output.double(), classes.double())\n",
    "        if False and batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    classes = Variable(torch.DoubleTensor(50, 10))\n",
    "    for data, target in test_loader:\n",
    "        if (data.shape[0] != 50):\n",
    "            classes = Variable(torch.DoubleTensor(data.shape[0], 10))\n",
    "            data = Variable(data).view(data.shape[0], 784)\n",
    "            target = Variable(target).view(data.shape[0], 1)\n",
    "        else:\n",
    "            data = Variable(data).view(50, 784)\n",
    "            target = Variable(target).view(50, 1)\n",
    "        classes.zero_()\n",
    "        classes.scatter_(1, target, 1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        test_loss += loss_fn(output.double(), classes.double()) + reg_fn(output.double())\n",
    "        correct += acc_fn(output.double(), classes.double())\n",
    "        total += data.shape[0] * data.shape[0]\n",
    "\n",
    "    test_loss /= total\n",
    "    correct /= total\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {:.4f}%'.format(\n",
    "        test_loss.data[0], 100. * correct.data[0]))\n",
    "    return correct.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32 features, 2-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic loss, lr: 0.005\n",
      "Test set: Average loss: 0.3883, Accuracy: 89.6519%\n",
      "Test set: Average loss: 0.3418, Accuracy: 91.8059%\n",
      "Test set: Average loss: 0.3104, Accuracy: 92.9372%\n",
      "Test set: Average loss: 0.2925, Accuracy: 93.6002%\n",
      "Test set: Average loss: 0.2851, Accuracy: 94.1550%\n",
      "\n",
      "logistic loss, lr: 0.01\n",
      "Test set: Average loss: 0.3580, Accuracy: 90.2348%\n",
      "Test set: Average loss: 0.3161, Accuracy: 93.0629%\n",
      "Test set: Average loss: 0.2859, Accuracy: 93.8923%\n",
      "Test set: Average loss: 0.2950, Accuracy: 93.9531%\n",
      "Test set: Average loss: 0.2829, Accuracy: 94.5218%\n",
      "\n",
      "hinge loss, lr: 0.005\n",
      "Test set: Average loss: 0.3190, Accuracy: 91.0822%\n",
      "Test set: Average loss: 0.2516, Accuracy: 93.3953%\n",
      "Test set: Average loss: 0.2111, Accuracy: 94.2449%\n",
      "Test set: Average loss: 0.1986, Accuracy: 94.6151%\n",
      "Test set: Average loss: 0.1864, Accuracy: 95.0634%\n",
      "\n",
      "hinge loss, lr: 0.01\n",
      "Test set: Average loss: 0.3010, Accuracy: 91.7323%\n",
      "Test set: Average loss: 0.2310, Accuracy: 93.8121%\n",
      "Test set: Average loss: 0.2068, Accuracy: 94.3836%\n",
      "Test set: Average loss: 0.1882, Accuracy: 95.0031%\n",
      "Test set: Average loss: 0.1917, Accuracy: 94.8244%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.005, 0.01]:\n",
    "    loss_fn = logistic_loss_fn\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(784, 64),\n",
    "        torch.nn.BatchNorm1d(64),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 32)\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    print('logistic loss, lr: {}'.format(lr))\n",
    "    for epoch in range(5):\n",
    "        train(epoch)\n",
    "        test()\n",
    "    print()\n",
    "    \n",
    "for lr in [0.005, 0.01]:\n",
    "    loss_fn = hinge_loss_fn\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(784, 64),\n",
    "        torch.nn.BatchNorm1d(64),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 32)\n",
    "    )    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    print('hinge loss, lr: {}'.format(lr))\n",
    "    for epoch in range(5):\n",
    "        train(epoch)\n",
    "        test()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 features, 2-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic loss, lr: 0.0005\n",
      "Test set: Average loss: 0.5781, Accuracy: 73.8855%\n",
      "Test set: Average loss: 0.5564, Accuracy: 75.3544%\n",
      "Test set: Average loss: 0.5448, Accuracy: 75.1283%\n",
      "Test set: Average loss: 0.5350, Accuracy: 77.1252%\n",
      "Test set: Average loss: 0.5232, Accuracy: 76.3542%\n",
      "\n",
      "logistic loss, lr: 0.001\n",
      "Test set: Average loss: 0.5572, Accuracy: 75.7373%\n",
      "Test set: Average loss: 0.5337, Accuracy: 76.4281%\n",
      "Test set: Average loss: 0.5150, Accuracy: 76.6726%\n",
      "Test set: Average loss: 0.5032, Accuracy: 75.3771%\n",
      "Test set: Average loss: 0.4902, Accuracy: 75.6581%\n",
      "\n",
      "logistic loss, lr: 0.005\n",
      "Test set: Average loss: 0.5003, Accuracy: 75.9919%\n",
      "Test set: Average loss: 0.4645, Accuracy: 77.1719%\n",
      "Test set: Average loss: 0.4441, Accuracy: 77.5151%\n",
      "Test set: Average loss: 0.4390, Accuracy: 78.0368%\n",
      "Test set: Average loss: 0.4475, Accuracy: 77.7977%\n",
      "\n",
      "logistic loss, lr: 0.01\n",
      "Test set: Average loss: 0.4870, Accuracy: 75.7246%\n",
      "Test set: Average loss: 0.4526, Accuracy: 77.0228%\n",
      "Test set: Average loss: 0.4339, Accuracy: 77.3794%\n",
      "Test set: Average loss: 0.4378, Accuracy: 77.4064%\n",
      "Test set: Average loss: 0.4290, Accuracy: 77.6266%\n",
      "\n",
      "hinge loss, lr: 0.0005\n",
      "Test set: Average loss: 0.6761, Accuracy: 77.6638%\n",
      "Test set: Average loss: 0.6363, Accuracy: 79.4914%\n",
      "Test set: Average loss: 0.6037, Accuracy: 80.9215%\n",
      "Test set: Average loss: 0.5834, Accuracy: 81.6343%\n",
      "Test set: Average loss: 0.5685, Accuracy: 82.7430%\n",
      "\n",
      "hinge loss, lr: 0.001\n",
      "Test set: Average loss: 0.6030, Accuracy: 81.1219%\n",
      "Test set: Average loss: 0.5573, Accuracy: 83.1816%\n",
      "Test set: Average loss: 0.5292, Accuracy: 84.1306%\n",
      "Test set: Average loss: 0.5165, Accuracy: 84.4928%\n",
      "Test set: Average loss: 0.5052, Accuracy: 84.8337%\n",
      "\n",
      "hinge loss, lr: 0.005\n",
      "Test set: Average loss: 0.5640, Accuracy: 83.3069%\n",
      "Test set: Average loss: 0.5300, Accuracy: 84.5258%\n",
      "Test set: Average loss: 0.5172, Accuracy: 84.9755%\n",
      "Test set: Average loss: 0.5063, Accuracy: 85.6190%\n",
      "Test set: Average loss: 0.4981, Accuracy: 85.5030%\n",
      "\n",
      "hinge loss, lr: 0.01\n",
      "Test set: Average loss: 0.4903, Accuracy: 83.6002%\n",
      "Test set: Average loss: 0.4768, Accuracy: 84.4199%\n",
      "Test set: Average loss: 0.4507, Accuracy: 84.8034%\n",
      "Test set: Average loss: 0.4402, Accuracy: 84.7472%\n",
      "Test set: Average loss: 0.4388, Accuracy: 84.9782%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.0005, 0.001, 0.005, 0.01]:\n",
    "    loss_fn = logistic_loss_fn\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(784, 64),\n",
    "        torch.nn.BatchNorm1d(64),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 5)\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    print('logistic loss, lr: {}'.format(lr))\n",
    "    for epoch in range(5):\n",
    "        train(epoch)\n",
    "        test()\n",
    "    print()\n",
    "    \n",
    "for lr in [0.0005, 0.001, 0.005, 0.01]:\n",
    "    loss_fn = hinge_loss_fn\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(784, 64),\n",
    "        torch.nn.BatchNorm1d(64),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 5)\n",
    "    )    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    print('hinge loss, lr: {}'.format(lr))\n",
    "    for epoch in range(5):\n",
    "        train(epoch)\n",
    "        test()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 features, 3-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_selector = None\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic loss, lr: 0.005\n",
      "Test set: Average loss: 0.4488, Accuracy: 77.5119%\n",
      "Test set: Average loss: 0.4170, Accuracy: 78.9075%\n",
      "Test set: Average loss: 0.4195, Accuracy: 79.2945%\n",
      "Test set: Average loss: 0.4072, Accuracy: 79.1910%\n",
      "Test set: Average loss: 0.4053, Accuracy: 79.4282%\n",
      "Test set: Average loss: 0.4122, Accuracy: 79.6226%\n",
      "Test set: Average loss: 0.4000, Accuracy: 79.6144%\n",
      "Test set: Average loss: 0.4053, Accuracy: 79.4527%\n",
      "Test set: Average loss: 0.4069, Accuracy: 79.7583%\n",
      "Test set: Average loss: 0.4001, Accuracy: 79.6932%\n",
      "\n",
      "hinge loss, lr: 0.005\n",
      "Test set: Average loss: 0.5517, Accuracy: 83.2714%\n",
      "Test set: Average loss: 0.5190, Accuracy: 84.2642%\n",
      "Test set: Average loss: 0.4995, Accuracy: 84.7137%\n",
      "Test set: Average loss: 0.4960, Accuracy: 85.2199%\n",
      "Test set: Average loss: 0.4899, Accuracy: 85.4691%\n",
      "Test set: Average loss: 0.4836, Accuracy: 85.5986%\n",
      "Test set: Average loss: 0.4781, Accuracy: 85.9910%\n",
      "Test set: Average loss: 0.4735, Accuracy: 85.8993%\n",
      "Test set: Average loss: 0.4728, Accuracy: 85.9882%\n",
      "Test set: Average loss: 0.4757, Accuracy: 85.7628%\n",
      "\n",
      "hinge loss, lr: 0.01\n",
      "Test set: Average loss: 0.5359, Accuracy: 83.5711%\n",
      "Test set: Average loss: 0.5046, Accuracy: 84.8542%\n",
      "Test set: Average loss: 0.4999, Accuracy: 85.4475%\n",
      "Test set: Average loss: 0.4863, Accuracy: 85.6236%\n",
      "Test set: Average loss: 0.4923, Accuracy: 85.5237%\n",
      "Test set: Average loss: 0.4778, Accuracy: 85.7920%\n",
      "Test set: Average loss: 0.4747, Accuracy: 86.0191%\n",
      "Test set: Average loss: 0.4762, Accuracy: 85.6849%\n",
      "Test set: Average loss: 0.4731, Accuracy: 85.9635%\n",
      "Test set: Average loss: 0.4693, Accuracy: 86.1437%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.005]:\n",
    "    loss_fn = logistic_loss_fn\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(784, 64),\n",
    "        torch.nn.BatchNorm1d(64),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 64),\n",
    "        torch.nn.BatchNorm1d(64),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 5)\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    print('logistic loss, lr: {}'.format(lr))\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        acc = test()\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            feature_selector = model\n",
    "    print()\n",
    "    \n",
    "for lr in [0.005, 0.01]:\n",
    "    loss_fn = hinge_loss_fn\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(784, 64),\n",
    "        torch.nn.BatchNorm1d(64),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 5)\n",
    "    )    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    print('hinge loss, lr: {}'.format(lr))\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        acc = test()\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            feature_selector = model\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def acc_fn(output, target):    \n",
    "    classes = torch.max(output, dim=1)[1]  \n",
    "    num_equal = torch.sum(torch.clamp(-torch.abs(classes - target) + 1,min=0))\n",
    "#     num_equal = torch.sum(torch.eq(classes, target))\n",
    "#     print(classes)\n",
    "#     print(target)\n",
    "    return num_equal\n",
    "\n",
    "def mm_loss_fn(output, target, gamma=1.0):\n",
    "    scores = torch.clamp(gamma + torch.max(output, dim=1)[0] - output.gather(1, target.view(-1,1)), min=0)\n",
    "    loss = torch.sum(scores)\n",
    "    return loss\n",
    "\n",
    "def log_loss_fn(output, target):\n",
    "    log_softmax = F.log_softmax(output, dim=1)\n",
    "    scores = log_softmax.gather(1, target.view(-1,1))\n",
    "    loss = -torch.sum(scores)\n",
    "    return loss\n",
    "\n",
    "def train_classifier(epoch):\n",
    "    linear_classifier.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        features = feature_selector(data.view(data.shape[0], 784))\n",
    "        output = linear_classifier(features)\n",
    "        loss = mm_loss_fn(output, target) + reg_fn(output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if False and batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "def test_classifier():\n",
    "    linear_classifier.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        features = feature_selector(data.view(data.shape[0], 784))      \n",
    "        optimizer.zero_grad()\n",
    "        output = linear_classifier(features)        \n",
    "        test_loss += mm_loss_fn(output, target) + reg_fn(output)\n",
    "        correct += acc_fn(output, target)\n",
    "        total += data.shape[0]\n",
    "\n",
    "    test_loss /= total\n",
    "    correct = correct.double()\n",
    "    correct /= total\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {:.4f}%'.format(\n",
    "        test_loss.data[0], 100. * correct.data[0]))\n",
    "    return correct.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hinge loss, lr: 0.0001\n",
      "Test set: Average loss: 1690.0898, Accuracy: 11.6900%\n",
      "Test set: Average loss: 1494.5939, Accuracy: 20.6200%\n",
      "Test set: Average loss: 1344.7733, Accuracy: 28.6800%\n",
      "Test set: Average loss: 1227.3981, Accuracy: 36.6400%\n",
      "Test set: Average loss: 1133.5254, Accuracy: 25.3300%\n",
      "Test set: Average loss: 1063.1982, Accuracy: 50.1100%\n",
      "Test set: Average loss: 1049.9664, Accuracy: 50.6900%\n",
      "Test set: Average loss: 1046.5115, Accuracy: 53.3700%\n",
      "Test set: Average loss: 1035.0486, Accuracy: 52.8600%\n",
      "Test set: Average loss: 1034.7437, Accuracy: 54.8100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = log_loss_fn\n",
    "linear_classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(5, 10)\n",
    ")    \n",
    "lr = 0.0001\n",
    "optimizer = torch.optim.Adam(linear_classifier.parameters(), lr = lr)\n",
    "print('hinge loss, lr: {}'.format(lr))\n",
    "for epoch in range(10):\n",
    "    train_classifier(epoch)\n",
    "    test_classifier()\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
