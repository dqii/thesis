{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dqi/.conda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/dqi/.conda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "from features.samplers import PairSampler, TripletSampler\n",
    "from features.settings import Pair_Hinge_Settings, Pair_Log_Settings, Triplet_Hinge_Settings, Triplet_Log_Settings\n",
    "from features.models import ConvModelSmall, ConvModelMedium, ConvModelLarge\n",
    "from keras.datasets import mnist, fashion_mnist, cifar10, cifar100\n",
    "from sklearn.svm import LinearSVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_other = input_data.read_data_sets('MNIST_data', one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, settings, num_features, num_steps, lr, keep_prob, reg):\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    y = tf.placeholder(tf.int64, shape=[None])\n",
    "    dropout = tf.placeholder(tf.float32)\n",
    "    m = model(x, y, num_features, settings, lr, reg, dropout)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        print(\"begin training // num_features: %g, lr: %g, reg: %g\"%(num_features, lr, reg))\n",
    "        train_time = time.time()\n",
    "        for step in range(num_steps):\n",
    "            x_, y_ = train.sample(100)\n",
    "            sess.run(m.optimize, feed_dict={x:x_, y:y_, dropout:keep_prob})     \n",
    "            if step % 1000 == 0:\n",
    "                train_loss = sess.run(m.loss, feed_dict={x:x_, y:y_, dropout: 1.0})                \n",
    "                train_error = 1 - sess.run(m.acc, feed_dict={x:x_, y:y_, dropout: 1.0})\n",
    "                print(\"\\tstep %d: train loss %g, train error %g\"%(step, train_loss, train_error))  \n",
    "        train_time = time.time() - train_time\n",
    "        print(\"end training // time elapsed: %.4f s\"%(train_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        x_, y_ = test.sample(500)\n",
    "        test_error = 1 - sess.run(m.acc, feed_dict={x:x_, y:y_, dropout:1.0})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"test set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        svc = LinearSVC(random_state=0)\n",
    "        features_train = sess.run(m.features, feed_dict={x:x_train, y:y_train, dropout: 1.0})\n",
    "        svc.fit(features_train, y_train)\n",
    "        features_test = sess.run(m.features, feed_dict={x:x_test, y:y_test, dropout: 1.0})\n",
    "        print(\"classification accuracy: {:.4f}\".format(svc.score(features_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training // num_features: 10, lr: 0.0005, reg: 0\n",
      "\tstep 0: train loss 1.0027, train error 0.52\n",
      "\tstep 1000: train loss 0.0299508, train error 0.02\n",
      "\tstep 2000: train loss 0.018441, train error 0\n",
      "\tstep 3000: train loss 0.0396671, train error 0.02\n",
      "\tstep 4000: train loss 0.018127, train error 0.00999999\n",
      "\tstep 5000: train loss 0, train error 0\n",
      "\tstep 6000: train loss 0.0105485, train error 0\n",
      "\tstep 7000: train loss 0, train error 0\n",
      "\tstep 8000: train loss 0.0235283, train error 0.00999999\n",
      "\tstep 9000: train loss 0.00892892, train error 0\n",
      "\tstep 10000: train loss 0, train error 0\n",
      "\tstep 11000: train loss 0.00196601, train error 0\n",
      "\tstep 12000: train loss 0, train error 0\n",
      "\tstep 13000: train loss 0.0217008, train error 0.00999999\n",
      "\tstep 14000: train loss 0, train error 0\n",
      "\tstep 15000: train loss 0, train error 0\n",
      "\tstep 16000: train loss 0.000532984, train error 0\n",
      "\tstep 17000: train loss 0, train error 0\n",
      "\tstep 18000: train loss 0, train error 0\n",
      "\tstep 19000: train loss 0.003248, train error 0\n",
      "end training // time elapsed: 429.2154 s\n",
      "test set error: 0.0020 // time elapsed: 0.0336 s\n",
      "classification accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train.reshape((60000, -1))/255.0, x_test.reshape((10000, -1))/255.0\n",
    "train, test = TripletSampler((x_train, y_train)), TripletSampler((x_test, y_test))\n",
    "\n",
    "test_model(model=ConvModelSmall, settings=Triplet_Hinge_Settings, \n",
    "           num_features=10, num_steps=20000, lr=0.0005, keep_prob=0.8, reg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training // num_features: 10, lr: 0.0001, reg: 0\n",
      "\tstep 0: train loss 2.18447, train error 0.89\n",
      "\tstep 1000: train loss 1.00494, train error 0.86\n",
      "\tstep 2000: train loss 0.90664, train error 0.5\n",
      "\tstep 3000: train loss 0.796032, train error 0.39\n",
      "\tstep 4000: train loss 0.779033, train error 0.3\n",
      "\tstep 5000: train loss 0.580968, train error 0.23\n",
      "\tstep 6000: train loss 0.508518, train error 0.18\n",
      "\tstep 7000: train loss 0.563187, train error 0.22\n",
      "\tstep 8000: train loss 0.765119, train error 0.26\n",
      "\tstep 9000: train loss 0.556815, train error 0.16\n",
      "\tstep 10000: train loss 0.316389, train error 0.1\n",
      "\tstep 11000: train loss 0.506035, train error 0.15\n",
      "\tstep 12000: train loss 0.406031, train error 0.12\n",
      "\tstep 13000: train loss 0.246979, train error 0.09\n",
      "\tstep 14000: train loss 0.318502, train error 0.11\n",
      "\tstep 15000: train loss 0.39917, train error 0.12\n",
      "\tstep 16000: train loss 0.271222, train error 0.06\n",
      "\tstep 17000: train loss 0.326984, train error 0.1\n",
      "\tstep 18000: train loss 0.188281, train error 0.05\n",
      "\tstep 19000: train loss 0.22419, train error 0.07\n",
      "\tstep 20000: train loss 0.189732, train error 0.06\n",
      "\tstep 21000: train loss 0.343628, train error 0.08\n",
      "\tstep 22000: train loss 0.341635, train error 0.08\n",
      "\tstep 23000: train loss 0.221326, train error 0.08\n",
      "\tstep 24000: train loss 0.226654, train error 0.07\n",
      "\tstep 25000: train loss 0.269044, train error 0.09\n",
      "\tstep 26000: train loss 0.312757, train error 0.09\n",
      "\tstep 27000: train loss 0.259117, train error 0.09\n",
      "\tstep 28000: train loss 0.177127, train error 0.07\n",
      "\tstep 29000: train loss 0.41535, train error 0.05\n",
      "end training // time elapsed: 454.2696 s\n",
      "test set error: 0.0760 // time elapsed: 0.0156 s\n",
      "classification accuracy: 0.9278\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train.reshape((60000, -1))/255.0, x_test.reshape((10000, -1))/255.0\n",
    "train, test = PairSampler((x_train, y_train)), PairSampler((x_test, y_test))\n",
    "\n",
    "test_model(model=ConvModelSmall, settings=Pair_Hinge_Settings, \n",
    "           num_features=10, num_steps=30000, lr=0.0001, keep_prob=0.8, reg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
