{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from features.models import ConvModelSmall\n",
    "from features.settings import Baseline_Settings, Triplet_Hinge_Settings, Triplet_Log_Settings\n",
    "from classes.models import LinearClassifier, TwoLayerClassifier\n",
    "from learn import get_feature_model, get_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_save_path(i):\n",
    "    return '/tmp/boostmodels' + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifiers(iterations):\n",
    "    \n",
    "    probs = np.ones(60000)/60000\n",
    "    alpha = np.zeros(50)    \n",
    "    \n",
    "    for i in np.arange(iterations):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        f, f_params = get_feature_model(feature_model=ConvModelSmall, settings=Triplet_Hinge_Settings,\n",
    "                                        num_features=10, num_classes=10, data_format=[28, 28, 1],\n",
    "                                        f_lr=0.07, f_reg=0.001, f_scope=\"f_cms_mnist_10\")\n",
    "        fs = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"f_cms_mnist_10\"))\n",
    "        (x, y, dropout, training) = f_params\n",
    "\n",
    "        scope = \"boosting\" + str(i)\n",
    "        c, features = get_classifier(classifier=TwoLayerClassifier, num_features=10, num_classes=10, \n",
    "                                    c_lr=0.02, c_reg=0.001, c_scope=scope, f_params=f_params)\n",
    "\n",
    "        s = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope))\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            fs.restore(sess, \"./models/f_cms_mnist_10.ckpt\")\n",
    "\n",
    "            print(\"begin training classifier\")\n",
    "            train_time = time.time()\n",
    "            for step in range(2001):\n",
    "                indices = np.random.choice(60000, 1000, p=probs)\n",
    "                x_ = x_train[indices]\n",
    "                y_ = y_train[indices]\n",
    "                features_ = sess.run(f.features, feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "                sess.run(c.optimize, feed_dict={x:x_, y:y_, features:features_, dropout:1.0, training:True})\n",
    "                if step % 1000 == 0:\n",
    "                    train_loss, train_acc = sess.run([c.loss, c.acc], feed_dict={x:x_, y:y_, features:features_, \n",
    "                                                                                 dropout:1.0, training:False})\n",
    "                    print(\"\\tepoch %d: train loss %g, train error %g\"%(step/60, train_loss, 1 - train_acc))  \n",
    "            train_time = time.time() - train_time\n",
    "            print(\"end training classifier // time elapsed: %.4f s\"%(train_time))\n",
    "\n",
    "            eval_train_time = time.time()\n",
    "            x_ = x_train\n",
    "            y_ = y_train\n",
    "            features_ = sess.run(f.features, feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "            incorrect = sess.run(c.incorrect, \n",
    "                                 feed_dict={x:x_, y:y_, features:features_, dropout:1.0, training:False})\n",
    "            correct = incorrect * 2 - 1\n",
    "            train_error = np.sum(probs[incorrect.astype(bool)])\n",
    "            eval_train_time = time.time() - eval_train_time\n",
    "            print(\"train set error: %.4f // time elapsed: %.4f s\"%(train_error, eval_train_time))   \n",
    "\n",
    "            if train_error < 0.5:\n",
    "                s.save(sess=sess, save_path=get_save_path(i))\n",
    "            else:\n",
    "                return (i-1), alpha\n",
    "\n",
    "            eval_test_time = time.time()\n",
    "            features_ = sess.run(f.features, feed_dict={x:x_test, y:y_test, dropout:1.0, training:False})\n",
    "            test_error = 1 - sess.run(c.acc, feed_dict={x:x_test, y:y_test, \n",
    "                                                        features:features_, dropout:1.0, training:False})\n",
    "            eval_test_time = time.time() - eval_test_time\n",
    "            print(\"test set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time)) \n",
    "\n",
    "            alpha[i] = 0.5 * np.log((1 - train_error)/train_error)\n",
    "            probs = probs * np.exp(alpha[i]*correct)\n",
    "            probs /= np.sum(probs)\n",
    "            \n",
    "    return iterations, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_classifiers(iterations, alpha): \n",
    "    scores = np.zeros((10000, 10))\n",
    "    \n",
    "    for i in np.arange(iterations):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        f, f_params = get_feature_model(feature_model=ConvModelSmall, settings=Triplet_Hinge_Settings,\n",
    "                                        num_features=10, num_classes=10, data_format=[28, 28, 1],\n",
    "                                        f_lr=0.07, f_reg=0.001, f_scope=\"f_cms_mnist_10\")\n",
    "        fs = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"f_cms_mnist_10\"))\n",
    "        (x, y, dropout, training) = f_params\n",
    "    \n",
    "        scope = \"boosting\" + str(i)\n",
    "        c, features = get_classifier(classifier=TwoLayerClassifier, num_features=10, num_classes=10, \n",
    "                                    c_lr=0.02, c_reg=0.001, c_scope=scope, f_params=f_params)\n",
    "\n",
    "        s = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope))\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            s.restore(sess, get_save_path(i))\n",
    "            features_ = sess.run(f.features, feed_dict={x:x_test, y:y_test, dropout:1.0, training:False})\n",
    "            predictions = sess.run(c.predictions, feed_dict=\n",
    "                                   {x:x_test, y:y_test, features:features_, dropout:1.0, training:False})\n",
    "            scores[np.arange(10000), predictions] += alpha[i]\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/f_cms_mnist_10.ckpt\n",
      "begin training classifier\n",
      "\tepoch 0: train loss 2.61536, train error 0.882\n",
      "\tepoch 16: train loss 0.0753889, train error 0.011\n",
      "\tepoch 33: train loss 0.0873157, train error 0.015\n",
      "end training classifier // time elapsed: 85.0288 s\n",
      "train set error: 0.0126 // time elapsed: 0.9974 s\n",
      "test set error: 0.0129 // time elapsed: 0.1920 s\n",
      "INFO:tensorflow:Restoring parameters from ./models/f_cms_mnist_10.ckpt\n",
      "begin training classifier\n",
      "\tepoch 0: train loss 2.39609, train error 0.885\n",
      "\tepoch 16: train loss 0.772468, train error 0.316\n",
      "\tepoch 33: train loss 0.690776, train error 0.293\n",
      "end training classifier // time elapsed: 85.2076 s\n",
      "train set error: 0.3012 // time elapsed: 0.9485 s\n",
      "test set error: 0.0164 // time elapsed: 0.1747 s\n",
      "INFO:tensorflow:Restoring parameters from ./models/f_cms_mnist_10.ckpt\n",
      "begin training classifier\n",
      "\tepoch 0: train loss 2.39028, train error 0.854\n",
      "\tepoch 16: train loss 1.02831, train error 0.472\n",
      "\tepoch 33: train loss 0.88823, train error 0.408\n",
      "end training classifier // time elapsed: 85.2379 s\n",
      "train set error: 0.4149 // time elapsed: 0.9838 s\n",
      "test set error: 0.0193 // time elapsed: 0.2018 s\n",
      "INFO:tensorflow:Restoring parameters from ./models/f_cms_mnist_10.ckpt\n",
      "begin training classifier\n",
      "\tepoch 0: train loss 2.36538, train error 0.889\n",
      "\tepoch 16: train loss 1.08367, train error 0.511\n",
      "\tepoch 33: train loss 1.06305, train error 0.496\n",
      "end training classifier // time elapsed: 85.4371 s\n",
      "train set error: 0.4885 // time elapsed: 0.9565 s\n",
      "test set error: 0.0185 // time elapsed: 0.1800 s\n",
      "INFO:tensorflow:Restoring parameters from ./models/f_cms_mnist_10.ckpt\n",
      "begin training classifier\n",
      "\tepoch 0: train loss 2.40905, train error 0.933\n",
      "\tepoch 16: train loss 1.121, train error 0.514\n",
      "\tepoch 33: train loss 1.01278, train error 0.466\n",
      "end training classifier // time elapsed: 85.0461 s\n",
      "train set error: 0.4749 // time elapsed: 0.9849 s\n",
      "test set error: 0.0211 // time elapsed: 0.1715 s\n",
      "INFO:tensorflow:Restoring parameters from ./models/f_cms_mnist_10.ckpt\n",
      "begin training classifier\n",
      "\tepoch 0: train loss 2.5149, train error 0.918\n",
      "\tepoch 16: train loss 1.17514, train error 0.545\n",
      "\tepoch 33: train loss 1.07908, train error 0.517\n",
      "end training classifier // time elapsed: 84.8209 s\n",
      "train set error: 0.5267 // time elapsed: 1.0183 s\n",
      "INFO:tensorflow:Restoring parameters from /tmp/boostmodels0\n",
      "INFO:tensorflow:Restoring parameters from /tmp/boostmodels1\n",
      "INFO:tensorflow:Restoring parameters from /tmp/boostmodels2\n",
      "INFO:tensorflow:Restoring parameters from /tmp/boostmodels3\n",
      "boosted accuracy: 0.1187\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "iterations, alpha = train_classifiers(iterations)\n",
    "scores = eval_classifiers(iterations, alpha)\n",
    "print(\"boosted accuracy:\", np.mean(np.equal(np.argmax(scores, axis=1), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
