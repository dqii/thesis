{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dqi/.conda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/dqi/.conda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from features.settings import Baseline_Settings, Triplet_Hinge_Settings, Triplet_Log_Settings, Pair_Hinge_Settings\n",
    "from features.models import CNNSmall0, CNNSmall1, CNNSmall2, CNNMedium0, CNNMedium1, CNNLarge0, CNNLarge1\n",
    "from features.models import STNCNNSmall0, STNCNNSmall1, STNCNNSmall2, STNCNNMedium0, STNCNNMedium1\n",
    "from features.models import GCNNSmall0, GCNNMedium0, GCNNMedium1, GCNNLarge0\n",
    "from learn import get_feature_model, train_features, test_features\n",
    "from datasets import load_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 loaded in 102 seconds\n"
     ]
    }
   ],
   "source": [
    "data, samplers, pair_samplers, triplet_samplers = load_cifar10(augment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = data; s=samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features\n",
      "\tstep 0: train loss 2.76624, train error 0.89, valid loss 2.7591, valid error 0.865714\n",
      "\tstep 200: train loss 2.74586, train error 0.778571, valid loss 2.74518, valid error 0.755714\n",
      "\tstep 400: train loss 1.67652, train error 0.481429, valid loss 1.65189, valid error 0.46\n",
      "\tstep 600: train loss 1.42236, train error 0.387143, valid loss 1.51102, valid error 0.397143\n",
      "\tstep 800: train loss 1.39443, train error 0.375714, valid loss 1.37988, valid error 0.377143\n",
      "\tstep 1000: train loss 1.18622, train error 0.292857, valid loss 1.2989, valid error 0.357143\n",
      "\tstep 1200: train loss 1.23132, train error 0.328571, valid loss 1.17455, valid error 0.324286\n",
      "\tstep 1400: train loss 1.06995, train error 0.281429, valid loss 1.00225, valid error 0.29\n",
      "\tstep 1600: train loss 0.953364, train error 0.251429, valid loss 1.08847, valid error 0.281429\n",
      "\tstep 1800: train loss 0.899414, train error 0.235714, valid loss 0.916466, valid error 0.244286\n",
      "\tstep 2000: train loss 0.999697, train error 0.287143, valid loss 1.13202, valid error 0.335714\n",
      "\tstep 2200: train loss 0.732866, train error 0.17, valid loss 0.998464, valid error 0.267143\n",
      "\tstep 2400: train loss 0.739833, train error 0.172857, valid loss 0.882309, valid error 0.247143\n",
      "\tstep 2600: train loss 0.705943, train error 0.188571, valid loss 0.742435, valid error 0.181429\n",
      "\tstep 2800: train loss 0.680753, train error 0.172857, valid loss 0.846699, valid error 0.23\n",
      "\tstep 3000: train loss 0.624713, train error 0.155714, valid loss 0.824943, valid error 0.24\n",
      "\tstep 3200: train loss 0.546684, train error 0.142857, valid loss 0.756572, valid error 0.204286\n",
      "\tstep 3400: train loss 0.589847, train error 0.142857, valid loss 0.765067, valid error 0.212857\n",
      "\tstep 3600: train loss 0.658493, train error 0.165714, valid loss 0.811875, valid error 0.235714\n",
      "\tstep 3800: train loss 0.47201, train error 0.118571, valid loss 0.73904, valid error 0.187143\n",
      "\tstep 4000: train loss 0.393894, train error 0.0828571, valid loss 0.597254, valid error 0.157143\n",
      "\tstep 4200: train loss 0.368042, train error 0.0642857, valid loss 0.664879, valid error 0.175714\n",
      "\tstep 4400: train loss 0.385114, train error 0.0814286, valid loss 0.649268, valid error 0.165714\n",
      "\tstep 4600: train loss 0.344135, train error 0.0671428, valid loss 0.537506, valid error 0.16\n",
      "\tstep 4800: train loss 0.289376, train error 0.0557143, valid loss 0.641962, valid error 0.174286\n",
      "\tstep 5000: train loss 0.320466, train error 0.0614285, valid loss 0.585634, valid error 0.162857\n",
      "\tstep 5200: train loss 0.338795, train error 0.0742857, valid loss 0.705386, valid error 0.185714\n",
      "\tstep 5400: train loss 0.261251, train error 0.0385714, valid loss 0.535367, valid error 0.151429\n",
      "\tstep 5600: train loss 0.262966, train error 0.0428572, valid loss 0.590719, valid error 0.167143\n",
      "\tstep 5800: train loss 0.2811, train error 0.0442857, valid loss 0.58719, valid error 0.162857\n",
      "\tstep 6000: train loss 0.201508, train error 0.0171428, valid loss 0.661952, valid error 0.16\n",
      "\tstep 6200: train loss 0.18876, train error 0.0114286, valid loss 0.647294, valid error 0.17\n",
      "\tstep 6400: train loss 0.209413, train error 0.0214286, valid loss 0.548911, valid error 0.152857\n",
      "\tstep 6600: train loss 0.189083, train error 0.02, valid loss 0.613187, valid error 0.171429\n",
      "\tstep 6800: train loss 0.20226, train error 0.02, valid loss 0.661498, valid error 0.168571\n",
      "\tstep 7000: train loss 0.181452, train error 0.0171428, valid loss 0.587289, valid error 0.151429\n",
      "\tstep 7200: train loss 0.196995, train error 0.0214286, valid loss 0.689232, valid error 0.172857\n",
      "\tstep 7400: train loss 0.183077, train error 0.0171428, valid loss 0.620104, valid error 0.164286\n",
      "\tstep 7600: train loss 0.165953, train error 0.0128571, valid loss 0.570421, valid error 0.157143\n",
      "\tstep 7800: train loss 0.166036, train error 0.00999999, valid loss 0.4524, valid error 0.11\n",
      "\tstep 8000: train loss 0.153968, train error 0.0057143, valid loss 0.58254, valid error 0.144286\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2f775251a00f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./models/fmnist/b_gm1_cifar10_10.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/similarity_experiments/learn.py\u001b[0m in \u001b[0;36mtrain_features\u001b[0;34m(sess, feature_model, samplers, num_steps, keep_prob, f_params)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             train_loss, train_acc = sess.run([feature_model.loss, feature_model.acc], \n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "f, f_params = get_feature_model(feature_model=GCNNMedium1, settings=Baseline_Settings,\n",
    "                                num_features=10, data_format=[32, 32, 3],\n",
    "                                f_lr=0.05, f_reg=0.001, f_scope=\"b_gm1_cifar10_10\")\n",
    "fs = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"b_gm1_cifar10_10\"))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_features(sess=sess, feature_model=f, samplers=s, num_steps=40000, keep_prob=0.8, f_params=f_params)\n",
    "    fs.save(sess, \"./models/fmnist/b_gm1_cifar10_10.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features\n",
      "\tstep 0: train loss 2.75515, train error 0.891429, valid loss 2.78114, valid error 0.902857\n",
      "\tstep 200: train loss 2.68834, train error 0.81, valid loss 2.59329, valid error 0.791429\n",
      "\tstep 400: train loss 2.15222, train error 0.671429, valid loss 2.20733, valid error 0.654286\n",
      "\tstep 600: train loss 2.07772, train error 0.611429, valid loss 2.14113, valid error 0.667143\n",
      "\tstep 800: train loss 2.08552, train error 0.65, valid loss 1.98873, valid error 0.581429\n",
      "\tstep 1000: train loss 1.70649, train error 0.498571, valid loss 1.70758, valid error 0.521429\n",
      "\tstep 1200: train loss 2.07469, train error 0.641429, valid loss 1.91971, valid error 0.61\n",
      "\tstep 1400: train loss 1.89246, train error 0.561429, valid loss 1.89179, valid error 0.565714\n",
      "\tstep 1600: train loss 1.64855, train error 0.5, valid loss 1.66273, valid error 0.517143\n",
      "\tstep 1800: train loss 2.36113, train error 0.685714, valid loss 2.13621, valid error 0.644286\n",
      "\tstep 2000: train loss 2.03307, train error 0.618571, valid loss 1.90479, valid error 0.574286\n",
      "\tstep 2200: train loss 1.59969, train error 0.515714, valid loss 1.61578, valid error 0.498571\n",
      "\tstep 2400: train loss 1.72835, train error 0.5, valid loss 1.64851, valid error 0.542857\n",
      "\tstep 2600: train loss 1.60493, train error 0.504286, valid loss 1.5573, valid error 0.505714\n",
      "\tstep 2800: train loss 1.56647, train error 0.465714, valid loss 1.27972, valid error 0.38\n",
      "\tstep 3000: train loss 1.43396, train error 0.471429, valid loss 1.4034, valid error 0.441429\n",
      "\tstep 3200: train loss 1.41659, train error 0.487143, valid loss 1.44437, valid error 0.475714\n",
      "\tstep 3400: train loss 1.33417, train error 0.424286, valid loss 1.44952, valid error 0.451429\n",
      "\tstep 3600: train loss 1.12191, train error 0.352857, valid loss 1.12585, valid error 0.361429\n",
      "\tstep 3800: train loss 1.35375, train error 0.437143, valid loss 1.20914, valid error 0.382857\n",
      "\tstep 4000: train loss 1.1577, train error 0.365714, valid loss 1.14295, valid error 0.35\n",
      "\tstep 4200: train loss 1.08073, train error 0.344286, valid loss 1.10554, valid error 0.33\n",
      "\tstep 4400: train loss 1.18589, train error 0.39, valid loss 1.20808, valid error 0.41\n",
      "\tstep 4600: train loss 1.14584, train error 0.364286, valid loss 1.12897, valid error 0.365714\n",
      "\tstep 4800: train loss 1.11055, train error 0.367143, valid loss 1.03817, valid error 0.357143\n",
      "\tstep 5000: train loss 0.978636, train error 0.317143, valid loss 0.982587, valid error 0.311429\n",
      "\tstep 5200: train loss 1.46747, train error 0.451429, valid loss 1.40962, valid error 0.458571\n",
      "\tstep 5400: train loss 1.10332, train error 0.364286, valid loss 1.05374, valid error 0.348571\n",
      "\tstep 5600: train loss 0.879801, train error 0.3, valid loss 0.968757, valid error 0.317143\n",
      "\tstep 5800: train loss 1.01764, train error 0.341429, valid loss 1.03337, valid error 0.355714\n",
      "\tstep 6000: train loss 1.01046, train error 0.321429, valid loss 0.96773, valid error 0.27\n",
      "\tstep 6200: train loss 1.03005, train error 0.361429, valid loss 0.97263, valid error 0.321429\n",
      "\tstep 6400: train loss 0.974206, train error 0.324286, valid loss 0.954944, valid error 0.325714\n",
      "\tstep 6600: train loss 0.872884, train error 0.292857, valid loss 0.86698, valid error 0.284286\n",
      "\tstep 6800: train loss 0.926713, train error 0.292857, valid loss 0.852754, valid error 0.268571\n",
      "\tstep 7000: train loss 0.916652, train error 0.314286, valid loss 0.884458, valid error 0.284286\n",
      "\tstep 7200: train loss 0.85317, train error 0.271429, valid loss 0.85041, valid error 0.292857\n",
      "\tstep 7400: train loss 0.838346, train error 0.288571, valid loss 0.805449, valid error 0.27\n",
      "\tstep 7600: train loss 0.906641, train error 0.32, valid loss 0.963779, valid error 0.31\n",
      "\tstep 7800: train loss 0.987819, train error 0.331429, valid loss 0.914663, valid error 0.308571\n",
      "\tstep 8000: train loss 0.731556, train error 0.238571, valid loss 0.852449, valid error 0.3\n",
      "\tstep 8200: train loss 0.889769, train error 0.311429, valid loss 0.852932, valid error 0.274286\n",
      "\tstep 8400: train loss 0.643301, train error 0.198571, valid loss 0.723251, valid error 0.251429\n",
      "\tstep 8600: train loss 0.717735, train error 0.224286, valid loss 0.717426, valid error 0.24\n",
      "\tstep 8800: train loss 0.910768, train error 0.29, valid loss 0.83465, valid error 0.264286\n",
      "\tstep 9000: train loss 1.37904, train error 0.42, valid loss 1.27963, valid error 0.391429\n",
      "\tstep 9200: train loss 0.874593, train error 0.277143, valid loss 0.819601, valid error 0.28\n",
      "\tstep 9400: train loss 0.668215, train error 0.227143, valid loss 0.714867, valid error 0.247143\n",
      "\tstep 9600: train loss 0.825287, train error 0.288571, valid loss 0.802342, valid error 0.271429\n",
      "\tstep 9800: train loss 0.701608, train error 0.242857, valid loss 0.721596, valid error 0.23\n",
      "\tstep 10000: train loss 0.803751, train error 0.28, valid loss 0.799106, valid error 0.261429\n",
      "\tstep 10200: train loss 0.67, train error 0.222857, valid loss 0.778325, valid error 0.261429\n",
      "\tstep 10400: train loss 0.71603, train error 0.217143, valid loss 0.74511, valid error 0.257143\n",
      "\tstep 10600: train loss 0.692562, train error 0.247143, valid loss 0.709617, valid error 0.215714\n",
      "\tstep 10800: train loss 0.735107, train error 0.247143, valid loss 0.762093, valid error 0.24\n",
      "\tstep 11000: train loss 0.661974, train error 0.212857, valid loss 0.620136, valid error 0.208571\n",
      "\tstep 11200: train loss 0.956046, train error 0.307143, valid loss 0.961967, valid error 0.308571\n",
      "\tstep 11400: train loss 0.739266, train error 0.264286, valid loss 0.736121, valid error 0.247143\n",
      "\tstep 11600: train loss 0.710466, train error 0.238571, valid loss 0.751398, valid error 0.251429\n",
      "\tstep 11800: train loss 0.661628, train error 0.208571, valid loss 0.716048, valid error 0.238571\n",
      "\tstep 12000: train loss 0.674133, train error 0.218571, valid loss 0.700917, valid error 0.237143\n",
      "\tstep 12200: train loss 0.635058, train error 0.215714, valid loss 0.720744, valid error 0.237143\n",
      "\tstep 12400: train loss 0.721131, train error 0.25, valid loss 0.760453, valid error 0.22\n",
      "\tstep 12600: train loss 0.575092, train error 0.191429, valid loss 0.688057, valid error 0.22\n",
      "\tstep 12800: train loss 0.622634, train error 0.2, valid loss 0.662384, valid error 0.225714\n",
      "\tstep 13000: train loss 0.596787, train error 0.211429, valid loss 0.625048, valid error 0.205714\n",
      "\tstep 13200: train loss 0.911956, train error 0.311429, valid loss 0.903711, valid error 0.3\n",
      "\tstep 13400: train loss 0.757255, train error 0.254286, valid loss 0.784854, valid error 0.261429\n",
      "\tstep 13600: train loss 0.625174, train error 0.208571, valid loss 0.648222, valid error 0.201429\n",
      "\tstep 13800: train loss 0.626493, train error 0.214286, valid loss 0.750553, valid error 0.25\n",
      "\tstep 14000: train loss 0.605825, train error 0.197143, valid loss 0.701444, valid error 0.26\n",
      "\tstep 14200: train loss 0.678189, train error 0.224286, valid loss 0.73806, valid error 0.245714\n",
      "\tstep 14400: train loss 0.553976, train error 0.194286, valid loss 0.614546, valid error 0.2\n",
      "\tstep 14600: train loss 0.536974, train error 0.172857, valid loss 0.594167, valid error 0.18\n",
      "\tstep 14800: train loss 0.625628, train error 0.207143, valid loss 0.705966, valid error 0.234286\n",
      "\tstep 15000: train loss 0.62393, train error 0.19, valid loss 0.696521, valid error 0.227143\n",
      "\tstep 15200: train loss 0.659305, train error 0.224286, valid loss 0.69092, valid error 0.235714\n",
      "\tstep 15400: train loss 0.529961, train error 0.171429, valid loss 0.620076, valid error 0.2\n",
      "\tstep 15600: train loss 0.563169, train error 0.184286, valid loss 0.494366, valid error 0.19\n",
      "\tstep 15800: train loss 0.592506, train error 0.19, valid loss 0.668791, valid error 0.23\n",
      "\tstep 16000: train loss 0.565679, train error 0.174286, valid loss 0.637903, valid error 0.212857\n",
      "\tstep 16200: train loss 0.657897, train error 0.237143, valid loss 0.75576, valid error 0.232857\n",
      "\tstep 16400: train loss 0.69864, train error 0.231429, valid loss 0.744161, valid error 0.238571\n",
      "\tstep 16600: train loss 0.591108, train error 0.192857, valid loss 0.678338, valid error 0.222857\n",
      "\tstep 16800: train loss 0.703907, train error 0.232857, valid loss 0.649391, valid error 0.218571\n",
      "\tstep 17000: train loss 0.670736, train error 0.215714, valid loss 0.731487, valid error 0.231429\n",
      "\tstep 17200: train loss 0.64492, train error 0.22, valid loss 0.787109, valid error 0.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tstep 17400: train loss 0.522999, train error 0.158571, valid loss 0.579793, valid error 0.178571\n",
      "\tstep 17600: train loss 0.58358, train error 0.191429, valid loss 0.719368, valid error 0.227143\n",
      "\tstep 17800: train loss 0.576787, train error 0.18, valid loss 0.627493, valid error 0.208571\n",
      "\tstep 18000: train loss 0.654057, train error 0.218571, valid loss 0.766172, valid error 0.264286\n",
      "\tstep 18200: train loss 0.500362, train error 0.158571, valid loss 0.620328, valid error 0.188571\n",
      "\tstep 18400: train loss 0.59984, train error 0.192857, valid loss 0.599521, valid error 0.175714\n",
      "\tstep 18600: train loss 0.566908, train error 0.188571, valid loss 0.665561, valid error 0.215714\n",
      "\tstep 18800: train loss 0.568878, train error 0.187143, valid loss 0.865743, valid error 0.26\n",
      "\tstep 19000: train loss 0.711188, train error 0.24, valid loss 0.759984, valid error 0.232857\n",
      "\tstep 19200: train loss 0.738255, train error 0.235714, valid loss 0.742643, valid error 0.234286\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ddeb54ca8205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./models/fmnist/b_gm1_cifar10_10.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/similarity_experiments/learn.py\u001b[0m in \u001b[0;36mtrain_features\u001b[0;34m(sess, feature_model, samplers, num_steps, keep_prob, f_params)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             train_loss, train_acc = sess.run([feature_model.loss, feature_model.acc], \n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "f, f_params = get_feature_model(feature_model=GCNNMedium1, settings=Baseline_Settings,\n",
    "                                num_features=10, data_format=[32, 32, 3],\n",
    "                                f_lr=0.05, f_reg=0.001, f_scope=\"b_gm1_cifar10_10\")\n",
    "fs = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"b_gm1_cifar10_10\"))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_features(sess=sess, feature_model=f, samplers=s, num_steps=40000, keep_prob=0.5, f_params=f_params)\n",
    "    fs.save(sess, \"./models/fmnist/b_gm1_cifar10_10.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features\n",
      "\tstep 0: train loss 2.74258, train error 0.914286, valid loss 2.74794, valid error 0.908571\n",
      "\tstep 200: train loss 2.96569, train error 0.79, valid loss 2.86812, valid error 0.86\n",
      "\tstep 400: train loss 1.81994, train error 0.525714, valid loss 1.85178, valid error 0.542857\n",
      "\tstep 600: train loss 1.69165, train error 0.462857, valid loss 1.68865, valid error 0.48\n",
      "\tstep 800: train loss 1.58198, train error 0.477143, valid loss 1.55927, valid error 0.434286\n",
      "\tstep 1000: train loss 1.52999, train error 0.442857, valid loss 1.46456, valid error 0.408571\n",
      "\tstep 1200: train loss 1.4177, train error 0.388571, valid loss 1.43536, valid error 0.405714\n",
      "\tstep 1400: train loss 1.40256, train error 0.378571, valid loss 1.39005, valid error 0.398571\n",
      "\tstep 1600: train loss 1.35033, train error 0.387143, valid loss 1.36271, valid error 0.375714\n",
      "\tstep 1800: train loss 1.18607, train error 0.338571, valid loss 1.34999, valid error 0.41\n",
      "\tstep 2000: train loss 1.20833, train error 0.352857, valid loss 1.20522, valid error 0.32\n",
      "\tstep 2200: train loss 1.15293, train error 0.341429, valid loss 1.1506, valid error 0.311429\n",
      "\tstep 2400: train loss 1.06484, train error 0.298571, valid loss 1.13942, valid error 0.308571\n",
      "\tstep 2600: train loss 0.923764, train error 0.268571, valid loss 1.01344, valid error 0.271429\n",
      "\tstep 2800: train loss 1.01676, train error 0.291429, valid loss 1.07865, valid error 0.314286\n",
      "\tstep 3000: train loss 1.04543, train error 0.304286, valid loss 1.06373, valid error 0.29\n",
      "\tstep 3200: train loss 0.837702, train error 0.227143, valid loss 0.968493, valid error 0.285714\n",
      "\tstep 3400: train loss 0.818914, train error 0.238571, valid loss 0.993367, valid error 0.27\n",
      "\tstep 3600: train loss 0.95615, train error 0.268571, valid loss 1.01631, valid error 0.291429\n",
      "\tstep 3800: train loss 0.787207, train error 0.201429, valid loss 0.808767, valid error 0.234286\n",
      "\tstep 4000: train loss 0.793398, train error 0.212857, valid loss 0.839805, valid error 0.242857\n",
      "\tstep 4200: train loss 0.783619, train error 0.231429, valid loss 0.897602, valid error 0.262857\n",
      "\tstep 4400: train loss 0.723353, train error 0.214286, valid loss 0.794339, valid error 0.234286\n",
      "\tstep 4600: train loss 0.840146, train error 0.25, valid loss 0.823951, valid error 0.225714\n",
      "\tstep 4800: train loss 0.72377, train error 0.211429, valid loss 0.842377, valid error 0.252857\n",
      "\tstep 5000: train loss 0.699939, train error 0.208571, valid loss 0.869521, valid error 0.24\n",
      "\tstep 5200: train loss 0.588724, train error 0.147143, valid loss 0.690792, valid error 0.191429\n",
      "\tstep 5400: train loss 0.676856, train error 0.191429, valid loss 0.614971, valid error 0.197143\n",
      "\tstep 5600: train loss 0.559801, train error 0.167143, valid loss 0.683288, valid error 0.192857\n",
      "\tstep 5800: train loss 0.720792, train error 0.227143, valid loss 0.83432, valid error 0.254286\n",
      "\tstep 6000: train loss 0.618545, train error 0.184286, valid loss 0.682162, valid error 0.188571\n",
      "\tstep 6200: train loss 0.525174, train error 0.135714, valid loss 0.720891, valid error 0.195714\n",
      "\tstep 6400: train loss 0.56817, train error 0.164286, valid loss 0.752718, valid error 0.211429\n",
      "\tstep 6600: train loss 0.512845, train error 0.128571, valid loss 0.664591, valid error 0.19\n",
      "\tstep 6800: train loss 0.444522, train error 0.131429, valid loss 0.598182, valid error 0.18\n",
      "\tstep 7000: train loss 0.494753, train error 0.137143, valid loss 0.682527, valid error 0.214286\n",
      "\tstep 7200: train loss 0.510354, train error 0.15, valid loss 0.646936, valid error 0.204286\n",
      "\tstep 7400: train loss 0.530923, train error 0.14, valid loss 0.719769, valid error 0.198571\n",
      "\tstep 7600: train loss 0.433287, train error 0.108571, valid loss 0.626773, valid error 0.168571\n",
      "\tstep 7800: train loss 0.340884, train error 0.0942857, valid loss 0.550504, valid error 0.162857\n",
      "\tstep 8000: train loss 0.370037, train error 0.101429, valid loss 0.588247, valid error 0.184286\n",
      "\tstep 8200: train loss 0.490216, train error 0.147143, valid loss 0.582517, valid error 0.21\n",
      "\tstep 8400: train loss 0.4011, train error 0.0957143, valid loss 0.645844, valid error 0.2\n",
      "\tstep 8600: train loss 0.460816, train error 0.134286, valid loss 0.621596, valid error 0.195714\n",
      "\tstep 8800: train loss 0.413074, train error 0.128571, valid loss 0.622513, valid error 0.187143\n",
      "\tstep 9000: train loss 0.406314, train error 0.112857, valid loss 0.609994, valid error 0.19\n",
      "\tstep 9200: train loss 0.336995, train error 0.102857, valid loss 0.578579, valid error 0.177143\n",
      "\tstep 9400: train loss 0.260071, train error 0.0471429, valid loss 0.536473, valid error 0.154286\n",
      "\tstep 9600: train loss 0.347721, train error 0.0957143, valid loss 0.613187, valid error 0.187143\n",
      "\tstep 9800: train loss 0.319265, train error 0.0714286, valid loss 0.78881, valid error 0.23\n",
      "\tstep 10000: train loss 0.330706, train error 0.0885714, valid loss 0.588708, valid error 0.168571\n",
      "\tstep 10200: train loss 0.404344, train error 0.121429, valid loss 0.686873, valid error 0.212857\n",
      "\tstep 10400: train loss 0.383908, train error 0.118571, valid loss 0.691965, valid error 0.197143\n",
      "\tstep 10600: train loss 0.27236, train error 0.06, valid loss 0.618102, valid error 0.184286\n",
      "\tstep 10800: train loss 0.261575, train error 0.0542857, valid loss 0.542662, valid error 0.161429\n",
      "\tstep 11000: train loss 0.252129, train error 0.0585715, valid loss 0.492243, valid error 0.135714\n",
      "\tstep 11200: train loss 0.258415, train error 0.0585715, valid loss 0.568995, valid error 0.181429\n",
      "\tstep 11400: train loss 0.257235, train error 0.0514286, valid loss 0.396529, valid error 0.09\n",
      "\tstep 11600: train loss 0.225971, train error 0.04, valid loss 0.571396, valid error 0.162857\n",
      "\tstep 11800: train loss 0.284617, train error 0.0671428, valid loss 0.634477, valid error 0.16\n",
      "\tstep 12000: train loss 0.228723, train error 0.0428572, valid loss 0.565174, valid error 0.155714\n",
      "\tstep 12200: train loss 0.206183, train error 0.0385714, valid loss 0.528586, valid error 0.145714\n",
      "\tstep 12400: train loss 0.218961, train error 0.0285714, valid loss 0.470432, valid error 0.148571\n",
      "\tstep 12600: train loss 0.283454, train error 0.0742857, valid loss 0.636099, valid error 0.194286\n",
      "\tstep 12800: train loss 0.211869, train error 0.0428572, valid loss 0.563882, valid error 0.164286\n",
      "\tstep 13000: train loss 0.231416, train error 0.0442857, valid loss 0.51597, valid error 0.14\n",
      "\tstep 13200: train loss 0.204219, train error 0.0285714, valid loss 0.500662, valid error 0.147143\n",
      "\tstep 13400: train loss 0.208441, train error 0.0385714, valid loss 0.550504, valid error 0.162857\n",
      "\tstep 13600: train loss 0.236382, train error 0.0485714, valid loss 0.550592, valid error 0.162857\n",
      "\tstep 13800: train loss 0.23103, train error 0.05, valid loss 0.581354, valid error 0.15\n",
      "\tstep 14000: train loss 0.190871, train error 0.0242857, valid loss 0.488125, valid error 0.154286\n",
      "\tstep 14200: train loss 0.176647, train error 0.0228571, valid loss 0.5546, valid error 0.172857\n",
      "\tstep 14400: train loss 0.174179, train error 0.0157143, valid loss 0.580024, valid error 0.157143\n",
      "\tstep 14600: train loss 0.1916, train error 0.0342857, valid loss 0.498335, valid error 0.12\n",
      "\tstep 14800: train loss 0.183675, train error 0.0271429, valid loss 0.534751, valid error 0.158571\n",
      "\tstep 15000: train loss 0.19454, train error 0.03, valid loss 0.595579, valid error 0.171429\n",
      "\tstep 15200: train loss 0.201269, train error 0.0314286, valid loss 0.538603, valid error 0.161429\n",
      "\tstep 15400: train loss 0.1738, train error 0.0185714, valid loss 0.565405, valid error 0.141429\n",
      "\tstep 15600: train loss 0.170123, train error 0.0185714, valid loss 0.585314, valid error 0.168571\n",
      "\tstep 15800: train loss 0.161511, train error 0.02, valid loss 0.503843, valid error 0.142857\n",
      "\tstep 16000: train loss 0.17806, train error 0.0171428, valid loss 0.537548, valid error 0.145714\n",
      "\tstep 16200: train loss 0.149946, train error 0.00999999, valid loss 0.476487, valid error 0.11\n",
      "\tstep 16400: train loss 0.171045, train error 0.0214286, valid loss 0.510724, valid error 0.132857\n",
      "\tstep 16600: train loss 0.17044, train error 0.0185714, valid loss 0.603876, valid error 0.16\n",
      "\tstep 16800: train loss 0.155181, train error 0.0142857, valid loss 0.499233, valid error 0.138571\n",
      "\tstep 17000: train loss 0.152161, train error 0.0114286, valid loss 0.620332, valid error 0.172857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tstep 17200: train loss 0.17013, train error 0.0185714, valid loss 0.503278, valid error 0.132857\n",
      "\tstep 17400: train loss 0.142976, train error 0.00428569, valid loss 0.498405, valid error 0.15\n",
      "\tstep 17600: train loss 0.13248, train error 0.00428569, valid loss 0.516911, valid error 0.134286\n",
      "\tstep 17800: train loss 0.142794, train error 0.00999999, valid loss 0.445893, valid error 0.14\n",
      "\tstep 18000: train loss 0.143444, train error 0.0114286, valid loss 0.542261, valid error 0.138571\n",
      "\tstep 18200: train loss 0.137962, train error 0.00285715, valid loss 0.584787, valid error 0.15\n",
      "\tstep 18400: train loss 0.146153, train error 0.0128571, valid loss 0.576165, valid error 0.152857\n",
      "\tstep 18600: train loss 0.153296, train error 0.0128571, valid loss 0.595946, valid error 0.168571\n",
      "\tstep 18800: train loss 0.137106, train error 0.00428569, valid loss 0.434178, valid error 0.114286\n",
      "\tstep 19000: train loss 0.14529, train error 0.0142857, valid loss 0.577088, valid error 0.161429\n",
      "\tstep 19200: train loss 0.13032, train error 0.0057143, valid loss 0.447026, valid error 0.127143\n",
      "\tstep 19400: train loss 0.13267, train error 0.00714284, valid loss 0.569963, valid error 0.12\n",
      "\tstep 19600: train loss 0.155153, train error 0.0157143, valid loss 0.547316, valid error 0.147143\n",
      "\tstep 19800: train loss 0.13254, train error 0.00714284, valid loss 0.558878, valid error 0.151429\n",
      "end training features // time elapsed: 4858.4800 s\n",
      "validation set error: 0.1544 // time elapsed: 1.1419 s\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "f, f_params = get_feature_model(feature_model=GCNNMedium1, settings=Baseline_Settings,\n",
    "                                num_features=10, data_format=[32, 32, 3],\n",
    "                                f_lr=0.04, f_reg=0.001, f_scope=\"b_gm1_cifar10_10\")\n",
    "fs = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"b_gm1_cifar10_10\"))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_features(sess=sess, feature_model=f, samplers=s, num_steps=20000, keep_prob=0.7, f_params=f_params)\n",
    "    fs.save(sess, \"./models/fmnist/b_gm1_cifar10_10.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = data; s=triplet_samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features\n",
      "\tstep 0: train loss 4.22928, train error 0.50625, valid loss 4.06296, valid error 0.47625\n",
      "\tstep 200: train loss 1.44731, train error 0.50875, valid loss 1.4229, valid error 0.47625\n",
      "\tstep 400: train loss 1.2556, train error 0.3975, valid loss 1.27005, valid error 0.4\n",
      "\tstep 600: train loss 1.18605, train error 0.35625, valid loss 1.20794, valid error 0.39875\n",
      "\tstep 800: train loss 1.11008, train error 0.3225, valid loss 1.1023, valid error 0.325\n",
      "\tstep 1000: train loss 1.017, train error 0.29875, valid loss 1.0466, valid error 0.3325\n",
      "\tstep 1200: train loss 1.0525, train error 0.325, valid loss 0.983855, valid error 0.3025\n",
      "\tstep 1400: train loss 0.978987, train error 0.29, valid loss 0.974904, valid error 0.31875\n",
      "\tstep 1600: train loss 0.911761, train error 0.30125, valid loss 0.976383, valid error 0.31375\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "f, f_params = get_feature_model(feature_model=GCNNLarge0, settings=Triplet_Hinge_Settings,\n",
    "                                num_features=10, data_format=[32, 32, 3],\n",
    "                                f_lr=0.04, f_reg=0.001, f_scope=\"f_gm1_cifar10_10\")\n",
    "fs = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"f_gm1_cifar10_10\"))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_features(sess=sess, feature_model=f, samplers=s, num_steps=20000, keep_prob=0.7, f_params=f_params)\n",
    "    fs.save(sess, \"./models/fmnist/f_gm1_cifar10_10.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
