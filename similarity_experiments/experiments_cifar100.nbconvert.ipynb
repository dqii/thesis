{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dqi/.conda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/dqi/.conda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from features.settings import Baseline_Settings, Pair_Hinge_Settings, Pair_Log_Settings, Triplet_Hinge_Settings, Triplet_Log_Settings\n",
    "from features.models import ConvModelSmall, ConvModelMedium, ConvModelLarge\n",
    "from features.models import GCNNModelSmall, GCNNModelMedium, GCNNModelLarge\n",
    "from classes.models import LinearClassifier\n",
    "from datasets import load_cifar100\n",
    "from sklearn.svm import LinearSVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-100 loaded in 100 seconds\n"
     ]
    }
   ],
   "source": [
    "data, samplers, pair_samplers, triplet_samplers = load_cifar100(augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(feature_model, settings, data, num_features, num_classes, feature_samplers, classification_samplers,\n",
    "               f_num_steps, f_lr, f_keep_prob, f_reg, c_num_steps, c_lr, c_reg):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    f_train, f_valid, f_test = feature_samplers\n",
    "    c_train, c_valid, c_test = classification_samplers\n",
    "    (x_train, y_train), (x_valid, y_valid), (x_test, y_test) = data\n",
    "    _, H, W, C = x_train.shape\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, H, W, C])\n",
    "    y = tf.placeholder(tf.int64, shape=[None])    \n",
    "    dropout = tf.placeholder(tf.float32)\n",
    "    training = tf.placeholder(tf.bool)\n",
    "    f_model = feature_model(x=x, y=y, settings=settings, num_chan=C, num_features=num_features, \n",
    "              lr=f_lr, reg=f_reg, dropout=dropout, training=training)\n",
    "    \n",
    "    features = tf.placeholder(tf.float32, shape=[None, num_features])\n",
    "    c_model = LinearClassifier(x=features, y=y, num_features=num_features, num_classes=num_features, \n",
    "                               lr=c_lr, reg=c_reg)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        print(\"begin training features // num_features: %g, lr: %g, reg: %g, dropout: %g\" %(num_features, f_lr, f_reg, f_keep_prob))\n",
    "        train_time = time.time()\n",
    "        for step in range(f_num_steps):        \n",
    "            x_, y_ = f_train.sample(700)\n",
    "            sess.run(f_model.optimize, feed_dict={x:x_, y:y_, dropout:f_keep_prob, training:True})     \n",
    "            if step % 1000 == 0:\n",
    "                train_loss, train_acc = sess.run([f_model.loss, f_model.acc], \n",
    "                                                 feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "                print(\"\\tstep %d: train loss %g, train error %g\"%(step, train_loss, 1 - train_acc))  \n",
    "        train_time = time.time() - train_time\n",
    "        print(\"end training features // time elapsed: %.4f s\"%(train_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        x_, y_ = f_valid.sample(1000)\n",
    "        test_error = 1 - sess.run(f_model.acc, feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"validation set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        x_, y_ = f_test.sample(1000)\n",
    "        test_error = 1 - sess.run(f_model.acc, feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"test set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        print(\"begin training classifier\")\n",
    "        train_time = time.time()\n",
    "        for step in range(c_num_steps):        \n",
    "            x_, y_ = c_train.sample(700)\n",
    "            features_ = sess.run(f_model.features, feed_dict={x:x_, dropout:1.0, training:False})\n",
    "            sess.run(c_model.optimize, feed_dict={features:features_, y:y_, x:x_, dropout:1.0, training:False})\n",
    "            if step % 1000 == 0:\n",
    "                train_loss, train_acc = sess.run([c_model.loss, c_model.acc], feed_dict={features:features_, y:y_})\n",
    "                print(\"\\tstep %d: train loss %g, train error %g\"%(step, train_loss, 1 - train_acc))  \n",
    "        train_time = time.time() - train_time\n",
    "        print(\"end training classifier // time elapsed: %.4f s\"%(train_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        features_ = sess.run(f_model.features, feed_dict={x:x_valid, dropout:1.0, training:False})\n",
    "        test_error = 1 - sess.run(c_model.acc, feed_dict={features:features_, y:y_valid})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"validation set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        features_ = sess.run(f_model.features, feed_dict={x:x_test, dropout:1.0, training:False})\n",
    "        test_error = 1 - sess.run(c_model.acc, feed_dict={features:features_, y:y_test})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"test set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 100, lr: 0.005, reg: 0.001, dropout: 0.6\n",
      "\tstep 0: train loss 5.19729, train error 0.991429\n",
      "\tstep 1000: train loss 4.93217, train error 0.954286\n",
      "\tstep 2000: train loss 4.79396, train error 0.935714\n",
      "\tstep 3000: train loss 4.57935, train error 0.91\n",
      "\tstep 4000: train loss 4.37973, train error 0.894286\n",
      "\tstep 5000: train loss 4.35247, train error 0.882857\n",
      "\tstep 6000: train loss 4.25342, train error 0.874286\n",
      "\tstep 7000: train loss 4.07276, train error 0.837143\n",
      "\tstep 8000: train loss 4.08911, train error 0.845714\n",
      "\tstep 9000: train loss 3.93279, train error 0.83\n",
      "\tstep 10000: train loss 3.86516, train error 0.827143\n",
      "\tstep 11000: train loss 3.82155, train error 0.798571\n",
      "\tstep 12000: train loss 3.7176, train error 0.804286\n",
      "\tstep 13000: train loss 3.66423, train error 0.778571\n",
      "\tstep 14000: train loss 3.63825, train error 0.777143\n",
      "\tstep 15000: train loss 3.58227, train error 0.777143\n",
      "\tstep 16000: train loss 3.5453, train error 0.771429\n",
      "\tstep 17000: train loss 3.52783, train error 0.791429\n",
      "\tstep 18000: train loss 3.50425, train error 0.781429\n",
      "\tstep 19000: train loss 3.35277, train error 0.75\n",
      "\tstep 20000: train loss 3.33098, train error 0.741429\n",
      "\tstep 21000: train loss 3.33998, train error 0.75\n",
      "\tstep 22000: train loss 3.25393, train error 0.738571\n",
      "\tstep 23000: train loss 3.18427, train error 0.722857\n",
      "\tstep 24000: train loss 3.18522, train error 0.712857\n",
      "\tstep 25000: train loss 3.09514, train error 0.67\n",
      "\tstep 26000: train loss 3.13759, train error 0.704286\n",
      "\tstep 27000: train loss 2.9912, train error 0.69\n",
      "\tstep 28000: train loss 2.95269, train error 0.694286\n",
      "\tstep 29000: train loss 2.95603, train error 0.691429\n",
      "\tstep 30000: train loss 3.0425, train error 0.681429\n",
      "\tstep 31000: train loss 2.89466, train error 0.658571\n",
      "\tstep 32000: train loss 2.90448, train error 0.665714\n",
      "\tstep 33000: train loss 2.92366, train error 0.665714\n",
      "\tstep 34000: train loss 2.82657, train error 0.675714\n",
      "\tstep 35000: train loss 2.82156, train error 0.647143\n",
      "\tstep 36000: train loss 2.88768, train error 0.66\n",
      "\tstep 37000: train loss 2.7424, train error 0.625714\n",
      "\tstep 38000: train loss 2.7307, train error 0.642857\n",
      "\tstep 39000: train loss 2.67395, train error 0.637143\n",
      "\tstep 40000: train loss 2.60196, train error 0.614286\n",
      "\tstep 41000: train loss 2.6237, train error 0.622857\n",
      "\tstep 42000: train loss 2.46575, train error 0.584286\n",
      "\tstep 43000: train loss 2.68978, train error 0.637143\n",
      "\tstep 44000: train loss 2.62998, train error 0.628571\n",
      "\tstep 45000: train loss 2.63178, train error 0.651429\n",
      "\tstep 46000: train loss 2.4838, train error 0.591429\n",
      "\tstep 47000: train loss 2.52091, train error 0.581429\n",
      "\tstep 48000: train loss 2.49186, train error 0.564286\n",
      "\tstep 49000: train loss 2.45867, train error 0.59\n",
      "\tstep 50000: train loss 2.39956, train error 0.55\n",
      "\tstep 51000: train loss 2.40452, train error 0.575714\n",
      "\tstep 52000: train loss 2.42065, train error 0.584286\n",
      "\tstep 53000: train loss 2.27668, train error 0.541429\n",
      "\tstep 54000: train loss 2.31788, train error 0.557143\n",
      "\tstep 55000: train loss 2.32173, train error 0.548571\n",
      "\tstep 56000: train loss 2.28258, train error 0.545714\n",
      "\tstep 57000: train loss 2.27358, train error 0.541429\n",
      "\tstep 58000: train loss 2.28456, train error 0.55\n",
      "\tstep 59000: train loss 2.26878, train error 0.56\n",
      "\tstep 60000: train loss 2.2413, train error 0.525714\n",
      "\tstep 61000: train loss 2.11835, train error 0.487143\n",
      "\tstep 62000: train loss 2.16896, train error 0.52\n",
      "\tstep 63000: train loss 2.12675, train error 0.505714\n",
      "\tstep 64000: train loss 2.14589, train error 0.524286\n",
      "\tstep 65000: train loss 2.19002, train error 0.537143\n",
      "\tstep 66000: train loss 2.1308, train error 0.487143\n",
      "\tstep 67000: train loss 2.0561, train error 0.487143\n",
      "\tstep 68000: train loss 2.06893, train error 0.485714\n",
      "\tstep 69000: train loss 2.02362, train error 0.465714\n",
      "end training features // time elapsed: 3756.9575 s\n",
      "validation set error: 0.5480 // time elapsed: 0.0799 s\n",
      "test set error: 0.5520 // time elapsed: 0.0299 s\n",
      "begin training classifier\n",
      "\tstep 0: train loss 8.21491, train error 0.997143\n",
      "\tstep 1000: train loss 2.71566, train error 0.574286\n",
      "\tstep 2000: train loss 2.44986, train error 0.551429\n",
      "\tstep 3000: train loss 2.38231, train error 0.554286\n",
      "\tstep 4000: train loss 2.2822, train error 0.498571\n",
      "\tstep 5000: train loss 2.09653, train error 0.482857\n",
      "\tstep 6000: train loss 2.14004, train error 0.485714\n",
      "\tstep 7000: train loss 2.22336, train error 0.501429\n",
      "\tstep 8000: train loss 2.10096, train error 0.487143\n",
      "\tstep 9000: train loss 2.09152, train error 0.488571\n",
      "\tstep 10000: train loss 2.0017, train error 0.48\n",
      "\tstep 11000: train loss 1.97772, train error 0.461429\n",
      "\tstep 12000: train loss 2.04219, train error 0.471429\n",
      "\tstep 13000: train loss 1.97623, train error 0.502857\n",
      "\tstep 14000: train loss 2.00034, train error 0.488571\n",
      "\tstep 15000: train loss 1.92581, train error 0.494286\n",
      "\tstep 16000: train loss 1.90015, train error 0.491429\n",
      "\tstep 17000: train loss 1.88162, train error 0.455714\n",
      "\tstep 18000: train loss 1.94305, train error 0.48\n",
      "\tstep 19000: train loss 1.97408, train error 0.468571\n",
      "\tstep 20000: train loss 1.89354, train error 0.468571\n",
      "\tstep 21000: train loss 1.92909, train error 0.5\n",
      "\tstep 22000: train loss 1.97071, train error 0.514286\n",
      "\tstep 23000: train loss 1.94402, train error 0.502857\n",
      "\tstep 24000: train loss 1.97304, train error 0.5\n",
      "\tstep 25000: train loss 1.84307, train error 0.454286\n",
      "\tstep 26000: train loss 1.81987, train error 0.454286\n",
      "\tstep 27000: train loss 1.88834, train error 0.485714\n",
      "\tstep 28000: train loss 1.84797, train error 0.488571\n",
      "\tstep 29000: train loss 1.94687, train error 0.501429\n",
      "end training classifier // time elapsed: 1247.7841 s\n",
      "validation set error: 0.5468 // time elapsed: 0.3172 s\n",
      "test set error: 0.5454 // time elapsed: 0.4949 s\n"
     ]
    }
   ],
   "source": [
    "test_model(feature_model=GCNNModelSmall, settings=Baseline_Settings, num_features=100, num_classes=100,\n",
    "           data=data, feature_samplers=samplers, classification_samplers=samplers,           \n",
    "           f_num_steps=70000, f_lr=0.005, f_keep_prob=0.6, f_reg=0.001, \n",
    "           c_num_steps=30000, c_lr=0.005, c_reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 100, lr: 0.005, reg: 0.001, dropout: 0.6\n",
      "\tstep 0: train loss 1.64034, train error 0.535714\n",
      "\tstep 1000: train loss 1.49851, train error 0.422857\n",
      "\tstep 2000: train loss 1.42179, train error 0.368571\n",
      "\tstep 3000: train loss 1.29873, train error 0.344286\n",
      "\tstep 4000: train loss 1.27121, train error 0.342857\n",
      "\tstep 5000: train loss 1.20242, train error 0.324286\n",
      "\tstep 6000: train loss 1.22536, train error 0.347143\n",
      "\tstep 7000: train loss 1.16909, train error 0.321429\n",
      "\tstep 8000: train loss 1.15804, train error 0.335714\n",
      "\tstep 9000: train loss 1.13623, train error 0.325714\n",
      "\tstep 10000: train loss 1.11869, train error 0.315714\n",
      "\tstep 11000: train loss 1.07868, train error 0.311429\n",
      "\tstep 12000: train loss 1.02552, train error 0.29\n",
      "\tstep 13000: train loss 1.09016, train error 0.321429\n",
      "\tstep 14000: train loss 1.08744, train error 0.32\n",
      "\tstep 15000: train loss 1.03725, train error 0.302857\n",
      "\tstep 16000: train loss 1.04683, train error 0.318571\n",
      "\tstep 17000: train loss 1.01106, train error 0.288571\n",
      "\tstep 18000: train loss 1.01888, train error 0.302857\n",
      "\tstep 19000: train loss 1.0219, train error 0.325714\n",
      "\tstep 20000: train loss 0.982523, train error 0.292857\n",
      "\tstep 21000: train loss 0.967241, train error 0.305714\n",
      "\tstep 22000: train loss 0.94548, train error 0.287143\n",
      "\tstep 23000: train loss 0.938636, train error 0.332857\n",
      "\tstep 24000: train loss 0.933099, train error 0.311429\n",
      "\tstep 25000: train loss 0.93009, train error 0.3\n",
      "\tstep 26000: train loss 0.92525, train error 0.311429\n",
      "\tstep 27000: train loss 0.906157, train error 0.288571\n",
      "\tstep 28000: train loss 0.949997, train error 0.304286\n",
      "\tstep 29000: train loss 0.902758, train error 0.302857\n",
      "\tstep 30000: train loss 0.878263, train error 0.282857\n",
      "\tstep 31000: train loss 0.84756, train error 0.284286\n",
      "\tstep 32000: train loss 0.816071, train error 0.274286\n",
      "\tstep 33000: train loss 0.777674, train error 0.24\n",
      "\tstep 34000: train loss 0.864257, train error 0.298571\n",
      "\tstep 35000: train loss 0.812866, train error 0.271429\n",
      "\tstep 36000: train loss 0.794249, train error 0.252857\n",
      "\tstep 37000: train loss 0.807544, train error 0.284286\n",
      "\tstep 38000: train loss 0.784533, train error 0.277143\n",
      "\tstep 39000: train loss 0.750353, train error 0.257143\n",
      "\tstep 40000: train loss 0.779241, train error 0.27\n",
      "\tstep 41000: train loss 0.75263, train error 0.244286\n",
      "\tstep 42000: train loss 0.778975, train error 0.285714\n",
      "\tstep 43000: train loss 0.747941, train error 0.255714\n",
      "\tstep 44000: train loss 0.735781, train error 0.242857\n",
      "\tstep 45000: train loss 0.771686, train error 0.278571\n",
      "\tstep 46000: train loss 0.761518, train error 0.281429\n",
      "\tstep 47000: train loss 0.711026, train error 0.252857\n",
      "\tstep 48000: train loss 0.718189, train error 0.254286\n",
      "\tstep 49000: train loss 0.690916, train error 0.237143\n",
      "\tstep 50000: train loss 0.712236, train error 0.254286\n",
      "\tstep 51000: train loss 0.732772, train error 0.267143\n",
      "\tstep 52000: train loss 0.692628, train error 0.247143\n",
      "\tstep 53000: train loss 0.694874, train error 0.252857\n",
      "\tstep 54000: train loss 0.67834, train error 0.251429\n",
      "\tstep 55000: train loss 0.61375, train error 0.217143\n",
      "\tstep 56000: train loss 0.668582, train error 0.238571\n",
      "\tstep 57000: train loss 0.673151, train error 0.248571\n",
      "\tstep 58000: train loss 0.61994, train error 0.205714\n",
      "\tstep 59000: train loss 0.641961, train error 0.237143\n",
      "\tstep 60000: train loss 0.595746, train error 0.21\n",
      "\tstep 61000: train loss 0.622211, train error 0.23\n",
      "\tstep 62000: train loss 0.654172, train error 0.255714\n",
      "\tstep 63000: train loss 0.587632, train error 0.22\n",
      "\tstep 64000: train loss 0.615444, train error 0.204286\n",
      "\tstep 65000: train loss 0.593305, train error 0.22\n",
      "\tstep 66000: train loss 0.604659, train error 0.224286\n",
      "\tstep 67000: train loss 0.607195, train error 0.222857\n",
      "\tstep 68000: train loss 0.564541, train error 0.204286\n",
      "\tstep 69000: train loss 0.603063, train error 0.228571\n",
      "end training features // time elapsed: 11653.3196 s\n",
      "validation set error: 0.2310 // time elapsed: 0.2370 s\n",
      "test set error: 0.2120 // time elapsed: 0.1710 s\n",
      "begin training classifier\n",
      "\tstep 0: train loss 5.11987, train error 0.988571\n",
      "\tstep 1000: train loss 5.01313, train error 0.981429\n",
      "\tstep 2000: train loss 4.93613, train error 0.971429\n",
      "\tstep 3000: train loss 4.84409, train error 0.938571\n",
      "\tstep 4000: train loss 4.77663, train error 0.934286\n",
      "\tstep 5000: train loss 4.72501, train error 0.934286\n",
      "\tstep 6000: train loss 4.65134, train error 0.905714\n",
      "\tstep 7000: train loss 4.59769, train error 0.92\n",
      "\tstep 8000: train loss 4.56607, train error 0.908571\n",
      "\tstep 9000: train loss 4.48903, train error 0.902857\n",
      "\tstep 10000: train loss 4.47362, train error 0.884286\n",
      "\tstep 11000: train loss 4.40772, train error 0.902857\n",
      "\tstep 12000: train loss 4.40371, train error 0.887143\n",
      "\tstep 13000: train loss 4.32971, train error 0.867143\n",
      "\tstep 14000: train loss 4.3334, train error 0.882857\n",
      "\tstep 15000: train loss 4.26009, train error 0.885714\n",
      "\tstep 16000: train loss 4.24012, train error 0.867143\n",
      "\tstep 17000: train loss 4.1886, train error 0.865714\n",
      "\tstep 18000: train loss 4.20108, train error 0.875714\n",
      "\tstep 19000: train loss 4.16775, train error 0.87\n",
      "\tstep 20000: train loss 4.1225, train error 0.861429\n",
      "\tstep 21000: train loss 4.1077, train error 0.831429\n",
      "\tstep 22000: train loss 4.09715, train error 0.842857\n",
      "\tstep 23000: train loss 4.07721, train error 0.871429\n",
      "\tstep 24000: train loss 4.04312, train error 0.854286\n",
      "\tstep 25000: train loss 4.00863, train error 0.837143\n",
      "\tstep 26000: train loss 4.04099, train error 0.85\n",
      "\tstep 27000: train loss 4.02992, train error 0.865714\n",
      "\tstep 28000: train loss 4.02465, train error 0.861429\n",
      "\tstep 29000: train loss 3.9824, train error 0.834286\n",
      "end training classifier // time elapsed: 1246.6693 s\n",
      "validation set error: 0.8505 // time elapsed: 0.2323 s\n",
      "test set error: 0.8428 // time elapsed: 0.3505 s\n"
     ]
    }
   ],
   "source": [
    "test_model(feature_model=GCNNModelSmall, settings=Triplet_Hinge_Settings, num_features=100, num_classes=100,\n",
    "           data=data, feature_samplers=triplet_samplers, classification_samplers=samplers,           \n",
    "           f_num_steps=70000, f_lr=0.005, f_keep_prob=0.6, f_reg=0.001, \n",
    "           c_num_steps=30000, c_lr=0.005, c_reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 100, lr: 0.005, reg: 0.001, dropout: 0.6\n",
      "\tstep 0: train loss 1.6621, train error 0.494286\n",
      "\tstep 1000: train loss 1.50876, train error 0.461429\n",
      "\tstep 2000: train loss 1.45701, train error 0.441429\n",
      "\tstep 3000: train loss 1.32495, train error 0.37\n",
      "\tstep 4000: train loss 1.30029, train error 0.404286\n",
      "\tstep 5000: train loss 1.28049, train error 0.367143\n",
      "\tstep 6000: train loss 1.23917, train error 0.374286\n",
      "\tstep 7000: train loss 1.2244, train error 0.355714\n",
      "\tstep 8000: train loss 1.17588, train error 0.337143\n",
      "\tstep 9000: train loss 1.18741, train error 0.338571\n",
      "\tstep 10000: train loss 1.16655, train error 0.337143\n",
      "\tstep 11000: train loss 1.10445, train error 0.332857\n",
      "\tstep 12000: train loss 1.11956, train error 0.351429\n",
      "\tstep 13000: train loss 1.10379, train error 0.318571\n",
      "\tstep 14000: train loss 1.07124, train error 0.311429\n",
      "\tstep 15000: train loss 1.03232, train error 0.294286\n",
      "\tstep 16000: train loss 1.03519, train error 0.311429\n",
      "\tstep 17000: train loss 1.00534, train error 0.302857\n",
      "\tstep 18000: train loss 1.01925, train error 0.311429\n",
      "\tstep 19000: train loss 1.03727, train error 0.324286\n",
      "\tstep 20000: train loss 0.960543, train error 0.271429\n",
      "\tstep 21000: train loss 1.00973, train error 0.325714\n",
      "\tstep 22000: train loss 0.994077, train error 0.32\n",
      "\tstep 23000: train loss 0.977554, train error 0.298571\n",
      "\tstep 24000: train loss 0.952126, train error 0.298571\n",
      "\tstep 25000: train loss 0.939053, train error 0.298571\n",
      "\tstep 26000: train loss 0.950007, train error 0.318571\n",
      "\tstep 27000: train loss 0.965741, train error 0.328571\n",
      "\tstep 28000: train loss 0.901696, train error 0.298571\n",
      "\tstep 29000: train loss 0.867447, train error 0.282857\n",
      "\tstep 30000: train loss 0.915817, train error 0.305714\n",
      "\tstep 31000: train loss 0.887852, train error 0.31\n",
      "\tstep 32000: train loss 0.921934, train error 0.305714\n",
      "\tstep 33000: train loss 0.849733, train error 0.284286\n",
      "\tstep 34000: train loss 0.874936, train error 0.292857\n",
      "\tstep 35000: train loss 0.869543, train error 0.281429\n",
      "\tstep 36000: train loss 0.84589, train error 0.288571\n",
      "\tstep 37000: train loss 0.844051, train error 0.267143\n",
      "\tstep 38000: train loss 0.857375, train error 0.29\n",
      "\tstep 39000: train loss 0.844846, train error 0.305714\n",
      "\tstep 40000: train loss 0.811044, train error 0.297143\n",
      "\tstep 41000: train loss 0.779571, train error 0.272857\n",
      "\tstep 42000: train loss 0.773366, train error 0.278571\n",
      "\tstep 43000: train loss 0.8055, train error 0.265714\n",
      "\tstep 44000: train loss 0.765721, train error 0.251429\n",
      "\tstep 45000: train loss 0.781249, train error 0.28\n",
      "\tstep 46000: train loss 0.737321, train error 0.251429\n",
      "\tstep 47000: train loss 0.722425, train error 0.25\n",
      "\tstep 48000: train loss 0.719022, train error 0.244286\n",
      "\tstep 49000: train loss 0.749344, train error 0.264286\n",
      "\tstep 50000: train loss 0.69235, train error 0.237143\n",
      "\tstep 51000: train loss 0.726071, train error 0.264286\n",
      "\tstep 52000: train loss 0.727961, train error 0.271429\n",
      "\tstep 53000: train loss 0.661838, train error 0.237143\n",
      "\tstep 54000: train loss 0.691097, train error 0.254286\n",
      "\tstep 55000: train loss 0.686229, train error 0.251429\n",
      "\tstep 56000: train loss 0.712458, train error 0.291429\n",
      "\tstep 57000: train loss 0.658651, train error 0.235714\n",
      "\tstep 58000: train loss 0.693412, train error 0.254286\n",
      "\tstep 59000: train loss 0.654679, train error 0.22\n",
      "\tstep 60000: train loss 0.65558, train error 0.24\n",
      "\tstep 61000: train loss 0.65753, train error 0.24\n",
      "\tstep 62000: train loss 0.620621, train error 0.221429\n",
      "\tstep 63000: train loss 0.627164, train error 0.235714\n",
      "\tstep 64000: train loss 0.64638, train error 0.235714\n",
      "\tstep 65000: train loss 0.584295, train error 0.218571\n",
      "\tstep 66000: train loss 0.594339, train error 0.228571\n",
      "\tstep 67000: train loss 0.649968, train error 0.237143\n",
      "\tstep 68000: train loss 0.617922, train error 0.228571\n",
      "\tstep 69000: train loss 0.597391, train error 0.211429\n",
      "end training features // time elapsed: 11654.8581 s\n",
      "validation set error: 0.2010 // time elapsed: 0.2124 s\n",
      "test set error: 0.2240 // time elapsed: 0.2123 s\n",
      "begin training classifier\n",
      "\tstep 0: train loss 5.13899, train error 0.977143\n",
      "\tstep 1000: train loss 5.04752, train error 0.972857\n",
      "\tstep 2000: train loss 4.95982, train error 0.964286\n",
      "\tstep 3000: train loss 4.86305, train error 0.94\n",
      "\tstep 4000: train loss 4.80334, train error 0.92\n",
      "\tstep 5000: train loss 4.72996, train error 0.915714\n",
      "\tstep 6000: train loss 4.68826, train error 0.928571\n",
      "\tstep 7000: train loss 4.62783, train error 0.917143\n",
      "\tstep 8000: train loss 4.55439, train error 0.894286\n",
      "\tstep 9000: train loss 4.53189, train error 0.908571\n",
      "\tstep 10000: train loss 4.48658, train error 0.891429\n",
      "\tstep 11000: train loss 4.46381, train error 0.897143\n",
      "\tstep 12000: train loss 4.43374, train error 0.914286\n",
      "\tstep 13000: train loss 4.40624, train error 0.89\n",
      "\tstep 14000: train loss 4.34413, train error 0.904286\n",
      "\tstep 15000: train loss 4.3394, train error 0.892857\n",
      "\tstep 16000: train loss 4.29215, train error 0.891429\n",
      "\tstep 17000: train loss 4.28591, train error 0.888571\n",
      "\tstep 18000: train loss 4.21776, train error 0.871429\n",
      "\tstep 19000: train loss 4.24537, train error 0.877143\n",
      "\tstep 20000: train loss 4.20073, train error 0.887143\n",
      "\tstep 21000: train loss 4.16729, train error 0.855714\n",
      "\tstep 22000: train loss 4.18261, train error 0.891429\n",
      "\tstep 23000: train loss 4.13881, train error 0.871429\n",
      "\tstep 24000: train loss 4.14201, train error 0.865714\n",
      "\tstep 25000: train loss 4.0618, train error 0.858571\n",
      "\tstep 26000: train loss 4.03949, train error 0.872857\n",
      "\tstep 27000: train loss 4.08131, train error 0.854286\n",
      "\tstep 28000: train loss 4.09358, train error 0.872857\n",
      "\tstep 29000: train loss 4.0397, train error 0.858571\n",
      "end training classifier // time elapsed: 1245.4916 s\n",
      "validation set error: 0.8648 // time elapsed: 0.2062 s\n",
      "test set error: 0.8538 // time elapsed: 0.3434 s\n"
     ]
    }
   ],
   "source": [
    "test_model(feature_model=GCNNModelSmall, settings=Triplet_Hinge_Settings, num_features=100, num_classes=100,\n",
    "           data=data, feature_samplers=triplet_samplers, classification_samplers=samplers,           \n",
    "           f_num_steps=70000, f_lr=0.005, f_keep_prob=0.6, f_reg=0.001, \n",
    "           c_num_steps=30000, c_lr=0.005, c_reg=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
