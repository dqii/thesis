{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dqi/.conda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/dqi/.conda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from features.settings import Baseline_Settings, Pair_Hinge_Settings, Pair_Log_Settings, Triplet_Hinge_Settings, Triplet_Log_Settings\n",
    "from features.models import ConvModelSmall, ConvModelMedium, ConvModelLarge\n",
    "from features.models import GCNNModelSmall, GCNNModelMedium, GCNNModelLarge\n",
    "from classes.models import LinearClassifier\n",
    "from datasets import load_mnist_datasets, load_cifar10\n",
    "from sklearn.svm import LinearSVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 loaded in 101 seconds\n"
     ]
    }
   ],
   "source": [
    "data, samplers, pair_samplers, triplet_samplers = load_cifar10(augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(feature_model, settings, data, num_features, num_classes, feature_samplers, classification_samplers,\n",
    "               f_num_steps, f_lr, f_keep_prob, f_reg, c_num_steps, c_lr, c_reg):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    f_train, f_valid, f_test = feature_samplers\n",
    "    c_train, c_valid, c_test = classification_samplers\n",
    "    (x_train, y_train), (x_valid, y_valid), (x_test, y_test) = data\n",
    "    _, H, W, C = x_train.shape\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, H, W, C])\n",
    "    y = tf.placeholder(tf.int64, shape=[None])    \n",
    "    dropout = tf.placeholder(tf.float32)\n",
    "    training = tf.placeholder(tf.bool)\n",
    "    f_model = feature_model(x=x, y=y, settings=settings, num_chan=C, num_features=num_features, \n",
    "              lr=f_lr, reg=f_reg, dropout=dropout, training=training)\n",
    "    \n",
    "    features = tf.placeholder(tf.float32, shape=[None, num_features])\n",
    "    c_model = LinearClassifier(x=features, y=y, num_features=num_features, num_classes=num_features, \n",
    "                               lr=c_lr, reg=c_reg)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        print(\"begin training features // num_features: %g, lr: %g, reg: %g, dropout: %g\" %(num_features, f_lr, f_reg, f_keep_prob))\n",
    "        train_time = time.time()\n",
    "        for step in range(f_num_steps):        \n",
    "            x_, y_ = f_train.sample(700)\n",
    "            sess.run(f_model.optimize, feed_dict={x:x_, y:y_, dropout:f_keep_prob, training:True})     \n",
    "            if step % 1000 == 0:\n",
    "                train_loss, train_acc = sess.run([f_model.loss, f_model.acc], \n",
    "                                                 feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "                print(\"\\tstep %d: train loss %g, train error %g\"%(step, train_loss, 1 - train_acc))  \n",
    "        train_time = time.time() - train_time\n",
    "        print(\"end training features // time elapsed: %.4f s\"%(train_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        x_, y_ = f_valid.sample(1000)\n",
    "        test_error = 1 - sess.run(f_model.acc, feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"validation set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        x_, y_ = f_test.sample(1000)\n",
    "        test_error = 1 - sess.run(f_model.acc, feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"test set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        print(\"begin training classifier\")\n",
    "        train_time = time.time()\n",
    "        for step in range(c_num_steps):        \n",
    "            x_, y_ = c_train.sample(700)\n",
    "            features_ = sess.run(f_model.features, feed_dict={x:x_, dropout:1.0, training:False})\n",
    "            sess.run(c_model.optimize, feed_dict={features:features_, y:y_, x:x_, dropout:1.0, training:False})\n",
    "            if step % 1000 == 0:\n",
    "                train_loss, train_acc = sess.run([c_model.loss, c_model.acc], feed_dict={features:features_, y:y_})\n",
    "                print(\"\\tstep %d: train loss %g, train error %g\"%(step, train_loss, 1 - train_acc))  \n",
    "        train_time = time.time() - train_time\n",
    "        print(\"end training classifier // time elapsed: %.4f s\"%(train_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        features_ = sess.run(f_model.features, feed_dict={x:x_valid, dropout:1.0, training:False})\n",
    "        test_error = 1 - sess.run(c_model.acc, feed_dict={features:features_, y:y_valid})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"validation set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        features_ = sess.run(f_model.features, feed_dict={x:x_test, dropout:1.0, training:False})\n",
    "        test_error = 1 - sess.run(c_model.acc, feed_dict={features:features_, y:y_test})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"test set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 10, lr: 0.01, reg: 0.001, dropout: 0.6\n",
      "\tstep 0: train loss 2.86984, train error 0.89\n",
      "\tstep 1000: train loss 2.16015, train error 0.598571\n",
      "\tstep 2000: train loss 1.94927, train error 0.571429\n",
      "\tstep 3000: train loss 1.86522, train error 0.528571\n",
      "\tstep 4000: train loss 1.55336, train error 0.42\n",
      "\tstep 5000: train loss 1.62448, train error 0.465714\n",
      "\tstep 6000: train loss 1.5064, train error 0.414286\n",
      "\tstep 7000: train loss 1.41088, train error 0.374286\n",
      "\tstep 8000: train loss 1.40901, train error 0.384286\n",
      "\tstep 9000: train loss 1.3384, train error 0.362857\n",
      "\tstep 10000: train loss 1.22834, train error 0.335714\n",
      "\tstep 11000: train loss 1.17861, train error 0.33\n",
      "\tstep 12000: train loss 1.14353, train error 0.304286\n",
      "\tstep 13000: train loss 1.09757, train error 0.301429\n",
      "\tstep 14000: train loss 0.989379, train error 0.264286\n",
      "\tstep 15000: train loss 0.997888, train error 0.278571\n",
      "\tstep 16000: train loss 0.947964, train error 0.271429\n",
      "\tstep 17000: train loss 0.947029, train error 0.248571\n",
      "\tstep 18000: train loss 0.986061, train error 0.29\n",
      "\tstep 19000: train loss 0.865651, train error 0.238571\n",
      "\tstep 20000: train loss 0.816415, train error 0.235714\n",
      "\tstep 21000: train loss 0.893585, train error 0.268571\n",
      "\tstep 22000: train loss 0.807884, train error 0.23\n",
      "\tstep 23000: train loss 0.818106, train error 0.248571\n",
      "\tstep 24000: train loss 0.701534, train error 0.178571\n",
      "\tstep 25000: train loss 0.70438, train error 0.181429\n",
      "\tstep 26000: train loss 0.661611, train error 0.187143\n",
      "\tstep 27000: train loss 0.667141, train error 0.187143\n",
      "\tstep 28000: train loss 0.657078, train error 0.19\n",
      "\tstep 29000: train loss 0.610806, train error 0.168571\n",
      "\tstep 30000: train loss 0.56577, train error 0.167143\n",
      "\tstep 31000: train loss 0.581984, train error 0.162857\n",
      "\tstep 32000: train loss 0.51274, train error 0.147143\n",
      "\tstep 33000: train loss 0.5521, train error 0.148571\n",
      "\tstep 34000: train loss 0.51993, train error 0.145714\n",
      "\tstep 35000: train loss 0.467071, train error 0.125714\n",
      "\tstep 36000: train loss 0.432375, train error 0.104286\n",
      "\tstep 37000: train loss 0.440593, train error 0.117143\n",
      "\tstep 38000: train loss 0.433607, train error 0.107143\n",
      "\tstep 39000: train loss 0.369214, train error 0.0957143\n",
      "\tstep 40000: train loss 0.3802, train error 0.09\n",
      "\tstep 41000: train loss 0.380789, train error 0.0942857\n",
      "\tstep 42000: train loss 0.353604, train error 0.0871429\n",
      "\tstep 43000: train loss 0.371834, train error 0.0985714\n",
      "\tstep 44000: train loss 0.330242, train error 0.0814286\n",
      "\tstep 45000: train loss 0.312612, train error 0.0714286\n",
      "\tstep 46000: train loss 0.288957, train error 0.0557143\n",
      "\tstep 47000: train loss 0.290967, train error 0.06\n",
      "\tstep 48000: train loss 0.308006, train error 0.0728571\n",
      "\tstep 49000: train loss 0.266649, train error 0.0514286\n",
      "end training features // time elapsed: 2688.2944 s\n",
      "validation set error: 0.1750 // time elapsed: 0.0824 s\n",
      "test set error: 0.1730 // time elapsed: 0.0314 s\n",
      "begin training classifier\n",
      "\tstep 0: train loss 6.59349, train error 0.997143\n",
      "\tstep 1000: train loss 0.289449, train error 0.0614285\n",
      "\tstep 2000: train loss 0.250489, train error 0.0514286\n",
      "\tstep 3000: train loss 0.239052, train error 0.0628572\n",
      "\tstep 4000: train loss 0.220627, train error 0.0642857\n",
      "\tstep 5000: train loss 0.209178, train error 0.0542857\n",
      "\tstep 6000: train loss 0.216681, train error 0.0528572\n",
      "\tstep 7000: train loss 0.193831, train error 0.0428572\n",
      "\tstep 8000: train loss 0.175632, train error 0.0342857\n",
      "\tstep 9000: train loss 0.183327, train error 0.04\n",
      "\tstep 10000: train loss 0.174094, train error 0.0428572\n",
      "\tstep 11000: train loss 0.187074, train error 0.0385714\n",
      "\tstep 12000: train loss 0.187385, train error 0.0485714\n",
      "\tstep 13000: train loss 0.198755, train error 0.0428572\n",
      "\tstep 14000: train loss 0.163717, train error 0.0442857\n",
      "\tstep 15000: train loss 0.166279, train error 0.0357143\n",
      "\tstep 16000: train loss 0.158978, train error 0.0385714\n",
      "\tstep 17000: train loss 0.233489, train error 0.0671428\n",
      "\tstep 18000: train loss 0.184096, train error 0.0485714\n",
      "\tstep 19000: train loss 0.171039, train error 0.0371429\n",
      "\tstep 20000: train loss 0.18188, train error 0.0428572\n",
      "\tstep 21000: train loss 0.1817, train error 0.0542857\n",
      "\tstep 22000: train loss 0.179546, train error 0.0414286\n",
      "\tstep 23000: train loss 0.174929, train error 0.0571429\n",
      "\tstep 24000: train loss 0.164877, train error 0.0471429\n",
      "\tstep 25000: train loss 0.173391, train error 0.0528572\n",
      "\tstep 26000: train loss 0.204632, train error 0.05\n",
      "\tstep 27000: train loss 0.150904, train error 0.0371429\n",
      "\tstep 28000: train loss 0.186906, train error 0.0442857\n",
      "\tstep 29000: train loss 0.155749, train error 0.0314286\n",
      "end training classifier // time elapsed: 1259.7114 s\n",
      "validation set error: 0.1725 // time elapsed: 0.3047 s\n",
      "test set error: 0.1831 // time elapsed: 0.4838 s\n"
     ]
    }
   ],
   "source": [
    "test_model(feature_model=GCNNModelSmall, settings=Baseline_Settings, num_features=10, num_classes=10,\n",
    "           data=data, feature_samplers=samplers, classification_samplers=samplers,           \n",
    "           f_num_steps=50000, f_lr=0.01, f_keep_prob=0.6, f_reg=0.001, \n",
    "           c_num_steps=30000, c_lr=0.005, c_reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 10, lr: 0.01, reg: 0.001, dropout: 0.6\n",
      "\tstep 0: train loss 1.5273, train error 0.5\n",
      "\tstep 1000: train loss 1.3048, train error 0.344286\n",
      "\tstep 2000: train loss 1.19955, train error 0.327143\n",
      "\tstep 3000: train loss 1.1406, train error 0.305714\n",
      "\tstep 4000: train loss 1.07139, train error 0.291429\n",
      "\tstep 5000: train loss 1.07001, train error 0.311429\n",
      "\tstep 6000: train loss 0.933511, train error 0.25\n",
      "\tstep 7000: train loss 0.943549, train error 0.267143\n",
      "\tstep 8000: train loss 0.874594, train error 0.234286\n",
      "\tstep 9000: train loss 0.893579, train error 0.252857\n",
      "\tstep 10000: train loss 0.80692, train error 0.225714\n",
      "\tstep 11000: train loss 0.786572, train error 0.225714\n",
      "\tstep 12000: train loss 0.777817, train error 0.217143\n",
      "\tstep 13000: train loss 0.74501, train error 0.217143\n",
      "\tstep 14000: train loss 0.702917, train error 0.207143\n",
      "\tstep 15000: train loss 0.671019, train error 0.185714\n",
      "\tstep 16000: train loss 0.702287, train error 0.217143\n",
      "\tstep 17000: train loss 0.638846, train error 0.168571\n",
      "\tstep 18000: train loss 0.629728, train error 0.194286\n",
      "\tstep 19000: train loss 0.591933, train error 0.188571\n",
      "\tstep 20000: train loss 0.572943, train error 0.177143\n",
      "\tstep 21000: train loss 0.590901, train error 0.192857\n",
      "\tstep 22000: train loss 0.578501, train error 0.188571\n",
      "\tstep 23000: train loss 0.546191, train error 0.177143\n",
      "\tstep 24000: train loss 0.484303, train error 0.138571\n",
      "\tstep 25000: train loss 0.516428, train error 0.17\n",
      "\tstep 26000: train loss 0.527838, train error 0.172857\n",
      "\tstep 27000: train loss 0.475182, train error 0.148571\n",
      "\tstep 28000: train loss 0.497486, train error 0.175714\n",
      "\tstep 29000: train loss 0.48731, train error 0.168571\n",
      "\tstep 30000: train loss 0.447759, train error 0.14\n",
      "\tstep 31000: train loss 0.376242, train error 0.108571\n",
      "\tstep 32000: train loss 0.409337, train error 0.137143\n",
      "\tstep 33000: train loss 0.404028, train error 0.14\n",
      "\tstep 34000: train loss 0.413991, train error 0.137143\n",
      "\tstep 35000: train loss 0.42177, train error 0.145714\n",
      "\tstep 36000: train loss 0.389513, train error 0.13\n",
      "\tstep 37000: train loss 0.386112, train error 0.127143\n",
      "\tstep 38000: train loss 0.329569, train error 0.0985714\n",
      "\tstep 39000: train loss 0.35648, train error 0.12\n",
      "\tstep 40000: train loss 0.404521, train error 0.137143\n",
      "\tstep 41000: train loss 0.361405, train error 0.118571\n",
      "\tstep 42000: train loss 0.318725, train error 0.108571\n",
      "\tstep 43000: train loss 0.320567, train error 0.117143\n",
      "\tstep 44000: train loss 0.28045, train error 0.0842857\n",
      "\tstep 45000: train loss 0.303811, train error 0.111429\n",
      "\tstep 46000: train loss 0.261836, train error 0.0942857\n",
      "\tstep 47000: train loss 0.277602, train error 0.0914286\n",
      "\tstep 48000: train loss 0.305363, train error 0.114286\n",
      "\tstep 49000: train loss 0.286669, train error 0.0957143\n",
      "end training features // time elapsed: 8459.3816 s\n",
      "validation set error: 0.1240 // time elapsed: 0.2383 s\n",
      "test set error: 0.1060 // time elapsed: 0.1666 s\n",
      "begin training classifier\n",
      "\tstep 0: train loss 3.08159, train error 0.987143\n",
      "\tstep 1000: train loss 1.60172, train error 0.3\n",
      "\tstep 2000: train loss 1.3591, train error 0.292857\n",
      "\tstep 3000: train loss 1.2307, train error 0.265714\n",
      "\tstep 4000: train loss 1.17578, train error 0.26\n",
      "\tstep 5000: train loss 1.16625, train error 0.284286\n",
      "\tstep 6000: train loss 1.08067, train error 0.274286\n",
      "\tstep 7000: train loss 1.13578, train error 0.291429\n",
      "\tstep 8000: train loss 1.04468, train error 0.274286\n",
      "\tstep 9000: train loss 1.04489, train error 0.287143\n",
      "\tstep 10000: train loss 1.03717, train error 0.29\n",
      "\tstep 11000: train loss 1.05654, train error 0.302857\n",
      "\tstep 12000: train loss 0.996501, train error 0.268571\n",
      "\tstep 13000: train loss 1.01921, train error 0.297143\n",
      "\tstep 14000: train loss 0.978073, train error 0.28\n",
      "\tstep 15000: train loss 1.05175, train error 0.3\n",
      "\tstep 16000: train loss 0.990365, train error 0.285714\n",
      "\tstep 17000: train loss 0.929247, train error 0.26\n",
      "\tstep 18000: train loss 0.928031, train error 0.242857\n",
      "\tstep 19000: train loss 1.01493, train error 0.292857\n",
      "\tstep 20000: train loss 0.96287, train error 0.285714\n",
      "\tstep 21000: train loss 0.96555, train error 0.272857\n",
      "\tstep 22000: train loss 0.912607, train error 0.264286\n",
      "\tstep 23000: train loss 0.976329, train error 0.288571\n",
      "\tstep 24000: train loss 0.912996, train error 0.272857\n",
      "\tstep 25000: train loss 0.945228, train error 0.301429\n",
      "\tstep 26000: train loss 0.92364, train error 0.292857\n",
      "\tstep 27000: train loss 0.92172, train error 0.258571\n",
      "\tstep 28000: train loss 0.904021, train error 0.281429\n",
      "\tstep 29000: train loss 0.879036, train error 0.275714\n",
      "end training classifier // time elapsed: 1260.3723 s\n",
      "validation set error: 0.2953 // time elapsed: 0.2139 s\n",
      "test set error: 0.2988 // time elapsed: 0.3284 s\n"
     ]
    }
   ],
   "source": [
    "test_model(feature_model=GCNNModelSmall, settings=Triplet_Hinge_Settings, num_features=10, num_classes=10,\n",
    "           data=data, feature_samplers=triplet_samplers, classification_samplers=samplers,           \n",
    "           f_num_steps=50000, f_lr=0.01, f_keep_prob=0.6, f_reg=0.001, \n",
    "           c_num_steps=30000, c_lr=0.01, c_reg=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
