{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dqi/.conda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/dqi/.conda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from features.settings import Baseline_Settings, Triplet_Hinge_Settings, Triplet_Distance_Settings\n",
    "from features.models import GCNNSmall0, GCNNMedium0, GCNNMedium1, GCNNLarge0\n",
    "from learn import get_feature_model, train_features, test_features\n",
    "from datasets import load_cifar100\n",
    "from classes.models import LinearClassifier0, LinearClassifier1, LinearClassifier2, LinearClassifier3, TwoLayerClassifier0\n",
    "from learn import get_feature_model, get_classifier, train_features, train_classifier, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-100 loaded in 105 seconds\n"
     ]
    }
   ],
   "source": [
    "data, samplers, pair_samplers, triplet_samplers = load_cifar100(augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=data; s=triplet_samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features\n",
      "\tstep 0: train loss 72.3358, train error 0.39, valid loss 81.7925, valid error 0.483333\n",
      "\tstep 200: train loss 1.41867, train error 0.423333, valid loss 1.40801, valid error 0.383333\n",
      "\tstep 400: train loss 1.28673, train error 0.35, valid loss 1.30268, valid error 0.38\n",
      "\tstep 600: train loss 1.19148, train error 0.333333, valid loss 1.28725, valid error 0.39\n",
      "\tstep 800: train loss 1.15208, train error 0.293333, valid loss 1.19491, valid error 0.32\n",
      "\tstep 1000: train loss 1.17897, train error 0.32, valid loss 1.24941, valid error 0.366667\n",
      "\tstep 1200: train loss 1.1069, train error 0.303333, valid loss 1.09944, valid error 0.286667\n",
      "\tstep 1400: train loss 1.0381, train error 0.276667, valid loss 1.08494, valid error 0.306667\n",
      "\tstep 1600: train loss 1.06121, train error 0.296667, valid loss 1.22263, valid error 0.403333\n",
      "\tstep 1800: train loss 1.04514, train error 0.296667, valid loss 1.05643, valid error 0.31\n",
      "\tstep 2000: train loss 1.1598, train error 0.366667, valid loss 1.03638, valid error 0.313333\n",
      "\tstep 2200: train loss 1.08608, train error 0.34, valid loss 1.0673, valid error 0.3\n",
      "\tstep 2400: train loss 0.930649, train error 0.273333, valid loss 1.03358, valid error 0.33\n",
      "\tstep 2600: train loss 1.0101, train error 0.31, valid loss 0.995814, valid error 0.333333\n",
      "\tstep 2800: train loss 1.04616, train error 0.33, valid loss 1.02126, valid error 0.336667\n",
      "\tstep 3000: train loss 1.12526, train error 0.413333, valid loss 0.970888, valid error 0.316667\n",
      "\tstep 3200: train loss 0.973535, train error 0.31, valid loss 0.887949, valid error 0.286667\n",
      "\tstep 3400: train loss 0.957508, train error 0.273333, valid loss 0.966832, valid error 0.27\n",
      "\tstep 3600: train loss 0.958195, train error 0.323333, valid loss 1.00646, valid error 0.336667\n",
      "\tstep 3800: train loss 0.87938, train error 0.276667, valid loss 0.913948, valid error 0.276667\n",
      "\tstep 4000: train loss 0.977287, train error 0.316667, valid loss 1.01728, valid error 0.343333\n",
      "\tstep 4200: train loss 0.933288, train error 0.29, valid loss 0.857135, valid error 0.273333\n",
      "\tstep 4400: train loss 0.932714, train error 0.31, valid loss 0.899723, valid error 0.28\n",
      "\tstep 4600: train loss 0.794811, train error 0.226667, valid loss 0.979496, valid error 0.313333\n",
      "\tstep 4800: train loss 0.820389, train error 0.256667, valid loss 0.888067, valid error 0.293333\n",
      "\tstep 5000: train loss 0.833582, train error 0.256667, valid loss 0.869968, valid error 0.29\n",
      "\tstep 5200: train loss 0.8013, train error 0.276667, valid loss 0.898752, valid error 0.303333\n",
      "\tstep 5400: train loss 0.91155, train error 0.33, valid loss 0.843924, valid error 0.28\n",
      "\tstep 5600: train loss 0.863009, train error 0.316667, valid loss 0.798894, valid error 0.273333\n",
      "\tstep 5800: train loss 0.801171, train error 0.273333, valid loss 0.844864, valid error 0.283333\n",
      "\tstep 6000: train loss 0.836537, train error 0.306667, valid loss 0.832295, valid error 0.283333\n",
      "\tstep 6200: train loss 0.727752, train error 0.24, valid loss 0.814676, valid error 0.276667\n",
      "\tstep 6400: train loss 0.757927, train error 0.263333, valid loss 0.806793, valid error 0.276667\n",
      "\tstep 6600: train loss 0.762587, train error 0.246667, valid loss 0.740224, valid error 0.243333\n",
      "\tstep 6800: train loss 0.687526, train error 0.243333, valid loss 0.771646, valid error 0.256667\n",
      "\tstep 7000: train loss 0.81682, train error 0.273333, valid loss 0.784248, valid error 0.296667\n",
      "\tstep 7200: train loss 0.767935, train error 0.27, valid loss 0.795833, valid error 0.296667\n",
      "\tstep 7400: train loss 0.730731, train error 0.256667, valid loss 0.742175, valid error 0.253333\n",
      "\tstep 7600: train loss 0.75574, train error 0.276667, valid loss 0.722235, valid error 0.23\n",
      "\tstep 7800: train loss 0.836194, train error 0.32, valid loss 0.829488, valid error 0.306667\n",
      "\tstep 8000: train loss 0.683892, train error 0.243333, valid loss 0.711563, valid error 0.266667\n",
      "\tstep 8200: train loss 0.705016, train error 0.243333, valid loss 0.7626, valid error 0.3\n",
      "\tstep 8400: train loss 0.632682, train error 0.23, valid loss 0.649236, valid error 0.22\n",
      "\tstep 8600: train loss 0.718854, train error 0.27, valid loss 0.711479, valid error 0.28\n",
      "\tstep 8800: train loss 0.68336, train error 0.246667, valid loss 0.691059, valid error 0.27\n",
      "\tstep 9000: train loss 0.663381, train error 0.223333, valid loss 0.650592, valid error 0.243333\n",
      "\tstep 9200: train loss 0.657865, train error 0.246667, valid loss 0.717025, valid error 0.276667\n",
      "\tstep 9400: train loss 0.689793, train error 0.27, valid loss 0.686582, valid error 0.27\n",
      "\tstep 9600: train loss 0.596778, train error 0.206667, valid loss 0.706984, valid error 0.266667\n",
      "\tstep 9800: train loss 0.64387, train error 0.24, valid loss 0.658168, valid error 0.25\n",
      "\tstep 10000: train loss 0.601536, train error 0.21, valid loss 0.623699, valid error 0.22\n",
      "\tstep 10200: train loss 0.625862, train error 0.24, valid loss 0.625707, valid error 0.24\n",
      "\tstep 10400: train loss 0.69577, train error 0.273333, valid loss 0.732898, valid error 0.28\n",
      "\tstep 10600: train loss 0.576426, train error 0.216667, valid loss 0.562386, valid error 0.186667\n",
      "\tstep 10800: train loss 0.631547, train error 0.246667, valid loss 0.604949, valid error 0.226667\n",
      "\tstep 11000: train loss 0.603342, train error 0.213333, valid loss 0.638893, valid error 0.24\n",
      "\tstep 11200: train loss 0.598441, train error 0.236667, valid loss 0.609166, valid error 0.23\n",
      "\tstep 11400: train loss 0.602224, train error 0.226667, valid loss 0.611124, valid error 0.236667\n",
      "\tstep 11600: train loss 0.609988, train error 0.233333, valid loss 0.681124, valid error 0.26\n",
      "\tstep 11800: train loss 0.580252, train error 0.22, valid loss 0.549064, valid error 0.193333\n",
      "\tstep 12000: train loss 0.584574, train error 0.22, valid loss 0.558772, valid error 0.17\n",
      "\tstep 12200: train loss 0.59429, train error 0.223333, valid loss 0.61338, valid error 0.253333\n",
      "\tstep 12400: train loss 0.56259, train error 0.203333, valid loss 0.547603, valid error 0.203333\n",
      "\tstep 12600: train loss 0.568196, train error 0.2, valid loss 0.527981, valid error 0.19\n",
      "\tstep 12800: train loss 0.518787, train error 0.176667, valid loss 0.572194, valid error 0.216667\n",
      "\tstep 13000: train loss 0.612441, train error 0.226667, valid loss 0.612155, valid error 0.236667\n",
      "\tstep 13200: train loss 0.563049, train error 0.226667, valid loss 0.597641, valid error 0.24\n",
      "\tstep 13400: train loss 0.517577, train error 0.19, valid loss 0.566971, valid error 0.216667\n",
      "\tstep 13600: train loss 0.558729, train error 0.243333, valid loss 0.521949, valid error 0.183333\n",
      "\tstep 13800: train loss 0.541602, train error 0.203333, valid loss 0.57548, valid error 0.223333\n",
      "\tstep 14000: train loss 0.626821, train error 0.233333, valid loss 0.586724, valid error 0.24\n",
      "\tstep 14200: train loss 0.470017, train error 0.193333, valid loss 0.524731, valid error 0.183333\n",
      "\tstep 14400: train loss 0.482923, train error 0.203333, valid loss 0.5176, valid error 0.203333\n",
      "\tstep 14600: train loss 0.530936, train error 0.163333, valid loss 0.593215, valid error 0.243333\n",
      "\tstep 14800: train loss 0.483335, train error 0.196667, valid loss 0.522076, valid error 0.21\n",
      "end training features // time elapsed: 5930.2164 s\n",
      "validation set error: 0.2027 // time elapsed: 142.8429 s\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "f, f_params = get_feature_model(feature_model=GCNNLarge0, settings=Triplet_Distance_Settings,\n",
    "                                num_features=10, data_format=[32, 32, 3],\n",
    "                                f_lr=0.03, f_reg=0.001, f_scope=\"d_gl0_cifar100_10\")\n",
    "fs = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"d_gl0_cifar100_10\"))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    fs.restore(sess, \"./models/cifar100/d_gl0_cifar100_10.ckpt\")\n",
    "    train_features(sess=sess, feature_model=f, samplers=s, num_steps=45000, keep_prob=0.6, f_params=f_params)\n",
    "    fs.save(sess, \"./models/cifar100/d_gl0_cifar100_10.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
