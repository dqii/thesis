{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dqi/.conda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/dqi/.conda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from features.settings import Pair_Hinge_Settings, Pair_Log_Settings, Triplet_Hinge_Settings, Triplet_Log_Settings\n",
    "from features.models import ConvModelSmall, ConvModelMedium\n",
    "from classes.models import LinearClassifier\n",
    "from datasets import load_datasets, load_mnist, load_cifar10, load_cifar100\n",
    "from sklearn.svm import LinearSVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST loaded in 39 seconds\n",
      "Fashion MNIST loaded in 39 seconds\n"
     ]
    }
   ],
   "source": [
    "data, samplers, pair_samplers, triplet_samplers = load_mnist(augment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, settings, data, feature_samplers, classification_samplers, num_features, num_steps, lr, keep_prob, reg):\n",
    "    tf.reset_default_graph()\n",
    "    f_train, f_test = feature_samplers\n",
    "    c_train, c_test = classification_samplers\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "    _, H, W, C = x_train.shape\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, H, W, C])\n",
    "    y = tf.placeholder(tf.int64, shape=[None])\n",
    "    dropout = tf.placeholder(tf.float32)\n",
    "    training = tf.placeholder(tf.bool)\n",
    "    m = model(x=x, y=y, settings=settings, num_chan=C, num_features=num_features, \n",
    "              lr=lr, reg=reg, dropout=dropout, training=training)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        print(\"begin training features // num_features: %g, lr: %g, reg: %g\"%(num_features, lr, reg))\n",
    "        train_time = time.time()\n",
    "        for step in range(num_steps):        \n",
    "            x_, y_ = f_train.sample(200)\n",
    "            sess.run(m.optimize, feed_dict={x:x_, y:y_, dropout:keep_prob, training:True})     \n",
    "            if step % 1000 == 0:\n",
    "                train_loss, train_acc = sess.run([m.loss, m.acc], feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "                print(\"\\tstep %d: train loss %g, train error %g\"%(step, train_loss, 1 - train_acc))  \n",
    "        train_time = time.time() - train_time\n",
    "        print(\"end training features // time elapsed: %.4f s\"%(train_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        x_, y_ = f_test.sample(5000)\n",
    "        test_error = 1 - sess.run(m.acc, feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"test set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        svc = LinearSVC(random_state=0)\n",
    "        x_, y_ = c_train.sample(20000)\n",
    "        features_train = sess.run(m.features, feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "        svc.fit(features_train, y_)\n",
    "        features_test = sess.run(m.features, feed_dict={x:x_test, y:y_test, dropout:1.0, training:False})\n",
    "        print(\"classification accuracy: {:.4f}\\n\".format(svc.score(features_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Triplet Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 10, lr: 0.0747453, reg: 0.001\n",
      "\tstep 0: train loss 1.22649, train error 0.46\n",
      "\tstep 5000: train loss 0.0441183, train error 0\n",
      "\tstep 10000: train loss 0.0209183, train error 0\n",
      "end training features // time elapsed: 116.8834 s\n",
      "test set error: 0.0038 // time elapsed: 0.1766 s\n",
      "classification accuracy: 0.9842\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.0986515, reg: 0.001\n",
      "\tstep 0: train loss 1.23039, train error 0.5\n",
      "\tstep 5000: train loss 0.0324496, train error 0\n",
      "\tstep 10000: train loss 0.0169188, train error 0\n",
      "end training features // time elapsed: 116.6316 s\n",
      "test set error: 0.0030 // time elapsed: 0.1702 s\n",
      "classification accuracy: 0.9860\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.063485, reg: 0.001\n",
      "\tstep 0: train loss 1.23051, train error 0.485\n",
      "\tstep 5000: train loss 0.0491716, train error 0\n",
      "\tstep 10000: train loss 0.0258126, train error 0\n",
      "end training features // time elapsed: 117.5176 s\n",
      "test set error: 0.0034 // time elapsed: 0.1832 s\n",
      "classification accuracy: 0.9859\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.0755927, reg: 0.001\n",
      "\tstep 0: train loss 1.23383, train error 0.545\n",
      "\tstep 5000: train loss 0.0499702, train error 0.005\n",
      "\tstep 10000: train loss 0.018534, train error 0\n",
      "end training features // time elapsed: 116.8181 s\n",
      "test set error: 0.0018 // time elapsed: 0.1800 s\n",
      "classification accuracy: 0.9849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.03, 0.1, 4):\n",
    "    test_model(model=ConvModelSmall, settings=Triplet_Hinge_Settings, \n",
    "               data=data['mnist'], samplers=triplet_samplers['mnist'],\n",
    "               num_features=10, num_steps=15000, lr=lr, keep_prob=0.8, reg=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 20, lr: 0.0373034, reg: 0.001\n",
      "\tstep 0: train loss 1.23043, train error 0.495\n",
      "\tstep 5000: train loss 0.108515, train error 0.005\n",
      "\tstep 10000: train loss 0.040082, train error 0\n",
      "end training features // time elapsed: 116.0268 s\n",
      "test set error: 0.0028 // time elapsed: 0.2633 s\n",
      "classification accuracy: 0.9843\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0692201, reg: 0.001\n",
      "\tstep 0: train loss 1.22494, train error 0.47\n",
      "\tstep 5000: train loss 0.0463578, train error 0\n",
      "\tstep 10000: train loss 0.0199733, train error 0\n",
      "end training features // time elapsed: 116.1093 s\n",
      "test set error: 0.0042 // time elapsed: 0.2693 s\n",
      "classification accuracy: 0.9840\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0759431, reg: 0.001\n",
      "\tstep 0: train loss 1.24072, train error 0.545\n",
      "\tstep 5000: train loss 0.0406525, train error 0\n",
      "\tstep 10000: train loss 0.0190406, train error 0\n",
      "end training features // time elapsed: 116.8040 s\n",
      "test set error: 0.0048 // time elapsed: 0.3048 s\n",
      "classification accuracy: 0.9850\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0446505, reg: 0.001\n",
      "\tstep 0: train loss 1.23558, train error 0.48\n",
      "\tstep 5000: train loss 0.0745983, train error 0\n",
      "\tstep 10000: train loss 0.0362605, train error 0\n",
      "end training features // time elapsed: 116.1540 s\n",
      "test set error: 0.0024 // time elapsed: 0.3397 s\n",
      "classification accuracy: 0.9843\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0542958, reg: 0.001\n",
      "\tstep 0: train loss 1.22831, train error 0.44\n",
      "\tstep 5000: train loss 0.0626118, train error 0\n",
      "\tstep 10000: train loss 0.0319257, train error 0\n",
      "end training features // time elapsed: 116.9342 s\n",
      "test set error: 0.0020 // time elapsed: 0.3224 s\n",
      "classification accuracy: 0.9852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.01, 0.1, 5):\n",
    "    test_model(model=ConvModelSmall, settings=Triplet_Hinge_Settings, \n",
    "               data=data['mnist'], samplers=triplet_samplers['mnist'],\n",
    "               num_features=20, num_steps=15000, lr=lr, keep_prob=0.8, reg=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 40, lr: 0.0363715, reg: 0.001\n",
      "\tstep 0: train loss 1.24914, train error 0.5\n",
      "\tstep 5000: train loss 0.113362, train error 0.00999999\n",
      "\tstep 10000: train loss 0.043342, train error 0\n",
      "end training features // time elapsed: 116.5782 s\n",
      "test set error: 0.0020 // time elapsed: 0.1912 s\n",
      "classification accuracy: 0.9841\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.0826486, reg: 0.001\n",
      "\tstep 0: train loss 1.24419, train error 0.455\n",
      "\tstep 5000: train loss 0.0374918, train error 0\n",
      "\tstep 10000: train loss 0.0201124, train error 0\n",
      "end training features // time elapsed: 116.9268 s\n",
      "test set error: 0.0036 // time elapsed: 0.1858 s\n",
      "classification accuracy: 0.9839\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.023884, reg: 0.001\n",
      "\tstep 0: train loss 1.24599, train error 0.455\n",
      "\tstep 5000: train loss 0.13431, train error 0\n",
      "\tstep 10000: train loss 0.0996143, train error 0.005\n",
      "end training features // time elapsed: 117.4132 s\n",
      "test set error: 0.0036 // time elapsed: 0.1967 s\n",
      "classification accuracy: 0.9817\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.0934863, reg: 0.001\n",
      "\tstep 0: train loss 1.23698, train error 0.405\n",
      "\tstep 5000: train loss 0.0317137, train error 0\n",
      "\tstep 10000: train loss 0.0184666, train error 0\n",
      "end training features // time elapsed: 117.0096 s\n",
      "test set error: 0.0026 // time elapsed: 0.2078 s\n",
      "classification accuracy: 0.9865\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.0304254, reg: 0.001\n",
      "\tstep 0: train loss 1.24641, train error 0.47\n",
      "\tstep 5000: train loss 0.116583, train error 0.005\n",
      "\tstep 10000: train loss 0.0544538, train error 0\n",
      "end training features // time elapsed: 116.5367 s\n",
      "test set error: 0.0036 // time elapsed: 0.2377 s\n",
      "classification accuracy: 0.9848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.02, 0.1, 5):\n",
    "    test_model(model=ConvModelSmall, settings=Triplet_Hinge_Settings, \n",
    "               data=data['mnist'], samplers=triplet_samplers['mnist'],\n",
    "               num_features=40, num_steps=15000, lr=lr, keep_prob=0.8, reg=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 10, lr: 0.059262, reg: 0.001\n",
      "\tstep 0: train loss 1.22897, train error 0.49\n",
      "\tstep 4000: train loss 0.0858287, train error 0\n",
      "\tstep 8000: train loss 0.0605886, train error 0.005\n",
      "\tstep 12000: train loss 0.0523309, train error 0.00999999\n",
      "end training features // time elapsed: 118.3798 s\n",
      "test set error: 0.0036 // time elapsed: 0.1799 s\n",
      "classification accuracy: 0.9811\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.0951218, reg: 0.001\n",
      "\tstep 0: train loss 1.22956, train error 0.47\n",
      "\tstep 4000: train loss 0.065812, train error 0.005\n",
      "\tstep 8000: train loss 0.0501976, train error 0\n",
      "\tstep 12000: train loss 0.0351119, train error 0\n",
      "end training features // time elapsed: 118.7211 s\n",
      "test set error: 0.0032 // time elapsed: 0.1908 s\n",
      "classification accuracy: 0.9823\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.100889, reg: 0.001\n",
      "\tstep 0: train loss 1.23, train error 0.495\n",
      "\tstep 4000: train loss 0.0859322, train error 0.015\n",
      "\tstep 8000: train loss 0.0568283, train error 0.00999999\n",
      "\tstep 12000: train loss 0.0379877, train error 0\n",
      "end training features // time elapsed: 118.2167 s\n",
      "test set error: 0.0046 // time elapsed: 0.1851 s\n",
      "classification accuracy: 0.9826\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.057905, reg: 0.001\n",
      "\tstep 0: train loss 1.2272, train error 0.42\n",
      "\tstep 4000: train loss 0.0996768, train error 0.005\n",
      "\tstep 8000: train loss 0.0506085, train error 0\n",
      "\tstep 12000: train loss 0.035486, train error 0\n",
      "end training features // time elapsed: 118.7128 s\n",
      "test set error: 0.0030 // time elapsed: 0.1792 s\n",
      "classification accuracy: 0.9826\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.0513295, reg: 0.001\n",
      "\tstep 0: train loss 1.23048, train error 0.495\n",
      "\tstep 4000: train loss 0.114139, train error 0.005\n",
      "\tstep 8000: train loss 0.0689564, train error 0.005\n",
      "\tstep 12000: train loss 0.0405384, train error 0\n",
      "end training features // time elapsed: 118.0291 s\n",
      "test set error: 0.0028 // time elapsed: 0.1980 s\n",
      "classification accuracy: 0.9834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.03, 0.15, 5):\n",
    "    test_model(model=ConvModelSmall, settings=Triplet_Hinge_Settings, \n",
    "               data=data['mnist'], samplers=triplet_samplers['mnist'],\n",
    "               num_features=10, num_steps=15000, lr=lr, keep_prob=0.8, reg=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 20, lr: 0.112168, reg: 0.001\n",
      "\tstep 0: train loss 1.23382, train error 0.5\n",
      "\tstep 4000: train loss 0.0593057, train error 0.005\n",
      "\tstep 8000: train loss 0.0369204, train error 0\n",
      "\tstep 12000: train loss 0.0377043, train error 0.005\n",
      "end training features // time elapsed: 118.2453 s\n",
      "test set error: 0.0016 // time elapsed: 0.1988 s\n",
      "classification accuracy: 0.9871\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.141733, reg: 0.001\n",
      "\tstep 0: train loss 1.23479, train error 0.415\n",
      "\tstep 4000: train loss 0.0511741, train error 0\n",
      "\tstep 8000: train loss 0.0419123, train error 0\n",
      "\tstep 12000: train loss 0.0410957, train error 0\n",
      "end training features // time elapsed: 117.9538 s\n",
      "test set error: 0.0026 // time elapsed: 0.2057 s\n",
      "classification accuracy: 0.9861\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.145708, reg: 0.001\n",
      "\tstep 0: train loss 1.23608, train error 0.495\n",
      "\tstep 4000: train loss 0.0679675, train error 0.005\n",
      "\tstep 8000: train loss 0.0527129, train error 0.005\n",
      "\tstep 12000: train loss 0.0583877, train error 0.005\n",
      "end training features // time elapsed: 118.0110 s\n",
      "test set error: 0.0016 // time elapsed: 0.1957 s\n",
      "classification accuracy: 0.9857\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.130628, reg: 0.001\n",
      "\tstep 0: train loss 1.23415, train error 0.465\n",
      "\tstep 4000: train loss 0.0752229, train error 0.00999999\n",
      "\tstep 8000: train loss 0.0588116, train error 0.00999999\n",
      "\tstep 12000: train loss 0.0419117, train error 0.005\n",
      "end training features // time elapsed: 119.1064 s\n",
      "test set error: 0.0036 // time elapsed: 0.2025 s\n",
      "classification accuracy: 0.9866\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.145767, reg: 0.001\n",
      "\tstep 0: train loss 1.23608, train error 0.52\n",
      "\tstep 4000: train loss 0.0581936, train error 0\n",
      "\tstep 8000: train loss 0.0444953, train error 0\n",
      "\tstep 12000: train loss 0.0436316, train error 0\n",
      "end training features // time elapsed: 118.6854 s\n",
      "test set error: 0.0042 // time elapsed: 0.2259 s\n",
      "classification accuracy: 0.9832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.03, 0.15, 5):\n",
    "    test_model(model=ConvModelSmall, settings=Triplet_Hinge_Settings, \n",
    "               data=data['mnist'], samplers=triplet_samplers['mnist'],\n",
    "               num_features=20, num_steps=15000, lr=lr, keep_prob=0.8, reg=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 40, lr: 0.0732618, reg: 0.001\n",
      "\tstep 0: train loss 1.24144, train error 0.495\n",
      "\tstep 4000: train loss 0.0929606, train error 0.00999999\n",
      "\tstep 8000: train loss 0.0561131, train error 0.005\n",
      "\tstep 12000: train loss 0.0330865, train error 0\n",
      "end training features // time elapsed: 117.4174 s\n",
      "test set error: 0.0036 // time elapsed: 0.2119 s\n",
      "classification accuracy: 0.9825\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.142971, reg: 0.001\n",
      "\tstep 0: train loss 1.22403, train error 0.415\n",
      "\tstep 4000: train loss 0.0654998, train error 0.005\n",
      "\tstep 8000: train loss 0.0436373, train error 0\n",
      "\tstep 12000: train loss 0.0384467, train error 0\n",
      "end training features // time elapsed: 118.8584 s\n",
      "test set error: 0.0022 // time elapsed: 0.2229 s\n",
      "classification accuracy: 0.9866\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.111092, reg: 0.001\n",
      "\tstep 0: train loss 1.24466, train error 0.46\n",
      "\tstep 4000: train loss 0.0806207, train error 0.005\n",
      "\tstep 8000: train loss 0.0409483, train error 0\n",
      "\tstep 12000: train loss 0.0386673, train error 0\n",
      "end training features // time elapsed: 117.1368 s\n",
      "test set error: 0.0048 // time elapsed: 0.2419 s\n",
      "classification accuracy: 0.9830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.03, 0.15, 3):\n",
    "    test_model(model=ConvModelSmall, settings=Triplet_Hinge_Settings, \n",
    "               data=data['mnist'], samplers=triplet_samplers['mnist'],\n",
    "               num_features=40, num_steps=15000, lr=lr, keep_prob=0.8, reg=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Pair Tests (Adagrad optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 10, lr: 0.00847161, reg: 0\n",
      "\tstep 0: train loss 1.62533, train error 0.89\n",
      "\tstep 5000: train loss 0.952284, train error 0.47\n",
      "\tstep 10000: train loss 0.462537, train error 0.17\n",
      "end training features // time elapsed: 87.0650 s\n",
      "test set error: 0.1072 // time elapsed: 0.2684 s\n",
      "classification accuracy: 0.8635\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.00901295, reg: 0\n",
      "\tstep 0: train loss 1.77281, train error 0.915\n",
      "\tstep 5000: train loss 0.999498, train error 0.495\n",
      "\tstep 10000: train loss 0.568107, train error 0.225\n",
      "end training features // time elapsed: 86.9414 s\n",
      "test set error: 0.1082 // time elapsed: 0.2252 s\n",
      "classification accuracy: 0.8864\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.00651539, reg: 0\n",
      "\tstep 0: train loss 1.86173, train error 0.94\n",
      "\tstep 5000: train loss 0.780267, train error 0.33\n",
      "\tstep 10000: train loss 0.490319, train error 0.175\n",
      "end training features // time elapsed: 86.8976 s\n",
      "test set error: 0.1128 // time elapsed: 0.2297 s\n",
      "classification accuracy: 0.8728\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.00542112, reg: 0\n",
      "\tstep 0: train loss 1.36591, train error 0.925\n",
      "\tstep 5000: train loss 0.882167, train error 0.38\n",
      "\tstep 10000: train loss 0.666696, train error 0.255\n",
      "end training features // time elapsed: 87.0624 s\n",
      "test set error: 0.1690 // time elapsed: 0.3224 s\n",
      "classification accuracy: 0.8268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.007, 0.012, 3):\n",
    "    test_model(model=ConvModelSmall, settings=Pair_Hinge_Settings, \n",
    "               data=data['mnist'], samplers=pair_samplers['mnist'],\n",
    "               num_features=10, num_steps=15000, lr=lr, keep_prob=0.8, reg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 20, lr: 0.0132497, reg: 0\n",
      "\tstep 0: train loss 1.61059, train error 0.89\n",
      "\tstep 5000: train loss 0.632083, train error 0.24\n",
      "\tstep 10000: train loss 0.351145, train error 0.105\n",
      "end training features // time elapsed: 86.0507 s\n",
      "test set error: 0.0278 // time elapsed: 0.2836 s\n",
      "classification accuracy: 0.9573\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0126081, reg: 0\n",
      "\tstep 0: train loss 1.62727, train error 0.89\n",
      "\tstep 5000: train loss 0.519724, train error 0.165\n",
      "\tstep 10000: train loss 0.190258, train error 0.065\n",
      "end training features // time elapsed: 86.7726 s\n",
      "test set error: 0.0410 // time elapsed: 0.2450 s\n",
      "classification accuracy: 0.9526\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.00610331, reg: 0\n",
      "\tstep 0: train loss 1.42406, train error 0.86\n",
      "\tstep 5000: train loss 0.850974, train error 0.41\n",
      "\tstep 10000: train loss 0.470849, train error 0.18\n",
      "end training features // time elapsed: 86.5777 s\n",
      "test set error: 0.1062 // time elapsed: 0.2880 s\n",
      "classification accuracy: 0.9025\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0196944, reg: 0\n",
      "\tstep 0: train loss 1.29701, train error 0.91\n",
      "\tstep 5000: train loss 0.217759, train error 0.08\n",
      "\tstep 10000: train loss 0.0735018, train error 0.015\n",
      "end training features // time elapsed: 86.1099 s\n",
      "test set error: 0.0182 // time elapsed: 0.2855 s\n",
      "classification accuracy: 0.9701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.01, 0.03, 3):\n",
    "    test_model(model=ConvModelSmall, settings=Pair_Hinge_Settings, \n",
    "               data=data['mnist'], samplers=pair_samplers['mnist'],\n",
    "               num_features=20, num_steps=15000, lr=lr, keep_prob=0.8, reg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 40, lr: 0.018455, reg: 0\n",
      "\tstep 0: train loss 1.80684, train error 0.89\n",
      "\tstep 5000: train loss 0.608959, train error 0.245\n",
      "\tstep 10000: train loss 0.177772, train error 0.06\n",
      "end training features // time elapsed: 387.6101 s\n",
      "test set error: 0.0248 // time elapsed: 0.1941 s\n",
      "classification accuracy: 0.9606\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.0305185, reg: 0\n",
      "\tstep 0: train loss 2.31007, train error 0.9\n",
      "\tstep 5000: train loss 0.666152, train error 0.295\n",
      "\tstep 10000: train loss 0.12812, train error 0.05\n",
      "end training features // time elapsed: 384.0874 s\n",
      "test set error: 0.0314 // time elapsed: 0.1761 s\n",
      "classification accuracy: 0.8875\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.0221891, reg: 0\n",
      "\tstep 0: train loss 1.81611, train error 0.9\n",
      "\tstep 5000: train loss 0.0708081, train error 0.02\n",
      "\tstep 10000: train loss 0.0252054, train error 0.00999999\n",
      "end training features // time elapsed: 386.5518 s\n",
      "test set error: 0.0124 // time elapsed: 0.1660 s\n",
      "classification accuracy: 0.9734\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.030375, reg: 0\n",
      "\tstep 0: train loss 1.60996, train error 0.91\n",
      "\tstep 5000: train loss 0.0661105, train error 0.02\n",
      "\tstep 10000: train loss 0.0972831, train error 0.02\n",
      "end training features // time elapsed: 386.3034 s\n",
      "test set error: 0.0116 // time elapsed: 0.1708 s\n",
      "classification accuracy: 0.9780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.01, 0.035, 4):\n",
    "    test_model(model=ConvModelSmall, settings=Pair_Hinge_Settings, \n",
    "               data=data['mnist'], samplers=pair_samplers['mnist'],\n",
    "               num_features=40, num_steps=15000, lr=lr, keep_prob=0.8, reg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 10, lr: 0.0108642, reg: 0\n",
      "\tstep 0: train loss 1.29718, train error 0.885\n",
      "\tstep 4000: train loss 1.00266, train error 0.875\n",
      "\tstep 8000: train loss 0.979311, train error 0.48\n",
      "\tstep 12000: train loss 0.764198, train error 0.31\n",
      "end training features // time elapsed: 87.5860 s\n",
      "test set error: 0.1960 // time elapsed: 0.1538 s\n",
      "classification accuracy: 0.8151\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.0100808, reg: 0\n",
      "\tstep 0: train loss 1.26411, train error 0.925\n",
      "\tstep 4000: train loss 1.0026, train error 0.87\n",
      "\tstep 8000: train loss 1.00269, train error 0.84\n",
      "\tstep 12000: train loss 0.857726, train error 0.38\n",
      "end training features // time elapsed: 86.7527 s\n",
      "test set error: 0.2712 // time elapsed: 0.1470 s\n",
      "classification accuracy: 0.7620\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.0150876, reg: 0\n",
      "\tstep 0: train loss 1.39692, train error 0.925\n",
      "\tstep 4000: train loss 1.00072, train error 0.57\n",
      "\tstep 8000: train loss 0.697347, train error 0.285\n",
      "\tstep 12000: train loss 0.580294, train error 0.235\n",
      "end training features // time elapsed: 86.4290 s\n",
      "test set error: 0.1174 // time elapsed: 0.1532 s\n",
      "classification accuracy: 0.8129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.01, 0.03, 3):\n",
    "    test_model(model=ConvModelSmall, settings=Pair_Hinge_Settings, \n",
    "               data=data['mnist'], samplers=pair_samplers['mnist'],\n",
    "               num_features=10, num_steps=15000, lr=lr, keep_prob=0.8, reg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 20, lr: 0.0214675, reg: 0\n",
      "\tstep 0: train loss 1.4666, train error 0.885\n",
      "\tstep 4000: train loss 1.0032, train error 0.79\n",
      "\tstep 8000: train loss 0.514572, train error 0.205\n",
      "\tstep 12000: train loss 0.405674, train error 0.13\n",
      "end training features // time elapsed: 86.0124 s\n",
      "test set error: 0.0764 // time elapsed: 0.0944 s\n",
      "classification accuracy: 0.8781\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0292262, reg: 0\n",
      "\tstep 0: train loss 1.60217, train error 0.9\n",
      "\tstep 4000: train loss 0.764863, train error 0.285\n",
      "\tstep 8000: train loss 0.316047, train error 0.12\n",
      "\tstep 12000: train loss 0.141271, train error 0.055\n",
      "end training features // time elapsed: 85.6583 s\n",
      "test set error: 0.0388 // time elapsed: 0.1003 s\n",
      "classification accuracy: 0.9009\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0237202, reg: 0\n",
      "\tstep 0: train loss 1.88621, train error 0.92\n",
      "\tstep 4000: train loss 0.885426, train error 0.4\n",
      "\tstep 8000: train loss 0.383373, train error 0.135\n",
      "\tstep 12000: train loss 0.292549, train error 0.1\n",
      "end training features // time elapsed: 86.4654 s\n",
      "test set error: 0.0414 // time elapsed: 0.1064 s\n",
      "classification accuracy: 0.9523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.015, 0.03, 3):\n",
    "    test_model(model=ConvModelSmall, settings=Pair_Hinge_Settings, \n",
    "               data=data['mnist'], samplers=pair_samplers['mnist'],\n",
    "               num_features=20, num_steps=15000, lr=lr, keep_prob=0.8, reg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 40, lr: 0.0165854, reg: 0\n",
      "\tstep 0: train loss 1.82771, train error 0.89\n",
      "\tstep 4000: train loss 1.00289, train error 0.95\n",
      "\tstep 8000: train loss 1.00333, train error 0.73\n",
      "\tstep 12000: train loss 0.640527, train error 0.255\n",
      "end training features // time elapsed: 86.7912 s\n",
      "test set error: 0.0906 // time elapsed: 0.1186 s\n",
      "classification accuracy: 0.8403\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.0220736, reg: 0\n",
      "\tstep 0: train loss 1.63185, train error 0.895\n",
      "\tstep 4000: train loss 1.01056, train error 0.495\n",
      "\tstep 8000: train loss 0.435688, train error 0.155\n",
      "\tstep 12000: train loss 0.25372, train error 0.065\n",
      "end training features // time elapsed: 86.5853 s\n",
      "test set error: 0.0478 // time elapsed: 0.1417 s\n",
      "classification accuracy: 0.8853\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.0263975, reg: 0\n",
      "\tstep 0: train loss 1.97354, train error 0.9\n",
      "\tstep 4000: train loss 0.735703, train error 0.3\n",
      "\tstep 8000: train loss 0.325682, train error 0.105\n",
      "\tstep 12000: train loss 0.171908, train error 0.055\n",
      "end training features // time elapsed: 86.3208 s\n",
      "test set error: 0.0252 // time elapsed: 0.1229 s\n",
      "classification accuracy: 0.9611\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.015, 0.04, 3):\n",
    "    test_model(model=ConvModelSmall, settings=Pair_Hinge_Settings, \n",
    "               data=data['mnist'], samplers=pair_samplers['mnist'],\n",
    "               num_features=40, num_steps=15000, lr=lr, keep_prob=0.8, reg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fashion MNIST Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 10, lr: 0.119433, reg: 0.002\n",
      "\tstep 0: train loss 1.45781, train error 0.45\n",
      "\tstep 4000: train loss 0.0760131, train error 0.00999999\n",
      "\tstep 8000: train loss 0.0914871, train error 0.025\n",
      "\tstep 12000: train loss 0.0776445, train error 0.03\n",
      "\tstep 16000: train loss 0.0666515, train error 0.02\n",
      "end training features // time elapsed: 157.1605 s\n",
      "test set error: 0.0242 // time elapsed: 0.2092 s\n",
      "classification accuracy: 0.8881\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.117851, reg: 0.002\n",
      "\tstep 0: train loss 1.46418, train error 0.51\n",
      "\tstep 4000: train loss 0.114691, train error 0.04\n",
      "\tstep 8000: train loss 0.100385, train error 0.025\n",
      "\tstep 12000: train loss 0.0666172, train error 0.02\n",
      "\tstep 16000: train loss 0.0521798, train error 0.015\n",
      "end training features // time elapsed: 157.4858 s\n",
      "test set error: 0.0294 // time elapsed: 0.1716 s\n",
      "classification accuracy: 0.8885\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.105822, reg: 0.002\n",
      "\tstep 0: train loss 1.4597, train error 0.475\n",
      "\tstep 4000: train loss 0.0977025, train error 0.025\n",
      "\tstep 8000: train loss 0.080348, train error 0.015\n",
      "\tstep 12000: train loss 0.103476, train error 0.03\n",
      "\tstep 16000: train loss 0.0916474, train error 0.02\n",
      "end training features // time elapsed: 156.9452 s\n",
      "test set error: 0.0316 // time elapsed: 0.1969 s\n",
      "classification accuracy: 0.8823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.05, 0.15, 3):\n",
    "    test_model(model=ConvModelSmall, settings=Triplet_Hinge_Settings, \n",
    "               data=data['fashion_mnist'], samplers=triplet_samplers['fashion_mnist'],\n",
    "               num_features=10, num_steps=20000, lr=lr, keep_prob=0.8, reg=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 20, lr: 0.119088, reg: 0.002\n",
      "\tstep 0: train loss 1.47016, train error 0.375\n",
      "\tstep 4000: train loss 0.120975, train error 0.03\n",
      "\tstep 8000: train loss 0.0895732, train error 0.015\n",
      "\tstep 12000: train loss 0.0833746, train error 0.025\n",
      "\tstep 16000: train loss 0.0366519, train error 0.005\n",
      "end training features // time elapsed: 157.2065 s\n",
      "test set error: 0.0318 // time elapsed: 0.3166 s\n",
      "classification accuracy: 0.8867\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0526343, reg: 0.002\n",
      "\tstep 0: train loss 1.47449, train error 0.49\n",
      "\tstep 4000: train loss 0.148847, train error 0.035\n",
      "\tstep 8000: train loss 0.112621, train error 0.04\n",
      "\tstep 12000: train loss 0.114331, train error 0.03\n",
      "\tstep 16000: train loss 0.0320912, train error 0.005\n",
      "end training features // time elapsed: 157.4039 s\n",
      "test set error: 0.0358 // time elapsed: 0.3205 s\n",
      "classification accuracy: 0.8744\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0691768, reg: 0.002\n",
      "\tstep 0: train loss 1.46903, train error 0.45\n",
      "\tstep 4000: train loss 0.111947, train error 0.02\n",
      "\tstep 8000: train loss 0.101931, train error 0.045\n",
      "\tstep 12000: train loss 0.0899433, train error 0.03\n",
      "\tstep 16000: train loss 0.0586021, train error 0.00999999\n",
      "end training features // time elapsed: 156.9563 s\n",
      "test set error: 0.0356 // time elapsed: 0.3340 s\n",
      "classification accuracy: 0.8802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.05, 0.15, 3):\n",
    "    test_model(model=ConvModelSmall, settings=Triplet_Hinge_Settings, \n",
    "               data=data['fashion_mnist'], samplers=triplet_samplers['fashion_mnist'],\n",
    "               num_features=20, num_steps=20000, lr=lr, keep_prob=0.8, reg=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 10, lr: 0.00865784, reg: 0.002\n",
      "\tstep 0: train loss 2.11515, train error 0.92\n",
      "\tstep 4000: train loss 1.05817, train error 0.305\n",
      "\tstep 8000: train loss 0.862917, train error 0.195\n",
      "\tstep 12000: train loss 0.643841, train error 0.135\n",
      "\tstep 16000: train loss 0.532855, train error 0.115\n",
      "end training features // time elapsed: 114.8823 s\n",
      "test set error: 0.1532 // time elapsed: 0.0822 s\n",
      "classification accuracy: 0.7387\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.0136432, reg: 0.002\n",
      "\tstep 0: train loss 1.63396, train error 0.925\n",
      "\tstep 4000: train loss 0.753372, train error 0.155\n",
      "\tstep 8000: train loss 0.559513, train error 0.145\n",
      "\tstep 12000: train loss 0.450207, train error 0.095\n",
      "\tstep 16000: train loss 0.616267, train error 0.125\n",
      "end training features // time elapsed: 114.8808 s\n",
      "test set error: 0.1176 // time elapsed: 0.0814 s\n",
      "classification accuracy: 0.7666\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.0153829, reg: 0.002\n",
      "\tstep 0: train loss 1.89972, train error 0.92\n",
      "\tstep 4000: train loss 0.845517, train error 0.215\n",
      "\tstep 8000: train loss 0.488147, train error 0.11\n",
      "\tstep 12000: train loss 0.429121, train error 0.11\n",
      "\tstep 16000: train loss 0.334322, train error 0.11\n",
      "end training features // time elapsed: 115.0592 s\n",
      "test set error: 0.1312 // time elapsed: 0.0928 s\n",
      "classification accuracy: 0.7639\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.0193034, reg: 0.002\n",
      "\tstep 0: train loss 1.73137, train error 0.905\n",
      "\tstep 4000: train loss 0.94653, train error 0.245\n",
      "\tstep 8000: train loss 0.572663, train error 0.16\n",
      "\tstep 12000: train loss 0.44565, train error 0.115\n",
      "\tstep 16000: train loss 0.35395, train error 0.105\n",
      "end training features // time elapsed: 114.7615 s\n",
      "test set error: 0.1224 // time elapsed: 0.0888 s\n",
      "classification accuracy: 0.7313\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.0129668, reg: 0.002\n",
      "\tstep 0: train loss 1.82769, train error 0.895\n",
      "\tstep 4000: train loss 0.883303, train error 0.24\n",
      "\tstep 8000: train loss 0.461348, train error 0.105\n",
      "\tstep 12000: train loss 0.520661, train error 0.135\n",
      "\tstep 16000: train loss 0.542806, train error 0.135\n",
      "end training features // time elapsed: 114.2541 s\n",
      "test set error: 0.1194 // time elapsed: 0.0904 s\n",
      "classification accuracy: 0.7521\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.0186189, reg: 0.002\n",
      "\tstep 0: train loss 1.54036, train error 0.885\n",
      "\tstep 4000: train loss 0.831908, train error 0.215\n",
      "\tstep 8000: train loss 0.468777, train error 0.105\n",
      "\tstep 12000: train loss 0.508392, train error 0.135\n",
      "\tstep 16000: train loss 0.451151, train error 0.13\n",
      "end training features // time elapsed: 115.0761 s\n",
      "test set error: 0.1376 // time elapsed: 0.1030 s\n",
      "classification accuracy: 0.7425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.005, 0.02, 6):\n",
    "    test_model(model=ConvModelSmall, settings=Pair_Hinge_Settings, \n",
    "               data=data['fashion_mnist'], samplers=pair_samplers['fashion_mnist'],\n",
    "               num_features=10, num_steps=20000, lr=lr, keep_prob=0.8, reg=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 20, lr: 0.0217065, reg: 0\n",
      "\tstep 0: train loss 1.44929, train error 0.87\n",
      "\tstep 4000: train loss 0.531581, train error 0.12\n",
      "\tstep 8000: train loss 0.411968, train error 0.135\n",
      "\tstep 12000: train loss 0.388416, train error 0.13\n",
      "\tstep 16000: train loss 0.379726, train error 0.135\n",
      "end training features // time elapsed: 114.2696 s\n",
      "test set error: 0.1080 // time elapsed: 0.1059 s\n",
      "classification accuracy: 0.7981\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0218056, reg: 0\n",
      "\tstep 0: train loss 1.45932, train error 0.865\n",
      "\tstep 4000: train loss 0.521368, train error 0.175\n",
      "\tstep 8000: train loss 0.368553, train error 0.135\n",
      "\tstep 12000: train loss 0.311548, train error 0.085\n",
      "\tstep 16000: train loss 0.230428, train error 0.105\n",
      "end training features // time elapsed: 114.8639 s\n",
      "test set error: 0.0986 // time elapsed: 0.1260 s\n",
      "classification accuracy: 0.7963\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.00960272, reg: 0\n",
      "\tstep 0: train loss 1.5977, train error 0.915\n",
      "\tstep 4000: train loss 0.584998, train error 0.175\n",
      "\tstep 8000: train loss 0.354996, train error 0.105\n",
      "\tstep 12000: train loss 0.498708, train error 0.15\n",
      "\tstep 16000: train loss 0.302423, train error 0.105\n",
      "end training features // time elapsed: 116.0442 s\n",
      "test set error: 0.1156 // time elapsed: 0.1271 s\n",
      "classification accuracy: 0.7851\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0109691, reg: 0\n",
      "\tstep 0: train loss 1.26682, train error 0.945\n",
      "\tstep 4000: train loss 0.45537, train error 0.145\n",
      "\tstep 8000: train loss 0.397432, train error 0.135\n",
      "\tstep 12000: train loss 0.302791, train error 0.08\n",
      "\tstep 16000: train loss 0.269685, train error 0.08\n",
      "end training features // time elapsed: 115.7936 s\n",
      "test set error: 0.1114 // time elapsed: 0.1508 s\n",
      "classification accuracy: 0.7899\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0193567, reg: 0\n",
      "\tstep 0: train loss 1.268, train error 0.895\n",
      "\tstep 4000: train loss 0.510536, train error 0.17\n",
      "\tstep 8000: train loss 0.479229, train error 0.145\n",
      "\tstep 12000: train loss 0.311397, train error 0.105\n",
      "\tstep 16000: train loss 0.277003, train error 0.115\n",
      "end training features // time elapsed: 114.9691 s\n",
      "test set error: 0.0956 // time elapsed: 0.1271 s\n",
      "classification accuracy: 0.7965\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.00833843, reg: 0\n",
      "\tstep 0: train loss 1.41419, train error 0.88\n",
      "\tstep 4000: train loss 0.639777, train error 0.175\n",
      "\tstep 8000: train loss 0.51506, train error 0.15\n",
      "\tstep 12000: train loss 0.362836, train error 0.09\n",
      "\tstep 16000: train loss 0.316308, train error 0.115\n",
      "end training features // time elapsed: 114.3111 s\n",
      "test set error: 0.1230 // time elapsed: 0.1355 s\n",
      "classification accuracy: 0.7700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.005, 0.03, 6):\n",
    "    test_model(model=ConvModelSmall, settings=Pair_Hinge_Settings, \n",
    "               data=data['fashion_mnist'], samplers=pair_samplers['fashion_mnist'],\n",
    "               num_features=20, num_steps=20000, lr=lr, keep_prob=0.8, reg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 10, lr: 0.0775914, reg: 0.002\n",
      "\tstep 0: train loss 1.4636, train error 0.465\n",
      "\tstep 4000: train loss 0.0818809, train error 0.005\n",
      "\tstep 8000: train loss 0.062792, train error 0.005\n",
      "\tstep 12000: train loss 0.0509089, train error 0\n",
      "\tstep 16000: train loss 0.0497464, train error 0.00999999\n",
      "end training features // time elapsed: 158.0652 s\n",
      "test set error: 0.0038 // time elapsed: 0.2867 s\n",
      "classification accuracy: 0.9822\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.0960076, reg: 0.002\n",
      "\tstep 0: train loss 1.46496, train error 0.455\n",
      "\tstep 4000: train loss 0.0709629, train error 0.005\n",
      "\tstep 8000: train loss 0.0626883, train error 0.005\n",
      "\tstep 12000: train loss 0.0399753, train error 0\n",
      "\tstep 16000: train loss 0.0537192, train error 0.00999999\n",
      "end training features // time elapsed: 157.5807 s\n",
      "test set error: 0.0030 // time elapsed: 0.2301 s\n",
      "classification accuracy: 0.9853\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.101034, reg: 0.002\n",
      "\tstep 0: train loss 1.46052, train error 0.49\n",
      "\tstep 4000: train loss 0.0670225, train error 0.005\n",
      "\tstep 8000: train loss 0.0463222, train error 0\n",
      "\tstep 12000: train loss 0.0623773, train error 0.00999999\n",
      "\tstep 16000: train loss 0.039041, train error 0\n",
      "end training features // time elapsed: 158.0611 s\n",
      "test set error: 0.0024 // time elapsed: 0.2635 s\n",
      "classification accuracy: 0.9817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.05, 0.15, 3):\n",
    "    test_model(model=ConvModelSmall, settings=Triplet_Hinge_Settings, \n",
    "               data=data['fashion_mnist'], samplers=triplet_samplers['fashion_mnist'],\n",
    "               num_features=10, num_steps=20000, lr=lr, keep_prob=0.8, reg=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 20, lr: 0.120133, reg: 0.002\n",
      "\tstep 0: train loss 1.47892, train error 0.55\n",
      "\tstep 4000: train loss 1.00111, train error 0.455\n",
      "\tstep 8000: train loss 1, train error 0.545\n",
      "\tstep 12000: train loss 1, train error 1\n",
      "\tstep 16000: train loss 1, train error 1\n",
      "end training features // time elapsed: 158.5085 s\n",
      "test set error: 1.0000 // time elapsed: 0.2476 s\n",
      "classification accuracy: 0.1135\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0675542, reg: 0.002\n",
      "\tstep 0: train loss 1.47008, train error 0.41\n",
      "\tstep 4000: train loss 0.0699491, train error 0\n",
      "\tstep 8000: train loss 0.0626706, train error 0.005\n",
      "\tstep 12000: train loss 0.0531413, train error 0\n",
      "\tstep 16000: train loss 0.0446168, train error 0.005\n",
      "end training features // time elapsed: 156.6717 s\n",
      "test set error: 0.0044 // time elapsed: 0.2838 s\n",
      "classification accuracy: 0.9835\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.0835517, reg: 0.002\n",
      "\tstep 0: train loss 1.47784, train error 0.495\n",
      "\tstep 4000: train loss 0.0696012, train error 0.005\n",
      "\tstep 8000: train loss 0.0571674, train error 0\n",
      "\tstep 12000: train loss 0.0411233, train error 0\n",
      "\tstep 16000: train loss 0.0397345, train error 0\n",
      "end training features // time elapsed: 156.2569 s\n",
      "test set error: 0.0032 // time elapsed: 0.2431 s\n",
      "classification accuracy: 0.9842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.05, 0.15, 3):\n",
    "    test_model(model=ConvModelSmall, settings=Triplet_Hinge_Settings, \n",
    "               data=data['fashion_mnist'], samplers=triplet_samplers['fashion_mnist'],\n",
    "               num_features=20, num_steps=20000, lr=lr, keep_prob=0.8, reg=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 40, lr: 0.13256, reg: 0.001\n",
      "\tstep 0: train loss 1.24831, train error 0.525\n",
      "\tstep 1000: train loss 0.299273, train error 0.05\n",
      "\tstep 2000: train loss 0.214023, train error 0.055\n",
      "\tstep 3000: train loss 0.18164, train error 0.04\n",
      "\tstep 4000: train loss 0.217303, train error 0.07\n",
      "\tstep 5000: train loss 0.159904, train error 0.045\n",
      "\tstep 6000: train loss 0.114296, train error 0.02\n",
      "\tstep 7000: train loss 0.13144, train error 0.045\n",
      "\tstep 8000: train loss 0.144272, train error 0.045\n",
      "\tstep 9000: train loss 0.130618, train error 0.05\n",
      "\tstep 10000: train loss 0.147199, train error 0.025\n",
      "\tstep 11000: train loss 0.134921, train error 0.03\n",
      "\tstep 12000: train loss 0.111659, train error 0.03\n",
      "\tstep 13000: train loss 0.105656, train error 0.025\n",
      "\tstep 14000: train loss 0.103824, train error 0.03\n",
      "\tstep 15000: train loss 0.115541, train error 0.04\n",
      "\tstep 16000: train loss 0.119241, train error 0.025\n",
      "\tstep 17000: train loss 0.178198, train error 0.065\n",
      "\tstep 18000: train loss 0.0998972, train error 0.025\n",
      "\tstep 19000: train loss 0.123022, train error 0.035\n",
      "end training features // time elapsed: 156.2125 s\n",
      "test set error: 0.0354 // time elapsed: 0.2535 s\n",
      "classification accuracy: 0.8627\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.0557338, reg: 0.001\n",
      "\tstep 0: train loss 1.24549, train error 0.505\n",
      "\tstep 1000: train loss 0.37521, train error 0.1\n",
      "\tstep 2000: train loss 0.298878, train error 0.06\n",
      "\tstep 3000: train loss 0.23409, train error 0.05\n",
      "\tstep 4000: train loss 0.24656, train error 0.07\n",
      "\tstep 5000: train loss 0.233824, train error 0.075\n",
      "\tstep 6000: train loss 0.127473, train error 0.04\n",
      "\tstep 7000: train loss 0.141394, train error 0.035\n",
      "\tstep 8000: train loss 0.168852, train error 0.06\n",
      "\tstep 9000: train loss 0.119105, train error 0.04\n",
      "\tstep 10000: train loss 0.100619, train error 0.03\n",
      "\tstep 11000: train loss 0.123103, train error 0.045\n",
      "\tstep 12000: train loss 0.143745, train error 0.055\n",
      "\tstep 13000: train loss 0.0678143, train error 0.00999999\n",
      "\tstep 14000: train loss 0.130222, train error 0.04\n",
      "\tstep 15000: train loss 0.129513, train error 0.05\n",
      "\tstep 16000: train loss 0.120324, train error 0.04\n",
      "\tstep 17000: train loss 0.119062, train error 0.045\n",
      "\tstep 18000: train loss 0.160625, train error 0.05\n",
      "\tstep 19000: train loss 0.114999, train error 0.035\n",
      "end training features // time elapsed: 156.4673 s\n",
      "test set error: 0.0344 // time elapsed: 0.2565 s\n",
      "classification accuracy: 0.8640\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.0949432, reg: 0.001\n",
      "\tstep 0: train loss 1.24535, train error 0.455\n",
      "\tstep 1000: train loss 0.296631, train error 0.06\n",
      "\tstep 2000: train loss 0.193933, train error 0.04\n",
      "\tstep 3000: train loss 0.203489, train error 0.05\n",
      "\tstep 4000: train loss 0.132327, train error 0.025\n",
      "\tstep 5000: train loss 0.134388, train error 0.03\n",
      "\tstep 6000: train loss 0.145586, train error 0.04\n",
      "\tstep 7000: train loss 0.161417, train error 0.055\n",
      "\tstep 8000: train loss 0.164936, train error 0.06\n",
      "\tstep 9000: train loss 0.121589, train error 0.03\n",
      "\tstep 10000: train loss 0.118051, train error 0.03\n",
      "\tstep 11000: train loss 0.0954898, train error 0.03\n",
      "\tstep 12000: train loss 0.107853, train error 0.03\n",
      "\tstep 13000: train loss 0.120444, train error 0.04\n",
      "\tstep 14000: train loss 0.120914, train error 0.04\n",
      "\tstep 15000: train loss 0.0959273, train error 0.025\n",
      "\tstep 16000: train loss 0.111191, train error 0.025\n",
      "\tstep 17000: train loss 0.118223, train error 0.04\n",
      "\tstep 18000: train loss 0.0834638, train error 0.015\n",
      "\tstep 19000: train loss 0.104449, train error 0.03\n",
      "end training features // time elapsed: 156.3793 s\n",
      "test set error: 0.0334 // time elapsed: 0.2716 s\n",
      "classification accuracy: 0.8658\n",
      "\n",
      "begin training features // num_features: 40, lr: 0.0769077, reg: 0.001\n",
      "\tstep 0: train loss 1.25397, train error 0.57\n",
      "\tstep 1000: train loss 0.343612, train error 0.055\n",
      "\tstep 2000: train loss 0.275047, train error 0.065\n",
      "\tstep 3000: train loss 0.259994, train error 0.09\n",
      "\tstep 4000: train loss 0.190507, train error 0.035\n",
      "\tstep 5000: train loss 0.161495, train error 0.05\n",
      "\tstep 6000: train loss 0.157257, train error 0.05\n",
      "\tstep 7000: train loss 0.147355, train error 0.05\n",
      "\tstep 8000: train loss 0.16171, train error 0.055\n",
      "\tstep 9000: train loss 0.192483, train error 0.07\n",
      "\tstep 10000: train loss 0.165883, train error 0.06\n",
      "\tstep 11000: train loss 0.139412, train error 0.04\n",
      "\tstep 12000: train loss 0.132379, train error 0.06\n",
      "\tstep 13000: train loss 0.194293, train error 0.08\n",
      "\tstep 14000: train loss 0.0800928, train error 0.015\n",
      "\tstep 15000: train loss 0.117181, train error 0.04\n",
      "\tstep 16000: train loss 0.129311, train error 0.045\n",
      "\tstep 17000: train loss 0.140737, train error 0.045\n",
      "\tstep 18000: train loss 0.136951, train error 0.035\n",
      "\tstep 19000: train loss 0.141681, train error 0.04\n",
      "end training features // time elapsed: 157.8307 s\n",
      "test set error: 0.0412 // time elapsed: 0.2662 s\n",
      "classification accuracy: 0.8653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.01, 0.15, 4):\n",
    "    test_model(model=ConvModelSmall, settings=Triplet_Hinge_Settings, \n",
    "               data=data['fashion_mnist'], samplers=triplet_samplers['fashion_mnist'],\n",
    "               num_features=40, num_steps=20000, lr=lr, keep_prob=0.8, reg=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 10, lr: 0.00292767, reg: 0.002\n",
      "\tstep 0: train loss 2.48459, train error 0.91\n",
      "\tstep 4000: train loss 1.45283, train error 0.935\n",
      "\tstep 8000: train loss 1.43023, train error 0.88\n",
      "end training features // time elapsed: 261.6228 s\n",
      "test set error: 0.8892 // time elapsed: 0.5404 s\n",
      "classification accuracy: 0.3858\n",
      "\n",
      "begin training features // num_features: 10, lr: 0.00690873, reg: 0.002\n",
      "\tstep 0: train loss 1.63593, train error 0.92\n",
      "\tstep 4000: train loss 1.42279, train error 0.96\n",
      "\tstep 8000: train loss 1.37834, train error 0.94\n",
      "end training features // time elapsed: 260.0945 s\n",
      "test set error: 0.9040 // time elapsed: 0.5677 s\n",
      "classification accuracy: 0.4068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.001, 0.01, 2):\n",
    "    test_model(model=ConvModelSmall, settings=Pair_Hinge_Settings, \n",
    "               data=data['fashion_mnist'], samplers=pair_samplers['fashion_mnist'],\n",
    "               num_features=10, num_steps=10000, lr=lr, keep_prob=0.8, reg=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 20, lr: 0.01, reg: 0.002\n",
      "\tstep 0: train loss 1.72006, train error 0.88\n",
      "\tstep 4000: train loss 1.40857, train error 0.935\n",
      "\tstep 8000: train loss 1.3476, train error 0.915\n",
      "end training features // time elapsed: 262.1665 s\n",
      "test set error: 0.8974 // time elapsed: 0.5301 s\n",
      "classification accuracy: 0.4749\n",
      "\n",
      "begin training features // num_features: 20, lr: 0.01, reg: 0.002\n",
      "\tstep 0: train loss 2.26366, train error 0.89\n",
      "\tstep 4000: train loss 1.40845, train error 0.9\n",
      "\tstep 8000: train loss 1.34737, train error 0.885\n",
      "end training features // time elapsed: 261.5377 s\n",
      "test set error: 0.8514 // time elapsed: 0.5608 s\n",
      "classification accuracy: 0.5800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.random.uniform(0.001, 0.01, 2):\n",
    "    test_model(model=ConvModelSmall, settings=Pair_Hinge_Settings, \n",
    "               data=data['fashion_mnist'], samplers=pair_samplers['fashion_mnist'],\n",
    "               num_features=20, num_steps=10000, lr=0.01, keep_prob=0.8, reg=0.002)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
