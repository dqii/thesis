{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dqi/.conda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/dqi/.conda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from features.settings import Baseline_Settings, Pair_Hinge_Settings, Pair_Log_Settings, Triplet_Hinge_Settings, Triplet_Log_Settings\n",
    "from features.models import ConvModelSmall, ConvModelMedium, ConvModelLarge\n",
    "from features.models import GCNNModelSmall, GCNNModelMedium, GCNNModelLarge\n",
    "from classes.models import LinearClassifier\n",
    "from datasets import load_mnist_datasets, load_cifar10\n",
    "from sklearn.svm import LinearSVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, samplers, pair_samplers, triplet_samplers = load_cifar10(augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(feature_model, settings, data, num_features, num_classes, feature_samplers, classification_samplers,\n",
    "               f_num_steps, f_lr, f_keep_prob, f_reg, c_num_steps, c_lr, c_reg):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    f_train, f_valid, f_test = feature_samplers\n",
    "    c_train, c_valid, c_test = classification_samplers\n",
    "    (x_train, y_train), (x_valid, y_valid), (x_test, y_test) = data\n",
    "    _, H, W, C = x_train.shape\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, H, W, C])\n",
    "    y = tf.placeholder(tf.int64, shape=[None])    \n",
    "    dropout = tf.placeholder(tf.float32)\n",
    "    training = tf.placeholder(tf.bool)\n",
    "    f_model = feature_model(x=x, y=y, settings=settings, num_chan=C, num_features=num_features, \n",
    "              lr=f_lr, reg=f_reg, dropout=dropout, training=training)\n",
    "    \n",
    "    features = tf.placeholder(tf.float32, shape=[None, num_features])\n",
    "    c_model = LinearClassifier(x=features, y=y, num_features=num_features, num_classes=num_features, \n",
    "                               lr=c_lr, reg=c_reg)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        print(\"begin training features // num_features: %g, lr: %g, reg: %g, dropout: %g\" %(num_features, f_lr, f_reg, f_keep_prob))\n",
    "        train_time = time.time()\n",
    "        for step in range(f_num_steps):        \n",
    "            x_, y_ = f_train.sample(700)\n",
    "            sess.run(f_model.optimize, feed_dict={x:x_, y:y_, dropout:f_keep_prob, training:True})     \n",
    "            if step % 1000 == 0:\n",
    "                train_loss, train_acc = sess.run([f_model.loss, f_model.acc], \n",
    "                                                 feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "                print(\"\\tstep %d: train loss %g, train error %g\"%(step, train_loss, 1 - train_acc))  \n",
    "        train_time = time.time() - train_time\n",
    "        print(\"end training features // time elapsed: %.4f s\"%(train_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        x_, y_ = f_valid.sample(1000)\n",
    "        test_error = 1 - sess.run(f_model.acc, feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"validation set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        x_, y_ = f_test.sample(1000)\n",
    "        test_error = 1 - sess.run(f_model.acc, feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"test set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        print(\"begin training classifier\")\n",
    "        train_time = time.time()\n",
    "        for step in range(c_num_steps):        \n",
    "            x_, y_ = c_train.sample(700)\n",
    "            features_ = sess.run(f_model.features, feed_dict={x:x_, dropout:1.0, training:False})\n",
    "            sess.run(c_model.optimize, feed_dict={features:features_, y:y_, x:x_, dropout:1.0, training:False})\n",
    "            if step % 1000 == 0:\n",
    "                train_loss, train_acc = sess.run([c_model.loss, c_model.acc], feed_dict={features:features_, y:y_})\n",
    "                print(\"\\tstep %d: train loss %g, train error %g\"%(step, train_loss, 1 - train_acc))  \n",
    "        train_time = time.time() - train_time\n",
    "        print(\"end training classifier // time elapsed: %.4f s\"%(train_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        features_ = sess.run(f_model.features, feed_dict={x:x_valid, dropout:1.0, training:False})\n",
    "        test_error = 1 - sess.run(c_model.acc, feed_dict={features:features_, y:y_valid})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"validation set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        features_ = sess.run(f_model.features, feed_dict={x:x_test, dropout:1.0, training:False})\n",
    "        test_error = 1 - sess.run(c_model.acc, feed_dict={features:features_, y:y_test})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"test set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model(feature_model=GCNNModelSmall, settings=Baseline_Settings, num_features=10, num_classes=10,\n",
    "           data=data, feature_samplers=samplers, classification_samplers=samplers,           \n",
    "           f_num_steps=70000, f_lr=0.01, f_keep_prob=0.5, f_reg=0.001, \n",
    "           c_num_steps=30000, c_lr=0.005, c_reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 10, lr: 0.005, reg: 0.001, dropout: 0.7\n",
      "\tstep 0: train loss 2.90478, train error 0.88\n",
      "\tstep 1000: train loss 2.1117, train error 0.584286\n",
      "\tstep 2000: train loss 1.88936, train error 0.512857\n",
      "\tstep 3000: train loss 1.84096, train error 0.501429\n",
      "\tstep 4000: train loss 1.74124, train error 0.474286\n",
      "\tstep 5000: train loss 1.66072, train error 0.431429\n",
      "\tstep 6000: train loss 1.6487, train error 0.44\n",
      "\tstep 7000: train loss 1.56426, train error 0.392857\n",
      "\tstep 8000: train loss 1.53038, train error 0.427143\n",
      "\tstep 9000: train loss 1.46465, train error 0.354286\n",
      "\tstep 10000: train loss 1.44198, train error 0.404286\n",
      "\tstep 11000: train loss 1.37918, train error 0.354286\n",
      "\tstep 12000: train loss 1.34303, train error 0.347143\n",
      "\tstep 13000: train loss 1.3746, train error 0.354286\n",
      "\tstep 14000: train loss 1.30965, train error 0.33\n",
      "\tstep 15000: train loss 1.23419, train error 0.31\n",
      "\tstep 16000: train loss 1.18724, train error 0.315714\n",
      "\tstep 17000: train loss 1.16145, train error 0.31\n",
      "\tstep 18000: train loss 1.13039, train error 0.277143\n",
      "\tstep 19000: train loss 1.13911, train error 0.31\n",
      "\tstep 20000: train loss 1.05654, train error 0.262857\n",
      "\tstep 21000: train loss 1.05982, train error 0.291429\n",
      "\tstep 22000: train loss 1.08187, train error 0.281429\n",
      "\tstep 23000: train loss 1.01064, train error 0.247143\n",
      "\tstep 24000: train loss 0.88018, train error 0.224286\n",
      "\tstep 25000: train loss 0.957877, train error 0.238571\n",
      "\tstep 26000: train loss 0.910506, train error 0.24\n",
      "\tstep 27000: train loss 0.93953, train error 0.26\n",
      "\tstep 28000: train loss 0.901492, train error 0.234286\n",
      "\tstep 29000: train loss 0.846461, train error 0.217143\n",
      "\tstep 30000: train loss 0.817357, train error 0.205714\n",
      "\tstep 31000: train loss 0.804218, train error 0.211429\n",
      "\tstep 32000: train loss 0.796648, train error 0.202857\n",
      "\tstep 33000: train loss 0.791413, train error 0.185714\n",
      "\tstep 34000: train loss 0.750798, train error 0.188571\n",
      "\tstep 35000: train loss 0.69595, train error 0.175714\n",
      "\tstep 36000: train loss 0.741541, train error 0.205714\n",
      "\tstep 37000: train loss 0.659111, train error 0.154286\n",
      "\tstep 38000: train loss 0.676025, train error 0.182857\n",
      "\tstep 39000: train loss 0.649439, train error 0.161429\n",
      "\tstep 40000: train loss 0.65124, train error 0.15\n",
      "\tstep 41000: train loss 0.615056, train error 0.144286\n",
      "\tstep 42000: train loss 0.553963, train error 0.11\n",
      "\tstep 43000: train loss 0.635872, train error 0.145714\n",
      "\tstep 44000: train loss 0.566614, train error 0.152857\n",
      "\tstep 45000: train loss 0.540116, train error 0.135714\n",
      "\tstep 46000: train loss 0.499169, train error 0.11\n",
      "\tstep 47000: train loss 0.521024, train error 0.121429\n",
      "\tstep 48000: train loss 0.451255, train error 0.0985714\n",
      "\tstep 49000: train loss 0.470851, train error 0.108571\n",
      "end training features // time elapsed: 2704.0647 s\n",
      "test set error: 0.0980 // time elapsed: 0.0742 s\n",
      "begin training classifier\n",
      "\tstep 0: train loss 7.73228, train error 0.942857\n",
      "\tstep 1000: train loss 0.509928, train error 0.145714\n",
      "\tstep 2000: train loss 0.436219, train error 0.132857\n",
      "\tstep 3000: train loss 0.406093, train error 0.117143\n",
      "\tstep 4000: train loss 0.363274, train error 0.0942857\n",
      "\tstep 5000: train loss 0.374723, train error 0.112857\n",
      "\tstep 6000: train loss 0.346584, train error 0.101429\n",
      "\tstep 7000: train loss 0.310374, train error 0.0857143\n",
      "\tstep 8000: train loss 0.357692, train error 0.101429\n",
      "\tstep 9000: train loss 0.297803, train error 0.0728571\n",
      "\tstep 10000: train loss 0.414637, train error 0.127143\n",
      "\tstep 11000: train loss 0.339709, train error 0.105714\n",
      "\tstep 12000: train loss 0.314992, train error 0.0942857\n",
      "\tstep 13000: train loss 0.319081, train error 0.0914286\n",
      "\tstep 14000: train loss 0.346421, train error 0.0942857\n",
      "\tstep 15000: train loss 0.315819, train error 0.0885714\n",
      "\tstep 16000: train loss 0.276653, train error 0.0685714\n",
      "\tstep 17000: train loss 0.324875, train error 0.102857\n",
      "\tstep 18000: train loss 0.353682, train error 0.107143\n",
      "\tstep 19000: train loss 0.29632, train error 0.0857143\n",
      "\tstep 20000: train loss 0.299517, train error 0.0942857\n",
      "\tstep 21000: train loss 0.313753, train error 0.0971429\n",
      "\tstep 22000: train loss 0.327786, train error 0.1\n",
      "\tstep 23000: train loss 0.30733, train error 0.0942857\n",
      "\tstep 24000: train loss 0.293748, train error 0.09\n",
      "\tstep 25000: train loss 0.317954, train error 0.101429\n",
      "\tstep 26000: train loss 0.3072, train error 0.0957143\n",
      "\tstep 27000: train loss 0.279523, train error 0.08\n",
      "\tstep 28000: train loss 0.248246, train error 0.0814286\n",
      "\tstep 29000: train loss 0.274316, train error 0.088\n",
      "end training classifier // time elapsed: 1265.8765 s\n",
      "validation set error: 0.1953 // time elapsed: 0.3181 s\n",
      "test set error: 0.1919 // time elapsed: 0.5069 s\n"
     ]
    }
   ],
   "source": [
    "test_model(feature_model=GCNNModelSmall, settings=Triplet_Hinge_Settings, num_features=20, num_classes=10,\n",
    "           data=data, feature_samplers=triplet_samplers, classification_samplers=samplers,           \n",
    "           f_num_steps=70000, f_lr=0.01, f_keep_prob=0.5, f_reg=0.001, \n",
    "           c_num_steps=40000, c_lr=0.01, c_reg=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 10, lr: 0.01, reg: 0.001, dropout: 0.7\n",
      "\tstep 0: train loss 1.50643, train error 0.478571\n",
      "\tstep 1000: train loss 1.24498, train error 0.352857\n",
      "\tstep 2000: train loss 1.09998, train error 0.291429\n",
      "\tstep 3000: train loss 1.07486, train error 0.284286\n",
      "\tstep 4000: train loss 0.947896, train error 0.237143\n",
      "\tstep 5000: train loss 0.91593, train error 0.227143\n",
      "\tstep 6000: train loss 0.886203, train error 0.238571\n",
      "\tstep 7000: train loss 0.853999, train error 0.224286\n",
      "\tstep 8000: train loss 0.769975, train error 0.18\n",
      "\tstep 9000: train loss 0.754984, train error 0.204286\n",
      "\tstep 10000: train loss 0.751925, train error 0.202857\n",
      "\tstep 11000: train loss 0.654789, train error 0.162857\n",
      "\tstep 12000: train loss 0.626638, train error 0.162857\n",
      "\tstep 13000: train loss 0.600326, train error 0.161429\n",
      "\tstep 14000: train loss 0.63765, train error 0.168571\n",
      "\tstep 15000: train loss 0.62557, train error 0.18\n",
      "\tstep 16000: train loss 0.575746, train error 0.151429\n",
      "\tstep 17000: train loss 0.563768, train error 0.168571\n",
      "\tstep 18000: train loss 0.54012, train error 0.155714\n",
      "\tstep 19000: train loss 0.508662, train error 0.145714\n",
      "\tstep 20000: train loss 0.485249, train error 0.138571\n",
      "\tstep 21000: train loss 0.517119, train error 0.168571\n",
      "\tstep 22000: train loss 0.446396, train error 0.132857\n",
      "\tstep 23000: train loss 0.442461, train error 0.124286\n",
      "\tstep 24000: train loss 0.494697, train error 0.151429\n",
      "\tstep 25000: train loss 0.371701, train error 0.107143\n",
      "\tstep 26000: train loss 0.375476, train error 0.0971429\n",
      "\tstep 27000: train loss 0.344622, train error 0.101429\n",
      "\tstep 28000: train loss 0.318569, train error 0.0957143\n",
      "\tstep 29000: train loss 0.349275, train error 0.102857\n",
      "\tstep 30000: train loss 0.338423, train error 0.108571\n",
      "\tstep 31000: train loss 0.285128, train error 0.0785714\n",
      "\tstep 32000: train loss 0.275754, train error 0.0685714\n",
      "\tstep 33000: train loss 0.245414, train error 0.0714286\n",
      "\tstep 34000: train loss 0.285164, train error 0.09\n",
      "\tstep 35000: train loss 0.236233, train error 0.0628572\n",
      "\tstep 36000: train loss 0.277613, train error 0.09\n",
      "\tstep 37000: train loss 0.262703, train error 0.0842857\n",
      "\tstep 38000: train loss 0.204217, train error 0.0542857\n",
      "\tstep 39000: train loss 0.220159, train error 0.0557143\n",
      "\tstep 40000: train loss 0.205455, train error 0.0514286\n",
      "\tstep 41000: train loss 0.186126, train error 0.0471429\n",
      "\tstep 42000: train loss 0.221846, train error 0.0685714\n",
      "\tstep 43000: train loss 0.178245, train error 0.05\n",
      "\tstep 44000: train loss 0.173432, train error 0.0485714\n",
      "\tstep 45000: train loss 0.152934, train error 0.0485714\n",
      "\tstep 46000: train loss 0.162025, train error 0.0457143\n",
      "\tstep 47000: train loss 0.172565, train error 0.0471429\n",
      "\tstep 48000: train loss 0.132912, train error 0.03\n",
      "\tstep 49000: train loss 0.154171, train error 0.05\n",
      "end training features // time elapsed: 8499.1727 s\n",
      "test set error: 0.0530 // time elapsed: 0.2239 s\n",
      "begin training classifier\n",
      "\tstep 0: train loss 2.88748, train error 0.762857\n",
      "\tstep 1000: train loss 1.60364, train error 0.227143\n",
      "\tstep 2000: train loss 1.18572, train error 0.15\n",
      "\tstep 3000: train loss 1.06469, train error 0.167143\n",
      "\tstep 4000: train loss 0.970575, train error 0.152857\n",
      "\tstep 5000: train loss 0.950454, train error 0.162857\n",
      "\tstep 6000: train loss 0.894961, train error 0.154286\n",
      "\tstep 7000: train loss 0.884714, train error 0.148571\n",
      "\tstep 8000: train loss 0.851789, train error 0.18\n",
      "\tstep 9000: train loss 0.816386, train error 0.168571\n",
      "\tstep 10000: train loss 0.790865, train error 0.144286\n",
      "\tstep 11000: train loss 0.82316, train error 0.175714\n",
      "\tstep 12000: train loss 0.750503, train error 0.14\n",
      "\tstep 13000: train loss 0.739258, train error 0.151429\n",
      "\tstep 14000: train loss 0.755255, train error 0.177143\n",
      "\tstep 15000: train loss 0.726288, train error 0.148571\n",
      "\tstep 16000: train loss 0.724191, train error 0.164286\n",
      "\tstep 17000: train loss 0.70341, train error 0.158571\n",
      "\tstep 18000: train loss 0.675154, train error 0.144286\n",
      "\tstep 19000: train loss 0.696658, train error 0.147143\n",
      "\tstep 20000: train loss 0.720136, train error 0.165714\n",
      "\tstep 21000: train loss 0.704099, train error 0.154286\n",
      "\tstep 22000: train loss 0.664557, train error 0.144286\n",
      "\tstep 23000: train loss 0.708232, train error 0.168571\n",
      "\tstep 24000: train loss 0.644532, train error 0.152857\n",
      "\tstep 25000: train loss 0.669217, train error 0.145714\n",
      "\tstep 26000: train loss 0.671169, train error 0.152857\n",
      "\tstep 27000: train loss 0.626306, train error 0.141429\n",
      "\tstep 28000: train loss 0.650318, train error 0.154286\n",
      "\tstep 29000: train loss 0.621673, train error 0.131429\n",
      "end training classifier // time elapsed: 1267.0060 s\n",
      "validation set error: 0.2305 // time elapsed: 0.2429 s\n",
      "test set error: 0.2283 // time elapsed: 0.3750 s\n"
     ]
    }
   ],
   "source": [
    "test_model(feature_model=GCNNModelSmall, settings=Triplet_Hinge_Settings, num_features=20, num_classes=10,\n",
    "           data=data, feature_samplers=triplet_samplers, classification_samplers=samplers,           \n",
    "           f_num_steps=70000, f_lr=0.01, f_keep_prob=0.6, f_reg=0.001, \n",
    "           c_num_steps=40000, c_lr=0.01, c_reg=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
