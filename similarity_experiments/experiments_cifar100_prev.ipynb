{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dqi/.conda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/dqi/.conda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from features.settings import Baseline_Settings, Pair_Hinge_Settings, Pair_Log_Settings, Triplet_Hinge_Settings, Triplet_Log_Settings\n",
    "from features.models import ConvModelSmall, ConvModelMedium, ConvModelLarge\n",
    "from features.models import GCNNModelSmall, GCNNModelMedium, GCNNModelLarge\n",
    "from classes.models import LinearClassifier\n",
    "from datasets import load_cifar100\n",
    "from sklearn.svm import LinearSVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-100 loaded in 99 seconds\n"
     ]
    }
   ],
   "source": [
    "data, samplers, pair_samplers, triplet_samplers = load_cifar100(augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(feature_model, settings, data, num_features, num_classes, feature_samplers, classification_samplers,\n",
    "               f_num_steps, f_lr, f_keep_prob, f_reg, c_num_steps, c_lr, c_reg):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    f_train, f_valid, f_test = feature_samplers\n",
    "    c_train, c_valid, c_test = classification_samplers\n",
    "    (x_train, y_train), (x_valid, y_valid), (x_test, y_test) = data\n",
    "    _, H, W, C = x_train.shape\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, H, W, C])\n",
    "    y = tf.placeholder(tf.int64, shape=[None])    \n",
    "    dropout = tf.placeholder(tf.float32)\n",
    "    training = tf.placeholder(tf.bool)\n",
    "    f_model = feature_model(x=x, y=y, settings=settings, num_chan=C, num_features=num_features, \n",
    "              lr=f_lr, reg=f_reg, dropout=dropout, training=training)\n",
    "    \n",
    "    features = tf.placeholder(tf.float32, shape=[None, num_features])\n",
    "    c_model = LinearClassifier(x=features, y=y, num_features=num_features, num_classes=num_features, \n",
    "                               lr=c_lr, reg=c_reg)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        print(\"begin training features // num_features: %g, lr: %g, reg: %g, dropout: %g\" %(num_features, f_lr, f_reg, f_keep_prob))\n",
    "        train_time = time.time()\n",
    "        for step in range(f_num_steps):        \n",
    "            x_, y_ = f_train.sample(700)\n",
    "            sess.run(f_model.optimize, feed_dict={x:x_, y:y_, dropout:f_keep_prob, training:True})     \n",
    "            if step % 1000 == 0:\n",
    "                train_loss, train_acc = sess.run([f_model.loss, f_model.acc], \n",
    "                                                 feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "                print(\"\\tstep %d: train loss %g, train error %g\"%(step, train_loss, 1 - train_acc))  \n",
    "        train_time = time.time() - train_time\n",
    "        print(\"end training features // time elapsed: %.4f s\"%(train_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        x_, y_ = f_valid.sample(1000)\n",
    "        test_error = 1 - sess.run(f_model.acc, feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"validation set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        x_, y_ = f_test.sample(1000)\n",
    "        test_error = 1 - sess.run(f_model.acc, feed_dict={x:x_, y:y_, dropout:1.0, training:False})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"test set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        print(\"begin training classifier\")\n",
    "        train_time = time.time()\n",
    "        for step in range(c_num_steps):        \n",
    "            x_, y_ = c_train.sample(700)\n",
    "            features_ = sess.run(f_model.features, feed_dict={x:x_, dropout:1.0, training:False})\n",
    "            sess.run(c_model.optimize, feed_dict={features:features_, y:y_, x:x_, dropout:1.0, training:False})\n",
    "            if step % 1000 == 0:\n",
    "                train_loss, train_acc = sess.run([c_model.loss, c_model.acc], feed_dict={features:features_, y:y_})\n",
    "                print(\"\\tstep %d: train loss %g, train error %g\"%(step, train_loss, 1 - train_acc))  \n",
    "        train_time = time.time() - train_time\n",
    "        print(\"end training classifier // time elapsed: %.4f s\"%(train_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        features_ = sess.run(f_model.features, feed_dict={x:x_valid, dropout:1.0, training:False})\n",
    "        test_error = 1 - sess.run(c_model.acc, feed_dict={features:features_, y:y_valid})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"validation set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))\n",
    "        \n",
    "        eval_test_time = time.time()\n",
    "        features_ = sess.run(f_model.features, feed_dict={x:x_test, dropout:1.0, training:False})\n",
    "        test_error = 1 - sess.run(c_model.acc, feed_dict={features:features_, y:y_test})\n",
    "        eval_test_time = time.time() - eval_test_time\n",
    "        print(\"test set error: %.4f // time elapsed: %.4f s\"%(test_error, eval_test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 100, lr: 0.005, reg: 0.001, dropout: 0.7\n",
      "\tstep 0: train loss 5.1756, train error 0.994286\n",
      "\tstep 1000: train loss 4.70449, train error 0.928571\n",
      "\tstep 2000: train loss 4.48616, train error 0.895714\n",
      "\tstep 3000: train loss 4.28408, train error 0.858571\n",
      "\tstep 4000: train loss 4.14724, train error 0.86\n",
      "\tstep 5000: train loss 4.05787, train error 0.837143\n",
      "\tstep 6000: train loss 3.96254, train error 0.794286\n",
      "\tstep 7000: train loss 3.81377, train error 0.801429\n",
      "\tstep 8000: train loss 3.6956, train error 0.771429\n",
      "\tstep 9000: train loss 3.55967, train error 0.74\n",
      "\tstep 10000: train loss 3.60746, train error 0.762857\n",
      "\tstep 11000: train loss 3.50842, train error 0.751429\n",
      "\tstep 12000: train loss 3.33077, train error 0.691429\n",
      "\tstep 13000: train loss 3.37124, train error 0.747143\n",
      "\tstep 14000: train loss 3.23313, train error 0.725714\n",
      "\tstep 15000: train loss 3.18991, train error 0.691429\n",
      "\tstep 16000: train loss 3.08696, train error 0.668571\n",
      "\tstep 17000: train loss 3.09258, train error 0.697143\n",
      "\tstep 18000: train loss 3.09322, train error 0.672857\n",
      "\tstep 19000: train loss 2.96581, train error 0.665714\n",
      "\tstep 20000: train loss 3.01591, train error 0.622857\n",
      "\tstep 21000: train loss 2.88448, train error 0.63\n",
      "\tstep 22000: train loss 2.67756, train error 0.59\n",
      "\tstep 23000: train loss 2.74376, train error 0.608571\n",
      "\tstep 24000: train loss 2.74505, train error 0.635714\n",
      "\tstep 25000: train loss 2.73311, train error 0.621429\n",
      "\tstep 26000: train loss 2.71576, train error 0.611429\n",
      "\tstep 27000: train loss 2.57002, train error 0.601429\n",
      "\tstep 28000: train loss 2.54309, train error 0.56\n",
      "\tstep 29000: train loss 2.5726, train error 0.591429\n",
      "\tstep 30000: train loss 2.48304, train error 0.578571\n",
      "\tstep 31000: train loss 2.4247, train error 0.54\n",
      "\tstep 32000: train loss 2.42694, train error 0.547143\n",
      "\tstep 33000: train loss 2.29084, train error 0.535714\n",
      "\tstep 34000: train loss 2.41264, train error 0.557143\n",
      "\tstep 35000: train loss 2.28834, train error 0.515714\n",
      "\tstep 36000: train loss 2.27937, train error 0.547143\n",
      "\tstep 37000: train loss 2.26447, train error 0.497143\n",
      "\tstep 38000: train loss 2.16557, train error 0.5\n",
      "\tstep 39000: train loss 2.22823, train error 0.517143\n",
      "\tstep 40000: train loss 2.14273, train error 0.487143\n",
      "\tstep 41000: train loss 2.14506, train error 0.504286\n",
      "\tstep 42000: train loss 2.08251, train error 0.504286\n",
      "\tstep 43000: train loss 1.96733, train error 0.447143\n",
      "\tstep 44000: train loss 2.02825, train error 0.462857\n",
      "\tstep 45000: train loss 2.06205, train error 0.494286\n",
      "\tstep 46000: train loss 1.99402, train error 0.464286\n",
      "\tstep 47000: train loss 1.81416, train error 0.425714\n",
      "\tstep 48000: train loss 1.85119, train error 0.435714\n",
      "\tstep 49000: train loss 1.82661, train error 0.412857\n",
      "end training features // time elapsed: 2682.1527 s\n",
      "validation set error: 0.5400 // time elapsed: 0.0794 s\n",
      "test set error: 0.5310 // time elapsed: 0.0312 s\n",
      "begin training classifier\n",
      "\tstep 0: train loss 7.7302, train error 0.988571\n",
      "\tstep 1000: train loss 2.60847, train error 0.562857\n",
      "\tstep 2000: train loss 2.33289, train error 0.495714\n",
      "\tstep 3000: train loss 2.11307, train error 0.45\n",
      "\tstep 4000: train loss 2.01216, train error 0.448571\n",
      "\tstep 5000: train loss 1.98197, train error 0.45\n",
      "\tstep 6000: train loss 2.02348, train error 0.474286\n",
      "\tstep 7000: train loss 1.91427, train error 0.442857\n",
      "\tstep 8000: train loss 1.92565, train error 0.431429\n",
      "\tstep 9000: train loss 1.86029, train error 0.424286\n",
      "\tstep 10000: train loss 1.81891, train error 0.432857\n",
      "\tstep 11000: train loss 1.80285, train error 0.451429\n",
      "\tstep 12000: train loss 1.86371, train error 0.437143\n",
      "\tstep 13000: train loss 1.85183, train error 0.445714\n",
      "\tstep 14000: train loss 1.75146, train error 0.437143\n",
      "\tstep 15000: train loss 1.8381, train error 0.441429\n",
      "\tstep 16000: train loss 1.73527, train error 0.407143\n",
      "\tstep 17000: train loss 1.73167, train error 0.422857\n",
      "\tstep 18000: train loss 1.82393, train error 0.45\n",
      "\tstep 19000: train loss 1.71753, train error 0.424286\n",
      "\tstep 20000: train loss 1.83901, train error 0.438571\n",
      "\tstep 21000: train loss 1.64922, train error 0.424286\n",
      "\tstep 22000: train loss 1.71996, train error 0.43\n",
      "\tstep 23000: train loss 1.67308, train error 0.395714\n",
      "\tstep 24000: train loss 1.74658, train error 0.425714\n",
      "\tstep 25000: train loss 1.62067, train error 0.401429\n",
      "\tstep 26000: train loss 1.7719, train error 0.455714\n",
      "\tstep 27000: train loss 1.58613, train error 0.402857\n",
      "\tstep 28000: train loss 1.69502, train error 0.427143\n",
      "\tstep 29000: train loss 1.70386, train error 0.408571\n",
      "end training classifier // time elapsed: 1245.6339 s\n",
      "validation set error: 0.5380 // time elapsed: 0.3094 s\n",
      "test set error: 0.5314 // time elapsed: 0.4929 s\n"
     ]
    }
   ],
   "source": [
    "test_model(feature_model=GCNNModelSmall, settings=Baseline_Settings, num_features=100, num_classes=100,\n",
    "           data=data, feature_samplers=samplers, classification_samplers=samplers,           \n",
    "           f_num_steps=50000, f_lr=0.005, f_keep_prob=0.7, f_reg=0.001, \n",
    "           c_num_steps=30000, c_lr=0.005, c_reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training features // num_features: 100, lr: 0.005, reg: 0.001, dropout: 0.7\n",
      "\tstep 0: train loss 1.53351, train error 0.505714\n",
      "\tstep 1000: train loss 1.46798, train error 0.352857\n",
      "\tstep 2000: train loss 1.33485, train error 0.362857\n",
      "\tstep 3000: train loss 1.30228, train error 0.372857\n",
      "\tstep 4000: train loss 1.24266, train error 0.311429\n",
      "\tstep 5000: train loss 1.20417, train error 0.341429\n",
      "\tstep 6000: train loss 1.19621, train error 0.324286\n",
      "\tstep 7000: train loss 1.17528, train error 0.33\n",
      "\tstep 8000: train loss 1.16044, train error 0.345714\n",
      "\tstep 9000: train loss 1.10267, train error 0.307143\n",
      "\tstep 10000: train loss 1.10224, train error 0.317143\n",
      "\tstep 11000: train loss 1.12373, train error 0.324286\n",
      "\tstep 12000: train loss 1.0809, train error 0.325714\n",
      "\tstep 13000: train loss 1.06041, train error 0.3\n",
      "\tstep 14000: train loss 1.08949, train error 0.321429\n",
      "\tstep 15000: train loss 1.00825, train error 0.291429\n",
      "\tstep 16000: train loss 1.02152, train error 0.291429\n",
      "\tstep 17000: train loss 0.978742, train error 0.271429\n",
      "\tstep 18000: train loss 1.03716, train error 0.322857\n",
      "\tstep 19000: train loss 0.959697, train error 0.282857\n",
      "\tstep 20000: train loss 0.953021, train error 0.302857\n",
      "\tstep 21000: train loss 0.926537, train error 0.275714\n",
      "\tstep 22000: train loss 0.913064, train error 0.288571\n",
      "\tstep 23000: train loss 0.902799, train error 0.265714\n",
      "\tstep 24000: train loss 0.870271, train error 0.265714\n",
      "\tstep 25000: train loss 0.851202, train error 0.258571\n",
      "\tstep 26000: train loss 0.851143, train error 0.261429\n",
      "\tstep 27000: train loss 0.804845, train error 0.237143\n",
      "\tstep 28000: train loss 0.808907, train error 0.24\n",
      "\tstep 29000: train loss 0.824531, train error 0.252857\n",
      "\tstep 30000: train loss 0.78969, train error 0.245714\n",
      "\tstep 31000: train loss 0.785575, train error 0.242857\n",
      "\tstep 32000: train loss 0.799096, train error 0.268571\n",
      "\tstep 33000: train loss 0.767751, train error 0.244286\n",
      "\tstep 34000: train loss 0.766985, train error 0.254286\n",
      "\tstep 35000: train loss 0.735197, train error 0.238571\n",
      "\tstep 36000: train loss 0.717122, train error 0.231429\n",
      "\tstep 37000: train loss 0.723082, train error 0.224286\n",
      "\tstep 38000: train loss 0.765152, train error 0.254286\n",
      "\tstep 39000: train loss 0.721959, train error 0.238571\n",
      "\tstep 40000: train loss 0.70764, train error 0.235714\n",
      "\tstep 41000: train loss 0.704096, train error 0.237143\n",
      "\tstep 42000: train loss 0.675741, train error 0.202857\n",
      "\tstep 43000: train loss 0.683356, train error 0.234286\n",
      "\tstep 44000: train loss 0.672852, train error 0.215714\n",
      "\tstep 45000: train loss 0.666807, train error 0.224286\n",
      "\tstep 46000: train loss 0.681969, train error 0.247143\n",
      "\tstep 47000: train loss 0.614142, train error 0.174286\n",
      "\tstep 48000: train loss 0.599757, train error 0.185714\n",
      "\tstep 49000: train loss 0.674838, train error 0.222857\n",
      "end training features // time elapsed: 8339.1134 s\n",
      "validation set error: 0.2040 // time elapsed: 0.2360 s\n",
      "test set error: 0.2360 // time elapsed: 0.1623 s\n",
      "begin training classifier\n",
      "\tstep 0: train loss 5.13965, train error 0.987143\n",
      "\tstep 1000: train loss 5.00756, train error 0.96\n",
      "\tstep 2000: train loss 4.92846, train error 0.952857\n",
      "\tstep 3000: train loss 4.84418, train error 0.942857\n",
      "\tstep 4000: train loss 4.76539, train error 0.921429\n",
      "\tstep 5000: train loss 4.70586, train error 0.921429\n",
      "\tstep 6000: train loss 4.63937, train error 0.915714\n",
      "\tstep 7000: train loss 4.59588, train error 0.911429\n",
      "\tstep 8000: train loss 4.52265, train error 0.882857\n",
      "\tstep 9000: train loss 4.46197, train error 0.878571\n",
      "\tstep 10000: train loss 4.44519, train error 0.891429\n",
      "\tstep 11000: train loss 4.3691, train error 0.865714\n",
      "\tstep 12000: train loss 4.31467, train error 0.831429\n",
      "\tstep 13000: train loss 4.34406, train error 0.888571\n",
      "\tstep 14000: train loss 4.30916, train error 0.887143\n",
      "\tstep 15000: train loss 4.22216, train error 0.855714\n",
      "\tstep 16000: train loss 4.21097, train error 0.861429\n",
      "\tstep 17000: train loss 4.21258, train error 0.835714\n",
      "\tstep 18000: train loss 4.14324, train error 0.851429\n",
      "\tstep 19000: train loss 4.16644, train error 0.854286\n",
      "\tstep 20000: train loss 4.12187, train error 0.854286\n",
      "\tstep 21000: train loss 4.12384, train error 0.832857\n",
      "\tstep 22000: train loss 4.05758, train error 0.817143\n",
      "\tstep 23000: train loss 4.02542, train error 0.832857\n",
      "\tstep 24000: train loss 4.08691, train error 0.848571\n",
      "\tstep 25000: train loss 3.99368, train error 0.825714\n",
      "\tstep 26000: train loss 4.05031, train error 0.832857\n",
      "\tstep 27000: train loss 3.99266, train error 0.835714\n",
      "\tstep 28000: train loss 3.94493, train error 0.827143\n",
      "\tstep 29000: train loss 3.89835, train error 0.805714\n",
      "end training classifier // time elapsed: 1250.2533 s\n",
      "validation set error: 0.8433 // time elapsed: 0.2048 s\n",
      "test set error: 0.8264 // time elapsed: 0.3199 s\n"
     ]
    }
   ],
   "source": [
    "test_model(feature_model=GCNNModelSmall, settings=Triplet_Hinge_Settings, num_features=100, num_classes=100,\n",
    "           data=data, feature_samplers=triplet_samplers, classification_samplers=samplers,           \n",
    "           f_num_steps=50000, f_lr=0.005, f_keep_prob=0.7, f_reg=0.001, \n",
    "           c_num_steps=30000, c_lr=0.005, c_reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
