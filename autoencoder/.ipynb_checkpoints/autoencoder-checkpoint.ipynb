{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32').reshape((-1, 28, 28, 1)) / 255.\n",
    "x_test = x_test.astype('float32').reshape((-1, 28, 28, 1)) / 255.\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 29s 477us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 29s 475us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 28s 475us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 29s 475us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 29s 482us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 29s 477us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 28s 474us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 29s 475us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 29s 477us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 29s 481us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 28s 473us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 28s 468us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 28s 474us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 28s 474us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 28s 472us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 28s 473us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 29s 476us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 28s 475us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 28s 470us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 29s 478us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 28s 474us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 29s 476us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 28s 471us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 28s 467us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 28s 472us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 28s 474us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 29s 475us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 29s 477us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 29s 479us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 29s 477us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 28s 471us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 29s 479us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 29s 479us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 28s 471us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 38/50\n",
      " 6400/60000 [==>...........................] - ETA: 23s - loss: 0.0040"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2afe56319048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Reshape\n",
    "model = Sequential()\n",
    "model.add(Reshape((16,), input_shape=(4,4,1)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "train_labels = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "test_labels = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_encoded = encoder.predict(x_train)\n",
    "x_test_encoded = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 2.3219 - acc: 0.1024 - val_loss: 2.3021 - val_acc: 0.1028\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.3016 - acc: 0.1097 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3008 - val_acc: 0.1135\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 2.3012 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2afe55d64dd8>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model, iterating on the data in batches of 256 samples\n",
    "model.fit(x_train_encoded, train_labels, epochs=50, batch_size=256, validation_data=(x_test_encoded, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.3707 - acc: 0.6114 - val_loss: 0.6897 - val_acc: 0.7864\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.5865 - acc: 0.8202 - val_loss: 0.4973 - val_acc: 0.8528\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.4658 - acc: 0.8609 - val_loss: 0.4429 - val_acc: 0.8708\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.4096 - acc: 0.8789 - val_loss: 0.4065 - val_acc: 0.8766\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3757 - acc: 0.8889 - val_loss: 0.3601 - val_acc: 0.8980\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3514 - acc: 0.8956 - val_loss: 0.3273 - val_acc: 0.9063\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3345 - acc: 0.9014 - val_loss: 0.3154 - val_acc: 0.9086\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3208 - acc: 0.9052 - val_loss: 0.3030 - val_acc: 0.9110\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.3094 - acc: 0.9093 - val_loss: 0.3066 - val_acc: 0.9100\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 0.2995 - acc: 0.9127 - val_loss: 0.2900 - val_acc: 0.9180\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2912 - acc: 0.9149 - val_loss: 0.2760 - val_acc: 0.9189\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2836 - acc: 0.9178 - val_loss: 0.2681 - val_acc: 0.9217\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2769 - acc: 0.9202 - val_loss: 0.2814 - val_acc: 0.9166\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2708 - acc: 0.9213 - val_loss: 0.2690 - val_acc: 0.9210\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2647 - acc: 0.9231 - val_loss: 0.2618 - val_acc: 0.9233\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2601 - acc: 0.9251 - val_loss: 0.2497 - val_acc: 0.9264\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2558 - acc: 0.9258 - val_loss: 0.2402 - val_acc: 0.9291\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2510 - acc: 0.9276 - val_loss: 0.2360 - val_acc: 0.9320\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2468 - acc: 0.9291 - val_loss: 0.2410 - val_acc: 0.9285\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2429 - acc: 0.9306 - val_loss: 0.2355 - val_acc: 0.9295\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2395 - acc: 0.9316 - val_loss: 0.2274 - val_acc: 0.9340\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2362 - acc: 0.9320 - val_loss: 0.2230 - val_acc: 0.9355\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2329 - acc: 0.9328 - val_loss: 0.2200 - val_acc: 0.9354\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2301 - acc: 0.9337 - val_loss: 0.2263 - val_acc: 0.9333\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2272 - acc: 0.9350 - val_loss: 0.2225 - val_acc: 0.9343\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2242 - acc: 0.9363 - val_loss: 0.2216 - val_acc: 0.9335\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 0.2216 - acc: 0.9368 - val_loss: 0.2197 - val_acc: 0.9357\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 0.2192 - acc: 0.9375 - val_loss: 0.2118 - val_acc: 0.9380\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2168 - acc: 0.9381 - val_loss: 0.2318 - val_acc: 0.9322\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2142 - acc: 0.9387 - val_loss: 0.2056 - val_acc: 0.9394\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2119 - acc: 0.9392 - val_loss: 0.2074 - val_acc: 0.9382\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.2094 - acc: 0.9396 - val_loss: 0.2264 - val_acc: 0.9336\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.2075 - acc: 0.9406 - val_loss: 0.2102 - val_acc: 0.9386\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.2057 - acc: 0.9407 - val_loss: 0.2086 - val_acc: 0.9387\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.2044 - acc: 0.9413 - val_loss: 0.1968 - val_acc: 0.9425\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.2016 - acc: 0.9419 - val_loss: 0.1965 - val_acc: 0.9428\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.2001 - acc: 0.9418 - val_loss: 0.1930 - val_acc: 0.9437\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1979 - acc: 0.9437 - val_loss: 0.1956 - val_acc: 0.9435\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1965 - acc: 0.9436 - val_loss: 0.1906 - val_acc: 0.9449\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1949 - acc: 0.9444 - val_loss: 0.1902 - val_acc: 0.9449\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1934 - acc: 0.9439 - val_loss: 0.1908 - val_acc: 0.9433\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1914 - acc: 0.9458 - val_loss: 0.1889 - val_acc: 0.9448\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1896 - acc: 0.9459 - val_loss: 0.1885 - val_acc: 0.9463\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1887 - acc: 0.9453 - val_loss: 0.1826 - val_acc: 0.9475\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 0.1872 - acc: 0.9458 - val_loss: 0.1824 - val_acc: 0.9459\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1860 - acc: 0.9468 - val_loss: 0.1815 - val_acc: 0.9467\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1841 - acc: 0.9475 - val_loss: 0.1803 - val_acc: 0.9479\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1830 - acc: 0.9473 - val_loss: 0.1885 - val_acc: 0.9447\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1820 - acc: 0.9471 - val_loss: 0.1762 - val_acc: 0.9502\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1801 - acc: 0.9482 - val_loss: 0.1792 - val_acc: 0.9484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2afe70910e80>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model, iterating on the data in batches of 256 samples\n",
    "model.fit(x_train_encoded, train_labels, epochs=50, batch_size=256, validation_data=(x_test_encoded, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
